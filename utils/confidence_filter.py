"""
–£—Ç–∏–ª–∏—Ç—ã –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –ø–æ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
"""

import torch
import numpy as np
from typing import Dict, Tuple, Optional
from utils.logger import get_logger

logger = get_logger("ConfidenceFilter")


def filter_predictions_by_confidence(
    predictions: Dict[str, torch.Tensor],
    confidence_threshold: float = 0.6,
    return_mask: bool = False
) -> Dict[str, torch.Tensor]:
    """
    –§–∏–ª—å—Ç—Ä—É–µ—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –ø–æ –ø–æ—Ä–æ–≥—É —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
    
    Args:
        predictions: –°–ª–æ–≤–∞—Ä—å —Å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è–º–∏ –º–æ–¥–µ–ª–∏
        confidence_threshold: –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –ø–æ—Ä–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
        return_mask: –í–æ–∑–≤—Ä–∞—â–∞—Ç—å –ª–∏ –º–∞—Å–∫—É —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
        
    Returns:
        –û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
    """
    # –ò–∑–≤–ª–µ–∫–∞–µ–º confidence scores
    if 'confidence_scores' not in predictions:
        logger.warning("Confidence scores –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è—Ö")
        return predictions
    
    confidence_scores = predictions['confidence_scores']
    
    # confidence_scores –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ [-1, 1] –±–ª–∞–≥–æ–¥–∞—Ä—è Tanh
    # -1 = –Ω–µ—É–≤–µ—Ä–µ–Ω–Ω—ã–π/–Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π, +1 = —É–≤–µ—Ä–µ–Ω–Ω—ã–π/–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π
    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ [0, 1] –¥–ª—è –ø–æ—Ä–æ–≥–∞
    confidence_probs = (confidence_scores + 1) / 2
    
    # –°–æ–∑–¥–∞–µ–º –º–∞—Å–∫—É –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
    # confidence_probs –∏–º–µ–µ—Ç —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å (batch_size, 4) –¥–ª—è 4 —Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–≤
    confidence_mask = confidence_probs > confidence_threshold
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    total_predictions = confidence_scores.numel()
    confident_predictions = confidence_mask.sum().item()
    confidence_ratio = confident_predictions / total_predictions
    
    logger.info(f"üìä –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏:")
    logger.info(f"   –ü–æ—Ä–æ–≥: {confidence_threshold:.2f}")
    logger.info(f"   –£–≤–µ—Ä–µ–Ω–Ω—ã—Ö –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π: {confident_predictions}/{total_predictions} ({confidence_ratio:.1%})")
    
    # –°–æ–∑–¥–∞–µ–º –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
    filtered_predictions = predictions.copy()
    
    # –î–ª—è direction –∫–ª–∞—Å—Å–æ–≤: –∑–∞–º–µ–Ω—è–µ–º –Ω–µ—É–≤–µ—Ä–µ–Ω–Ω—ã–µ –Ω–∞ FLAT (2)
    if 'direction_classes' in predictions:
        direction_classes = predictions['direction_classes'].clone()
        # –ó–∞–º–µ–Ω—è–µ–º –Ω–µ—É–≤–µ—Ä–µ–Ω–Ω—ã–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –Ω–∞ FLAT
        direction_classes[~confidence_mask] = 2  # FLAT
        filtered_predictions['direction_classes'] = direction_classes
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∫–ª–∞—Å—Å–∞–º –ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
        for i in range(4):  # 4 —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞
            mask_tf = confidence_mask[:, i]
            confident_count = mask_tf.sum().item()
            total_count = mask_tf.shape[0]
            
            if confident_count > 0:
                classes = direction_classes[:, i][mask_tf]
                long_count = (classes == 0).sum().item()
                short_count = (classes == 1).sum().item()
                flat_count = (classes == 2).sum().item()
                
                logger.info(f"   –¢–∞–π–º—Ñ—Ä–µ–π–º {i+1}: {confident_count}/{total_count} —É–≤–µ—Ä–µ–Ω–Ω—ã—Ö "
                          f"(LONG: {long_count}, SHORT: {short_count}, FLAT: {flat_count})")
    
    # –î–ª—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π —É—Ä–æ–≤–Ω–µ–π: –æ–±–Ω—É–ª—è–µ–º –Ω–µ—É–≤–µ—Ä–µ–Ω–Ω—ã–µ
    for key in ['long_levels', 'short_levels']:
        if key in predictions:
            levels = predictions[key].clone()
            levels[~confidence_mask] = 0.0  # –û–±–Ω—É–ª—è–µ–º –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏
            filtered_predictions[key] = levels
    
    if return_mask:
        filtered_predictions['confidence_mask'] = confidence_mask
    
    return filtered_predictions


def get_high_confidence_signals(
    predictions: Dict[str, torch.Tensor],
    min_confidence: float = 0.7,
    min_price_change: float = 0.01  # 1%
) -> Dict[str, torch.Tensor]:
    """
    –ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–æ–ª—å–∫–æ –≤—ã—Å–æ–∫–æ—É–≤–µ—Ä–µ–Ω–Ω—ã–µ —Ç–æ—Ä–≥–æ–≤—ã–µ —Å–∏–≥–Ω–∞–ª—ã
    
    Args:
        predictions: –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –º–æ–¥–µ–ª–∏
        min_confidence: –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
        min_price_change: –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –æ–∂–∏–¥–∞–µ–º–æ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ —Ü–µ–Ω—ã
        
    Returns:
        –°–ª–æ–≤–∞—Ä—å —Å –≤—ã—Å–æ–∫–æ—É–≤–µ—Ä–µ–Ω–Ω—ã–º–∏ —Å–∏–≥–Ω–∞–ª–∞–º–∏
    """
    signals = {
        'long_signals': [],
        'short_signals': [],
        'confidence': [],
        'expected_return': []
    }
    
    if 'confidence_scores' not in predictions:
        return signals
    
    confidence_scores = predictions['confidence_scores']
    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –∏–∑ [-1, 1] –≤ [0, 1] (—Ç–∞–∫ –∫–∞–∫ –∏—Å–ø–æ–ª—å–∑—É–µ–º Tanh –≤ –º–æ–¥–µ–ª–∏)
    confidence_probs = (confidence_scores + 1) / 2
    
    direction_classes = predictions.get('direction_classes', None)
    future_returns = predictions.get('future_returns', None)
    
    if direction_classes is None or future_returns is None:
        return signals
    
    batch_size = confidence_scores.shape[0]
    
    for i in range(batch_size):
        for tf in range(4):  # 4 —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞
            conf = confidence_probs[i, tf].item()
            
            if conf >= min_confidence:
                direction = int(direction_classes[i, tf].item())
                expected_return = future_returns[i, tf].item()
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –¥–≤–∏–∂–µ–Ω–∏–µ
                if abs(expected_return) >= min_price_change:
                    if direction == 0:  # LONG
                        signals['long_signals'].append({
                            'sample': i,
                            'timeframe': tf,
                            'confidence': conf,
                            'expected_return': expected_return
                        })
                    elif direction == 1:  # SHORT
                        signals['short_signals'].append({
                            'sample': i,
                            'timeframe': tf,
                            'confidence': conf,
                            'expected_return': expected_return
                        })
    
    # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    total_long = len(signals['long_signals'])
    total_short = len(signals['short_signals'])
    
    if total_long + total_short > 0:
        logger.info(f"üéØ –í—ã—Å–æ–∫–æ—É–≤–µ—Ä–µ–Ω–Ω—ã–µ —Å–∏–≥–Ω–∞–ª—ã (conf>{min_confidence:.2f}, move>{min_price_change:.1%}):")
        logger.info(f"   LONG: {total_long} —Å–∏–≥–Ω–∞–ª–æ–≤")
        logger.info(f"   SHORT: {total_short} —Å–∏–≥–Ω–∞–ª–æ–≤")
        
        # –°—Ä–µ–¥–Ω—è—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
        all_conf = [s['confidence'] for s in signals['long_signals'] + signals['short_signals']]
        avg_conf = np.mean(all_conf) if all_conf else 0
        logger.info(f"   –°—Ä–µ–¥–Ω—è—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {avg_conf:.3f}")
    else:
        logger.info("‚ùå –ù–µ—Ç –≤—ã—Å–æ–∫–æ—É–≤–µ—Ä–µ–Ω–Ω—ã—Ö —Å–∏–≥–Ω–∞–ª–æ–≤")
    
    return signals


def apply_confidence_based_position_sizing(
    base_position_size: float,
    confidence_score: float,
    min_confidence: float = 0.5,
    max_confidence: float = 0.9
) -> float:
    """
    –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É–µ—Ç —Ä–∞–∑–º–µ—Ä –ø–æ–∑–∏—Ü–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
    
    Args:
        base_position_size: –ë–∞–∑–æ–≤—ã–π —Ä–∞–∑–º–µ—Ä –ø–æ–∑–∏—Ü–∏–∏
        confidence_score: –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è [0, 1]
        min_confidence: –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –¥–ª—è —Ç–æ—Ä–≥–æ–≤–ª–∏
        max_confidence: –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –ø–æ–∑–∏—Ü–∏–∏
        
    Returns:
        –°–∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ä–∞–∑–º–µ—Ä –ø–æ–∑–∏—Ü–∏–∏
    """
    if confidence_score < min_confidence:
        return 0.0  # –ù–µ —Ç–æ—Ä–≥—É–µ–º –ø—Ä–∏ –Ω–∏–∑–∫–æ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
    
    # –õ–∏–Ω–µ–π–Ω–∞—è –∏–Ω—Ç–µ—Ä–ø–æ–ª—è—Ü–∏—è –º–µ–∂–¥—É min –∏ max
    confidence_factor = (confidence_score - min_confidence) / (max_confidence - min_confidence)
    confidence_factor = np.clip(confidence_factor, 0.0, 1.0)
    
    # –†–∞–∑–º–µ—Ä –ø–æ–∑–∏—Ü–∏–∏ –æ—Ç 50% –¥–æ 100% –±–∞–∑–æ–≤–æ–≥–æ
    adjusted_size = base_position_size * (0.5 + 0.5 * confidence_factor)
    
    return adjusted_size