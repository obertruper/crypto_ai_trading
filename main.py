#!/usr/bin/env python3
"""
–ì–ª–∞–≤–Ω—ã–π —Å–∫—Ä–∏–ø—Ç –¥–ª—è –∑–∞–ø—É—Å–∫–∞ AI —Å–∏—Å—Ç–µ–º—ã –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è –∫—Ä–∏–ø—Ç–æ—Ñ—å—é—á–µ—Ä—Å–æ–≤
"""

import argparse
import yaml
from pathlib import Path
import torch
import pandas as pd
import numpy as np
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

from utils.logger import get_logger

def load_config(config_path: str) -> dict:
    """–ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏"""
    with open(config_path, 'r', encoding='utf-8') as f:
        return yaml.safe_load(f)

def prepare_data(config: dict, logger):
    """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è"""
    logger.start_stage("data_preparation")
    
    logger.info("üì• –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ PostgreSQL...")
    
    # –ò–º–ø–æ—Ä—Ç –∑–¥–µ—Å—å –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è —Ü–∏–∫–ª–∏—á–µ—Å–∫–∏—Ö –∏–º–ø–æ—Ä—Ç–æ–≤
    from data.data_loader import CryptoDataLoader
    from data.feature_engineering import FeatureEngineer
    from data.dataset import create_datasets
    
    data_loader = CryptoDataLoader(config)
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–µ 5 —Å–∏–º–≤–æ–ª–æ–≤ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
    raw_data = data_loader.load_data(
        symbols=config['data']['symbols'][:5],
        start_date=config['data']['start_date'],
        end_date=config['data']['end_date']
    )
    
    logger.info("üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –¥–∞–Ω–Ω—ã—Ö...")
    quality_report = data_loader.validate_data_quality(raw_data)
    
    for symbol, report in quality_report.items():
        if report['anomalies']:
            logger.warning(f"–ê–Ω–æ–º–∞–ª–∏–∏ –≤ –¥–∞–Ω–Ω—ã—Ö {symbol}: {report['anomalies']}")
    
    logger.info("üõ†Ô∏è –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤...")
    feature_engineer = FeatureEngineer(config)
    featured_data = feature_engineer.create_features(raw_data)
    
    logger.info("‚úÇÔ∏è –°–æ–∑–¥–∞–Ω–∏–µ datasets...")
    train_dataset, val_dataset, test_dataset = create_datasets(
        featured_data, 
        config,
        train_ratio=config['data']['train_ratio'],
        val_ratio=config['data']['val_ratio']
    )
    
    logger.info(f"üìä –†–∞–∑–º–µ—Ä—ã datasets:")
    logger.info(f"   - Train: {len(train_dataset)} –æ–±—Ä–∞–∑—Ü–æ–≤")
    logger.info(f"   - Val: {len(val_dataset)} –æ–±—Ä–∞–∑—Ü–æ–≤")
    logger.info(f"   - Test: {len(test_dataset)} –æ–±—Ä–∞–∑—Ü–æ–≤")
    
    logger.end_stage("data_preparation", 
                    train_size=len(train_dataset),
                    val_size=len(val_dataset),
                    test_size=len(test_dataset))
    
    return train_dataset, val_dataset, test_dataset

def train_model(config: dict, train_dataset, val_dataset, logger):
    """–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏"""
    logger.start_stage("model_training")
    
    logger.info("üèóÔ∏è –°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ PatchTST...")
    
    # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –¥–∞–Ω–Ω—ã—Ö
    n_features = len(train_dataset.get_feature_names())
    n_targets = len(train_dataset.get_target_names())
    
    logger.info(f"üìä –í—Ö–æ–¥–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏: {n_features}, –¶–µ–ª–µ–≤—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ: {n_targets}")
    
    # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω—É—é –º–æ–¥–µ–ª—å
    from models.patchtst import PatchTSTForPrediction
    
    model = PatchTSTForPrediction(
        c_in=n_features,
        c_out=n_targets,
        context_window=config['model']['context_window'],
        target_window=config['model']['pred_len'],
        patch_len=config['model']['patch_len'],
        stride=config['model']['stride'],
        n_layers=config['model']['e_layers'],
        d_model=config['model']['d_model'],
        n_heads=config['model']['n_heads'],
        d_ff=config['model']['d_ff'],
        dropout=config['model']['dropout']
    )
    
    # –°–æ–∑–¥–∞–Ω–∏–µ —Ç—Ä–µ–π–Ω–µ—Ä–∞
    from training.trainer import Trainer
    trainer = Trainer(model, config)
    
    # –°–æ–∑–¥–∞–Ω–∏–µ DataLoader'–æ–≤
    from torch.utils.data import DataLoader
    
    train_loader = DataLoader(
        train_dataset,
        batch_size=config['model']['batch_size'],
        shuffle=True,
        num_workers=config['performance'].get('num_workers', 4),
        pin_memory=True
    )
    
    val_loader = DataLoader(
        val_dataset,
        batch_size=config['model']['batch_size'],
        shuffle=False,
        num_workers=config['performance'].get('num_workers', 4),
        pin_memory=True
    )
    
    # –û–±—É—á–µ–Ω–∏–µ
    logger.info("üöÄ –ù–∞—á–∞–ª–æ –æ–±—É—á–µ–Ω–∏—è...")
    training_results = trainer.train(
        train_loader=train_loader,
        val_loader=val_loader
    )
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏
    best_model_path = trainer.checkpoint_dir / "best_model.pth"
    
    logger.info(f"‚úÖ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ. –õ—É—á—à–∞—è –º–æ–¥–µ–ª—å: {best_model_path}")
    
    logger.end_stage("model_training", model_path=str(best_model_path))
    
    return model, best_model_path, train_dataset

def backtest_strategy(config: dict, model, test_dataset, train_dataset, logger):
    """–ë—ç–∫—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏"""
    logger.start_stage("backtesting")
    
    logger.info("üí∞ –ó–∞–ø—É—Å–∫ –±—ç–∫—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è...")
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ —Ç–æ—Ä–≥–æ–≤–ª–∏
    from trading.risk_manager import RiskManager
    from trading.signals import SignalGenerator
    from trading.backtester import Backtester
    
    risk_manager = RiskManager(config)
    signal_generator = SignalGenerator(config)
    backtester = Backtester(config)
    
    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –º–æ–¥–µ–ª–∏ (—Ñ–∏–∫—Ç–∏–≤–Ω—ã—Ö –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏)
    logger.info("üîÆ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –º–æ–¥–µ–ª–∏...")
    
    # –°–æ–∑–¥–∞–µ–º —Ñ–∏–∫—Ç–∏–≤–Ω—ã–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
    n_samples = len(test_dataset)
    predictions = {
        'price_pred': np.random.random((n_samples, config['model']['pred_len'], len(train_dataset.get_target_names()))),
        'confidence': np.random.uniform(0.5, 0.9, n_samples)
    }
    
    # –°–æ–∑–¥–∞–µ–º —Ñ–∏–∫—Ç–∏–≤–Ω—ã–µ —Ä—ã–Ω–æ—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏
    test_data = pd.DataFrame({
        'datetime': pd.date_range('2025-01-01', periods=n_samples, freq='15min'),
        'symbol': np.random.choice(['BTCUSDT', 'ETHUSDT'], n_samples),
        'close': np.random.uniform(30000, 70000, n_samples),
        'volume': np.random.uniform(1000, 10000, n_samples)
    })
    
    # –ó–∞–ø—É—Å–∫ –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥–∞
    logger.info("üèÉ –ó–∞–ø—É—Å–∫ –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥–∞...")
    backtest_results = backtester.run_backtest(
        market_data=test_data,
        features=test_data,  # –£–ø—Ä–æ—â–µ–Ω–∏–µ –¥–ª—è –¥–µ–º–æ
        model_predictions=predictions
    )
    
    # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    logger.info("üìà –†–ï–ó–£–õ–¨–¢–ê–¢–´ –ë–≠–ö–¢–ï–°–¢–ò–ù–ì–ê:")
    logger.info(f"  –ù–∞—á–∞–ª—å–Ω—ã–π –∫–∞–ø–∏—Ç–∞–ª: ${backtest_results['initial_capital']:,.2f}")
    logger.info(f"  –§–∏–Ω–∞–ª—å–Ω—ã–π –∫–∞–ø–∏—Ç–∞–ª: ${backtest_results['final_capital']:,.2f}")
    logger.info(f"  –û–±—â–∞—è –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å: {backtest_results['total_return_pct']:.2f}%")
    logger.info(f"  –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –®–∞—Ä–ø–∞: {backtest_results['sharpe_ratio']:.2f}")
    logger.info(f"  –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –ø—Ä–æ—Å–∞–¥–∫–∞: {backtest_results['max_drawdown_pct']:.2f}%")
    logger.info(f"  Win Rate: {backtest_results['win_rate_pct']:.2f}%")
    logger.info(f"  –í—Å–µ–≥–æ —Å–¥–µ–ª–æ–∫: {backtest_results['total_trades']}")
    
    logger.end_stage("backtesting", 
                    total_return=backtest_results['total_return_pct'],
                    sharpe_ratio=backtest_results['sharpe_ratio'])
    
    return backtest_results

def analyze_results(config: dict, results: dict, logger):
    """–ê–Ω–∞–ª–∏–∑ –∏ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"""
    logger.start_stage("results_analysis")
    
    logger.info("üìä –ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤...")
    
    min_sharpe = config['validation']['min_sharpe_ratio']
    min_win_rate = config['validation']['min_win_rate']
    max_dd = config['validation']['max_drawdown']
    
    passed_validation = True
    
    if results['sharpe_ratio'] < min_sharpe:
        logger.warning(f"‚ö†Ô∏è Sharpe Ratio ({results['sharpe_ratio']:.2f}) –Ω–∏–∂–µ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–≥–æ ({min_sharpe})")
        passed_validation = False
    
    if results['win_rate'] < min_win_rate:
        logger.warning(f"‚ö†Ô∏è Win Rate ({results['win_rate']:.2%}) –Ω–∏–∂–µ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–≥–æ ({min_win_rate:.2%})")
        passed_validation = False
    
    if abs(results['max_drawdown']) > max_dd:
        logger.warning(f"‚ö†Ô∏è Max Drawdown ({results['max_drawdown']:.2%}) –ø—Ä–µ–≤—ã—à–∞–µ—Ç –ª–∏–º–∏—Ç ({max_dd:.2%})")
        passed_validation = False
    
    if passed_validation:
        logger.info("‚úÖ –í—Å–µ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ç–µ—Å—Ç—ã –ø—Ä–æ–π–¥–µ–Ω—ã!")
    else:
        logger.warning("‚ùå –ù–µ–∫–æ—Ç–æ—Ä—ã–µ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ç–µ—Å—Ç—ã –Ω–µ –ø—Ä–æ–π–¥–µ–Ω—ã")
    
    logger.end_stage("results_analysis", validation_passed=passed_validation)
    
    return passed_validation

def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    parser = argparse.ArgumentParser(description='Crypto AI Trading System')
    parser.add_argument('--config', type=str, default='config/config.yaml',
                       help='–ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏')
    parser.add_argument('--mode', type=str, default='full',
                       choices=['data', 'train', 'backtest', 'full', 'demo'],
                       help='–†–µ–∂–∏–º —Ä–∞–±–æ—Ç—ã')
    parser.add_argument('--model-path', type=str, default=None,
                       help='–ü—É—Ç—å –∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ (–¥–ª—è —Ä–µ–∂–∏–º–∞ backtest)')
    
    args = parser.parse_args()
    
    config = load_config(args.config)
    
    logger = get_logger("CryptoAI")
    
    logger.info("="*80)
    logger.info("üöÄ –ó–∞–ø—É—Å–∫ Crypto AI Trading System")
    logger.info(f"üìã –†–µ–∂–∏–º: {args.mode}")
    logger.info(f"‚öôÔ∏è –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è: {args.config}")
    logger.info("="*80)
    
    try:
        if args.mode in ['data', 'full']:
            train_dataset, val_dataset, test_dataset = prepare_data(config, logger)
        
        if args.mode in ['train', 'full']:
            if args.mode == 'train':
                # –ó–∞–≥—Ä—É–∑–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
                logger.error("–†–µ–∂–∏–º 'train' —Ç—Ä–µ–±—É–µ—Ç –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ–≥–æ –∑–∞–ø—É—Å–∫–∞ 'data'")
                return
            
            model, model_path, train_dataset = train_model(config, train_dataset, val_dataset, logger)
        
        if args.mode in ['backtest', 'full']:
            if args.mode == 'backtest':
                if not args.model_path:
                    logger.error("–ù–µ–æ–±—Ö–æ–¥–∏–º–æ —É–∫–∞–∑–∞—Ç—å --model-path –¥–ª—è —Ä–µ–∂–∏–º–∞ backtest")
                    return
                
                logger.info(f"üì• –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏: {args.model_path}")
                # –ó–¥–µ—Å—å –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –∑–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
                
            results = backtest_strategy(config, model, test_dataset, train_dataset, logger)
            
            validation_passed = analyze_results(config, results, logger)
        
        if args.mode == 'demo':
            logger.info("üéØ –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–æ–Ω–Ω—ã–π —Ä–µ–∂–∏–º - —Ç–æ–ª—å–∫–æ –ø—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –ë–î")
            from data.data_loader import CryptoDataLoader
            
            data_loader = CryptoDataLoader(config)
            available_symbols = data_loader.get_available_symbols()
            
            logger.info(f"‚úÖ –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –ë–î —É—Å–ø–µ—à–Ω–æ")
            logger.info(f"üìä –ù–∞–π–¥–µ–Ω–æ {len(available_symbols)} —Å–∏–º–≤–æ–ª–æ–≤")
            logger.info(f"üîç –ü–µ—Ä–≤—ã–µ 10 —Å–∏–º–≤–æ–ª–æ–≤: {available_symbols[:10]}")
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –Ω–µ–±–æ–ª—å—à–æ–π –æ–±—Ä–∞–∑–µ—Ü –¥–∞–Ω–Ω—ã—Ö
            sample_data = data_loader.load_data(
                symbols=available_symbols[:2],
                start_date="2025-06-01",
                end_date="2025-06-16"
            )
            
            logger.info(f"üìà –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(sample_data)} –∑–∞–ø–∏—Å–µ–π –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏")
        
        logger.info("="*80)
        logger.info("‚úÖ –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ —É—Å–ø–µ—à–Ω–æ!")
        logger.info("="*80)
        
    except Exception as e:
        logger.log_error(e, "main")
        logger.critical("‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞! –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –ø—Ä–µ—Ä–≤–∞–Ω–æ.")
        raise

if __name__ == "__main__":
    main()