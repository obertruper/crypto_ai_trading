#!/usr/bin/env python3
"""
Crypto AI Trading System - –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è —Ç–æ—á–∫–∞ –≤—Ö–æ–¥–∞
–ó–∞—â–∏—Ç–∞ –æ—Ç –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è –≤—Å—Ç—Ä–æ–µ–Ω–∞ –≤ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É
"""

import argparse
import yaml
from pathlib import Path
import torch
import pandas as pd
import numpy as np
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

from utils.logger import get_logger

# –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è GPU –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω
if torch.cuda.is_available():
    torch.backends.cudnn.benchmark = True
    torch.backends.cudnn.enabled = True
    # –£—Å—Ç–∞–Ω–æ–≤–∫–∞ float32 matmul precision –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è –Ω–∞ –Ω–æ–≤—ã—Ö GPU
    torch.set_float32_matmul_precision('high')
    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –¥–ª—è Ampere+ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã (RTX 5090)
    torch.backends.cuda.matmul.allow_tf32 = True
    torch.backends.cudnn.allow_tf32 = True

# –í–µ—Ä—Å–∏—è —Å–∏—Å—Ç–µ–º—ã
__version__ = "2.0.0"

def load_config(config_path: str) -> dict:
    """–ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏"""
    with open(config_path, 'r', encoding='utf-8') as f:
        return yaml.safe_load(f)

def load_cached_data_if_exists(logger) -> tuple:
    """–¶–µ–Ω—Ç—Ä–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    
    Returns:
        tuple: (train_data, val_data, test_data, feature_cols, target_cols) –∏–ª–∏ (None, None, None, None, None)
    """
    logger.info("üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö...")
    
    processed_dir = Path("data/processed")
    train_file = processed_dir / "train_data.parquet"
    val_file = processed_dir / "val_data.parquet"
    test_file = processed_dir / "test_data.parquet"
    
    if all(f.exists() for f in [train_file, val_file, test_file]):
        logger.info("‚úÖ –ù–∞–π–¥–µ–Ω—ã –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ, –∑–∞–≥—Ä—É–∂–∞–µ–º...")
        
        train_data = pd.read_parquet(train_file)
        val_data = pd.read_parquet(val_file)
        test_data = pd.read_parquet(test_file)
        
        logger.info(f"üìä –†–∞–∑–º–µ—Ä—ã –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö:")
        logger.info(f"   - Train: {len(train_data):,} –∑–∞–ø–∏—Å–µ–π")
        logger.info(f"   - Val: {len(val_data):,} –∑–∞–ø–∏—Å–µ–π")
        logger.info(f"   - Test: {len(test_data):,} –∑–∞–ø–∏—Å–µ–π")
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏ —Ü–µ–ª–µ–≤—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –∏–∑ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        from data.constants import (
            get_feature_columns, get_target_columns, 
            validate_data_structure, TRADING_TARGET_VARIABLES
        )
        
        try:
            data_info = validate_data_structure(train_data)
            feature_cols = data_info['feature_cols']
            target_cols = data_info['target_cols']
            
            logger.info(f"üìà –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö:")
            logger.info(f"   - –í—Å–µ–≥–æ –∫–æ–ª–æ–Ω–æ–∫: {len(train_data.columns)}")
            logger.info(f"   - –ü—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –º–æ–¥–µ–ª–∏: {len(feature_cols)}")
            logger.info(f"   - –¶–µ–ª–µ–≤—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö: {len(target_cols)}")
            logger.info(f"   - –°–ª—É–∂–µ–±–Ω—ã—Ö –∫–æ–ª–æ–Ω–æ–∫: {len(train_data.columns) - len(feature_cols) - len(target_cols)}")
            
            return train_data, val_data, test_data, feature_cols, target_cols
            
        except ValueError as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö: {e}")
            return None, None, None, None, None
    else:
        logger.info("‚ùå –ö—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
        missing_files = [f.name for f in [train_file, val_file, test_file] if not f.exists()]
        logger.info(f"   –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç —Ñ–∞–π–ª—ã: {missing_files}")
        return None, None, None, None, None

def create_unified_data_loaders(train_data, val_data, test_data, feature_cols, target_cols, config, logger):
    """–£–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Å–æ–∑–¥–∞–Ω–∏–µ DataLoader'–æ–≤ –¥–ª—è –≤—Å–µ—Ö —Ä–µ–∂–∏–º–æ–≤
    
    Args:
        train_data, val_data, test_data: DataFrame'—ã —Å –¥–∞–Ω–Ω—ã–º–∏
        feature_cols, target_cols: —Å–ø–∏—Å–∫–∏ –∫–æ–ª–æ–Ω–æ–∫
        config: –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
        logger: –ª–æ–≥–≥–µ—Ä
        
    Returns:
        tuple: (train_loader, val_loader, test_loader)
    """
    logger.info("üèóÔ∏è –°–æ–∑–¥–∞–Ω–∏–µ —É–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö DataLoader'–æ–≤...")
    
    from data.dataset import create_data_loaders
    
    # –û–±–Ω–æ–≤–ª—è–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é —á—Ç–æ–±—ã —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–æ–≤–∞—Ç—å —Ä–µ–∞–ª—å–Ω—ã–º –¥–∞–Ω–Ω—ã–º
    config_updated = config.copy()
    config_updated['model']['input_features'] = len(feature_cols)
    config_updated['model']['n_features'] = len(feature_cols)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö —Å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π –º–æ–¥–µ–ª–∏
    task_type = config['model'].get('task_type', 'regression')
    
    if task_type == 'trading':
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –í–°–ï –¥–æ—Å—Ç—É–ø–Ω—ã–µ —Ç–æ—Ä–≥–æ–≤—ã–µ —Ü–µ–ª–µ–≤—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –∏–∑ –∫—ç—à–∞
        config_updated['model']['target_variables'] = target_cols
        logger.info(f"‚úÖ –¢–æ—Ä–≥–æ–≤–∞—è –º–æ–¥–µ–ª—å: –∏—Å–ø–æ–ª—å–∑—É–µ–º –≤—Å–µ {len(target_cols)} —Ü–µ–ª–µ–≤—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö")
        logger.info(f"   –ü–µ—Ä–≤—ã–µ 5 –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö: {target_cols[:5]}")
    else:
        # –î–ª—è —Ä–µ–≥—Ä–µ—Å—Å–∏–∏ –≤—ã–±–∏—Ä–∞–µ–º –æ—Å–Ω–æ–≤–Ω—É—é —Ü–µ–ª–µ–≤—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é
        main_target = [col for col in target_cols if col.startswith('future_return_')]
        if main_target:
            config_updated['model']['target_variable'] = main_target[0]
            logger.info(f"‚úÖ –†–µ–≥—Ä–µ—Å—Å–∏—è: –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ü–µ–ª–µ–≤—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é {main_target[0]}")
        else:
            logger.error("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–∞ —Ü–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è –¥–ª—è —Ä–µ–≥—Ä–µ—Å—Å–∏–∏!")
            raise ValueError("–ù–µ—Ç –ø–æ–¥—Ö–æ–¥—è—â–µ–π —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –¥–ª—è —Ä–µ–≥—Ä–µ—Å—Å–∏–∏")
    
    # –°–æ–∑–¥–∞–Ω–∏–µ DataLoader'–æ–≤ —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
    train_loader, val_loader, test_loader = create_data_loaders(
        train_data=train_data,
        val_data=val_data, 
        test_data=test_data,
        config=config_updated,
        feature_cols=feature_cols,
        target_cols=target_cols
    )
    
    logger.info("‚úÖ DataLoader'—ã —Å–æ–∑–¥–∞–Ω—ã —É—Å–ø–µ—à–Ω–æ")
    return train_loader, val_loader, test_loader, config_updated

def prepare_data(config: dict, logger):
    """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è —Å –∑–∞—â–∏—Ç–æ–π –æ—Ç data leakage"""
    logger.start_stage("data_preparation")
    
    logger.info("üì• –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ PostgreSQL...")
    
    # –ò–º–ø–æ—Ä—Ç –∑–¥–µ—Å—å –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è —Ü–∏–∫–ª–∏—á–µ—Å–∫–∏—Ö –∏–º–ø–æ—Ä—Ç–æ–≤
    from data.data_loader import CryptoDataLoader
    from data.feature_engineering import FeatureEngineer
    from data.dataset import create_data_loaders, TradingDataset
    
    data_loader = CryptoDataLoader(config)
    
    # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ —Å–∏–º–≤–æ–ª–æ–≤
    if config['data']['symbols'] == 'all':
        available_symbols = data_loader.get_available_symbols()
        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–∏–º–≤–æ–ª–æ–≤ –¥–ª—è –¥–µ–º–æ
        max_symbols = config.get('data', {}).get('max_symbols', 10)
        symbols_to_load = available_symbols[:max_symbols]
        logger.info(f"üìä –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–≤—ã–µ {max_symbols} —Å–∏–º–≤–æ–ª–æ–≤ –∏–∑ {len(available_symbols)}: {symbols_to_load}")
    else:
        symbols_to_load = config['data']['symbols']
        logger.info(f"üìä –ó–∞–≥—Ä—É–∂–∞–µ–º —É–∫–∞–∑–∞–Ω–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã: {symbols_to_load}")
    
    raw_data = data_loader.load_data(
        symbols=symbols_to_load,
        start_date=config['data']['start_date'],
        end_date=config['data']['end_date']
    )
    
    logger.info("üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –¥–∞–Ω–Ω—ã—Ö...")
    quality_report = data_loader.validate_data_quality(raw_data)
    
    for symbol, report in quality_report.items():
        if report['anomalies']:
            logger.warning(f"–ê–Ω–æ–º–∞–ª–∏–∏ –≤ –¥–∞–Ω–Ω—ã—Ö {symbol}: {report['anomalies']}")
    
    logger.info("üõ†Ô∏è –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å –∑–∞—â–∏—Ç–æ–π –æ—Ç data leakage...")
    feature_engineer = FeatureEngineer(config)
    
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–æ–≤—ã–π –º–µ—Ç–æ–¥ —Å –∑–∞—â–∏—Ç–æ–π –æ—Ç data leakage
    train_data, val_data, test_data = feature_engineer.create_features_with_train_split(
        raw_data,
        train_ratio=config['data']['train_ratio'],
        val_ratio=config['data']['val_ratio']
    )
    
    logger.info("üèóÔ∏è –°–æ–∑–¥–∞–Ω–∏–µ datasets...")
    
    # –°–æ–∑–¥–∞–Ω–∏–µ DataLoader'–æ–≤ —á–µ—Ä–µ–∑ —É–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—É—é —Å–∏—Å—Ç–µ–º—É
    from data.constants import get_feature_columns, get_target_columns, validate_data_structure
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–∞–Ω–Ω—ã—Ö
    data_info = validate_data_structure(train_data)
    feature_cols = data_info['feature_cols']
    target_cols = data_info['target_cols']
    
    train_loader, val_loader, test_loader, _ = create_unified_data_loaders(
        train_data, val_data, test_data, feature_cols, target_cols, config, logger
    )
    
    logger.info(f"üìä –†–∞–∑–º–µ—Ä—ã datasets:")
    logger.info(f"   - Train: {len(train_data)} –∑–∞–ø–∏—Å–µ–π")
    logger.info(f"   - Val: {len(val_data)} –∑–∞–ø–∏—Å–µ–π")
    logger.info(f"   - Test: {len(test_data)} –∑–∞–ø–∏—Å–µ–π")
    
    logger.end_stage("data_preparation", 
                    train_size=len(train_data),
                    val_size=len(val_data),
                    test_size=len(test_data))
    
    return train_loader, val_loader, test_loader

def train_model(config: dict, train_loader, val_loader, logger):
    """–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏"""
    logger.start_stage("model_training")
    
    logger.info("üèóÔ∏è –°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ PatchTST...")
    
    # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –¥–∞–Ω–Ω—ã—Ö –∏–∑ –ø–µ—Ä–≤–æ–≥–æ –±–∞—Ç—á–∞
    sample_batch = next(iter(train_loader))
    X_sample, y_sample, _ = sample_batch
    
    n_features = X_sample.shape[-1]  # –ü–æ—Å–ª–µ–¥–Ω—è—è —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å
    n_targets = y_sample.shape[-1] if y_sample is not None else 1
    
    logger.info(f"üìä –í—Ö–æ–¥–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏: {n_features}, –¶–µ–ª–µ–≤—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ: {n_targets}")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π
    config_input_size = config['model'].get('input_size', 100)
    config_output_size = config['model'].get('output_size', 1)
    task_type = config['model'].get('task_type', 'regression')
    
    if n_features != config_input_size:
        logger.warning(f"‚ö†Ô∏è –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –Ω–µ —Å–æ–≤–ø–∞–¥–∞–µ—Ç: –¥–∞–Ω–Ω—ã–µ={n_features}, –∫–æ–Ω—Ñ–∏–≥={config_input_size}")
        logger.info(f"üîß –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–±–Ω–æ–≤–ª—è–µ–º input_size –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏")
        config['model']['input_size'] = n_features
    
    if task_type == 'trading':
        # –î–ª—è —Ç–æ—Ä–≥–æ–≤–æ–π –º–æ–¥–µ–ª–∏ —Å –±–æ–ª—å—à–∏–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º —Ü–µ–ª–µ–π –∏—Å–ø–æ–ª—å–∑—É–µ–º –±–∞–∑–æ–≤—É—é –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É
        if config['model']['name'] == 'UnifiedPatchTST':  # –ò—Å–ø–æ–ª—å–∑—É–µ–º —É–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—É—é –º–æ–¥–µ–ª—å
            logger.info(f"üìä –¢–æ—Ä–≥–æ–≤–∞—è –º–æ–¥–µ–ª—å: {n_targets} —Ü–µ–ª–µ–≤—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö - –∏—Å–ø–æ–ª—å–∑—É–µ–º –≥–∏–±–∫—É—é –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É")
            config['model']['output_size'] = n_targets
        else:
            logger.info(f"üìä –¢–æ—Ä–≥–æ–≤–∞—è –º–æ–¥–µ–ª—å: –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è PatchTSTForTrading —Å –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ –≤—ã—Ö–æ–¥–∞–º–∏")
    else:
        if n_targets != config_output_size:
            logger.warning(f"‚ö†Ô∏è –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å —Ü–µ–ª–µ–π –Ω–µ —Å–æ–≤–ø–∞–¥–∞–µ—Ç: –¥–∞–Ω–Ω—ã–µ={n_targets}, –∫–æ–Ω—Ñ–∏–≥={config_output_size}")
            logger.info(f"üîß –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–±–Ω–æ–≤–ª—è–µ–º output_size –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏")
            config['model']['output_size'] = n_targets
    
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ñ–∞–±—Ä–∏–∫—É –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏
    from models.patchtst import create_patchtst_model
    from models.patchtst_unified import create_unified_model, UnifiedPatchTSTForTrading
    
    # –ö–†–ò–¢–ò–ß–ï–°–ö–û–ï –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –í—Å–µ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑—É–µ–º UnifiedPatchTST –¥–ª—è 36 —Ü–µ–ª–µ–≤—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö
    if task_type == 'trading' and n_targets > 10:
        logger.info(f"üéØ –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ {n_targets} —Ü–µ–ª–µ–≤—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö - –∏—Å–ø–æ–ª—å–∑—É–µ–º UnifiedPatchTST")
        config['model']['name'] = 'UnifiedPatchTST'
        config['model']['output_size'] = n_targets
        model = create_unified_model(config)
        # –ò–°–ü–†–ê–í–õ–ï–ù–û: torch.compile —Å–æ–∑–¥–∞–µ—Ç CPU worker'—ã, –æ—Ç–∫–ª—é—á–∞–µ–º –¥–ª—è –ø—Ä—è–º–æ–≥–æ GPU –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
        # model = torch.compile(model, backend="inductor")
        logger.info("‚úÖ UnifiedPatchTST —Å–æ–∑–¥–∞–Ω —Å 36 –≤—ã—Ö–æ–¥–∞–º–∏ –¥–ª—è —Ç–æ—Ä–≥–æ–≤–æ–π –º–æ–¥–µ–ª–∏")
        logger.info("‚ö†Ô∏è torch.compile –æ—Ç–∫–ª—é—á–µ–Ω - –ø—Ä—è–º–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ GPU")
    elif config['model']['name'] == 'UnifiedPatchTST':
        model = create_unified_model(config)
        # –ò–°–ü–†–ê–í–õ–ï–ù–û: torch.compile —Å–æ–∑–¥–∞–µ—Ç CPU worker'—ã, –æ—Ç–∫–ª—é—á–∞–µ–º
        # model = torch.compile(model, backend="inductor")
        logger.info("üìä –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è UnifiedPatchTST —Å 36 –≤—ã—Ö–æ–¥–∞–º–∏")
        logger.info("‚ö†Ô∏è torch.compile –æ—Ç–∫–ª—é—á–µ–Ω - –ø—Ä—è–º–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ GPU")
    else:
        model = create_patchtst_model(config)
        # –õ–æ–≥–∏—Ä—É–µ–º —Ç–∏–ø –º–æ–¥–µ–ª–∏
        if hasattr(model, 'long_model'):
            logger.info("‚úÖ –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è PatchTSTForTrading —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π LONG/SHORT")
        else:
            logger.info("üìä –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –±–∞–∑–æ–≤–∞—è PatchTSTForPrediction")
    
    # –í–ê–ñ–ù–û: –Ø–≤–Ω–æ –ø–µ—Ä–µ–º–µ—â–∞–µ–º –º–æ–¥–µ–ª—å –Ω–∞ GPU –ø–µ—Ä–µ–¥ —Å–æ–∑–¥–∞–Ω–∏–µ–º —Ç—Ä–µ–π–Ω–µ—Ä–∞
    if torch.cuda.is_available():
        device = torch.device('cuda')
        model = model.to(device)
        logger.info(f"üî• –ú–æ–¥–µ–ª—å –ø–µ—Ä–µ–º–µ—â–µ–Ω–∞ –Ω–∞ GPU: {torch.cuda.get_device_name(0)}")
        logger.info(f"üíæ GPU –ø–∞–º—è—Ç—å –¥–æ—Å—Ç—É–ø–Ω–∞: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB")
    else:
        device = torch.device('cpu')
        logger.warning("‚ö†Ô∏è GPU –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è CPU")
    
    # –°–æ–∑–¥–∞–Ω–∏–µ —Ç—Ä–µ–π–Ω–µ—Ä–∞ —Å —è–≤–Ω—ã–º —É–∫–∞–∑–∞–Ω–∏–µ–º —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞
    from training.trainer import Trainer
    trainer = Trainer(model, config, device=device)
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑–º–µ—â–µ–Ω–∏—è –º–æ–¥–µ–ª–∏
    logger.info(f"‚úÖ –ú–æ–¥–µ–ª—å –Ω–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–µ: {next(model.parameters()).device}")
    logger.info(f"‚úÖ –¢—Ä–µ–π–Ω–µ—Ä –∏—Å–ø–æ–ª—å–∑—É–µ—Ç: {trainer.device}")
    
    # DataLoader'—ã —É–∂–µ —Å–æ–∑–¥–∞–Ω—ã, –∏—Å–ø–æ–ª—å–∑—É–µ–º –∏—Ö –Ω–∞–ø—Ä—è–º—É—é
    
    # –û–±—É—á–µ–Ω–∏–µ
    logger.info("üöÄ –ù–∞—á–∞–ª–æ –æ–±—É—á–µ–Ω–∏—è...")
    training_results = trainer.train(
        train_loader=train_loader,
        val_loader=val_loader
    )
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏
    best_model_path = trainer.checkpoint_dir / "best_model.pth"
    
    logger.info(f"‚úÖ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ. –õ—É—á—à–∞—è –º–æ–¥–µ–ª—å: {best_model_path}")
    
    logger.end_stage("model_training", model_path=str(best_model_path))
    
    return model, best_model_path, train_loader

def backtest_strategy(config: dict, model, test_loader, train_loader, logger):
    """–ë—ç–∫—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏"""
    logger.start_stage("backtesting")
    
    logger.info("üí∞ –ó–∞–ø—É—Å–∫ –±—ç–∫—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è...")
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ —Ç–æ—Ä–≥–æ–≤–ª–∏
    from trading.risk_manager import RiskManager
    from trading.signals import SignalGenerator
    from trading.backtester import Backtester
    
    risk_manager = RiskManager(config)
    signal_generator = SignalGenerator(config)
    backtester = Backtester(config)
    
    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –º–æ–¥–µ–ª–∏ (—Ñ–∏–∫—Ç–∏–≤–Ω—ã—Ö –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏)
    logger.info("üîÆ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –º–æ–¥–µ–ª–∏...")
    
    # –°–æ–∑–¥–∞–µ–º —Ñ–∏–∫—Ç–∏–≤–Ω—ã–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–∞–Ω–Ω—ã—Ö
    sample_batch = next(iter(test_loader))
    X_sample, y_sample, _ = sample_batch
    
    n_samples = len(test_loader.dataset) if hasattr(test_loader, 'dataset') else 1000
    n_targets = y_sample.shape[-1] if y_sample is not None else 1
    
    predictions = {
        'price_pred': np.random.random((n_samples, config['model']['pred_len'], n_targets)),
        'confidence': np.random.uniform(0.5, 0.9, n_samples)
    }
    
    # –°–æ–∑–¥–∞–µ–º —Ñ–∏–∫—Ç–∏–≤–Ω—ã–µ —Ä—ã–Ω–æ—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏
    test_data = pd.DataFrame({
        'datetime': pd.date_range('2025-01-01', periods=n_samples, freq='15min'),
        'symbol': np.random.choice(['BTCUSDT', 'ETHUSDT'], n_samples),
        'close': np.random.uniform(30000, 70000, n_samples),
        'volume': np.random.uniform(1000, 10000, n_samples)
    })
    
    # –ó–∞–ø—É—Å–∫ –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥–∞
    logger.info("üèÉ –ó–∞–ø—É—Å–∫ –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥–∞...")
    backtest_results = backtester.run_backtest(
        market_data=test_data,
        features=test_data,  # –£–ø—Ä–æ—â–µ–Ω–∏–µ –¥–ª—è –¥–µ–º–æ
        model_predictions=predictions
    )
    
    # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    logger.info("üìà –†–ï–ó–£–õ–¨–¢–ê–¢–´ –ë–≠–ö–¢–ï–°–¢–ò–ù–ì–ê:")
    logger.info(f"  –ù–∞—á–∞–ª—å–Ω—ã–π –∫–∞–ø–∏—Ç–∞–ª: ${backtest_results['initial_capital']:,.2f}")
    logger.info(f"  –§–∏–Ω–∞–ª—å–Ω—ã–π –∫–∞–ø–∏—Ç–∞–ª: ${backtest_results['final_capital']:,.2f}")
    logger.info(f"  –û–±—â–∞—è –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å: {backtest_results['total_return_pct']:.2f}%")
    logger.info(f"  –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –®–∞—Ä–ø–∞: {backtest_results['sharpe_ratio']:.2f}")
    logger.info(f"  –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –ø—Ä–æ—Å–∞–¥–∫–∞: {backtest_results['max_drawdown_pct']:.2f}%")
    logger.info(f"  Win Rate: {backtest_results['win_rate_pct']:.2f}%")
    logger.info(f"  –í—Å–µ–≥–æ —Å–¥–µ–ª–æ–∫: {backtest_results['total_trades']}")
    
    logger.end_stage("backtesting", 
                    total_return=backtest_results['total_return_pct'],
                    sharpe_ratio=backtest_results['sharpe_ratio'])
    
    return backtest_results

def analyze_results(config: dict, results: dict, logger):
    """–ê–Ω–∞–ª–∏–∑ –∏ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"""
    logger.start_stage("results_analysis")
    
    logger.info("üìä –ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤...")
    
    min_sharpe = config['validation']['min_sharpe_ratio']
    min_win_rate = config['validation']['min_win_rate']
    max_dd = config['validation']['max_drawdown']
    
    passed_validation = True
    
    if results['sharpe_ratio'] < min_sharpe:
        logger.warning(f"‚ö†Ô∏è Sharpe Ratio ({results['sharpe_ratio']:.2f}) –Ω–∏–∂–µ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–≥–æ ({min_sharpe})")
        passed_validation = False
    
    if results['win_rate'] < min_win_rate:
        logger.warning(f"‚ö†Ô∏è Win Rate ({results['win_rate']:.2%}) –Ω–∏–∂–µ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–≥–æ ({min_win_rate:.2%})")
        passed_validation = False
    
    if abs(results['max_drawdown']) > max_dd:
        logger.warning(f"‚ö†Ô∏è Max Drawdown ({results['max_drawdown']:.2%}) –ø—Ä–µ–≤—ã—à–∞–µ—Ç –ª–∏–º–∏—Ç ({max_dd:.2%})")
        passed_validation = False
    
    if passed_validation:
        logger.info("‚úÖ –í—Å–µ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ç–µ—Å—Ç—ã –ø—Ä–æ–π–¥–µ–Ω—ã!")
    else:
        logger.warning("‚ùå –ù–µ–∫–æ—Ç–æ—Ä—ã–µ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ç–µ—Å—Ç—ã –Ω–µ –ø—Ä–æ–π–¥–µ–Ω—ã")
    
    logger.end_stage("results_analysis", validation_passed=passed_validation)
    
    return passed_validation

def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    parser = argparse.ArgumentParser(description='Crypto AI Trading System')
    parser.add_argument('--config', type=str, default='config/config.yaml',
                       help='–ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏')
    parser.add_argument('--mode', type=str, default='full',
                       choices=['data', 'train', 'backtest', 'full', 'demo', 'interactive'],
                       help='–†–µ–∂–∏–º —Ä–∞–±–æ—Ç—ã')
    parser.add_argument('--model-path', type=str, default=None,
                       help='–ü—É—Ç—å –∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ (–¥–ª—è —Ä–µ–∂–∏–º–∞ backtest)')
    parser.add_argument('--use-improved-model', action='store_true',
                       help='–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —É–ª—É—á—à–µ–Ω–Ω—É—é –≤–µ—Ä—Å–∏—é –º–æ–¥–µ–ª–∏ —Å FeatureAttention')
    parser.add_argument('--validate-only', action='store_true',
                       help='–¢–æ–ª—å–∫–æ –≤–∞–ª–∏–¥–∞—Ü–∏—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –±–µ–∑ –∑–∞–ø—É—Å–∫–∞')
    
    args = parser.parse_args()
    
    config = load_config(args.config)
    
    # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ñ–ª–∞–≥ —É–ª—É—á—à–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ –∫ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
    if args.use_improved_model:
        config['model']['use_improvements'] = True
        config['model']['feature_attention'] = True
        config['model']['multi_scale_patches'] = True
    
    logger = get_logger("CryptoAI")
    
    logger.info("="*80)
    logger.info("üöÄ –ó–∞–ø—É—Å–∫ Crypto AI Trading System")
    logger.info(f"üìã –†–µ–∂–∏–º: {args.mode}")
    logger.info(f"‚öôÔ∏è –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è: {args.config}")
    if args.use_improved_model:
        logger.info("üî• –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —É–ª—É—á—à–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å —Å FeatureAttention")
    logger.info("="*80)
    
    # –í–∞–ª–∏–¥–∞—Ü–∏—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
    if args.validate_only:
        logger.info("üîç –†–µ–∂–∏–º –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏...")
        from utils.config_validator import validate_config
        is_valid = validate_config(config)
        if is_valid:
            logger.info("‚úÖ –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –≤–∞–ª–∏–¥–Ω–∞!")
        else:
            logger.error("‚ùå –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Å–æ–¥–µ—Ä–∂–∏—Ç –æ—à–∏–±–∫–∏!")
        return
    
    # –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π —Ä–µ–∂–∏–º
    if args.mode == 'interactive':
        logger.info("üéÆ –ó–∞–ø—É—Å–∫ –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ–≥–æ —Ä–µ–∂–∏–º–∞...")
        from run_interactive import run_interactive_mode
        run_interactive_mode(config)
        return
    
    try:
        # –¶–µ–Ω—Ç—Ä–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –≤—Å–µ—Ö —Ä–µ–∂–∏–º–æ–≤
        train_data, val_data, test_data, feature_cols, target_cols = None, None, None, None, None
        train_loader, val_loader, test_loader = None, None, None
        config_updated = config.copy()
        
        if args.mode in ['data', 'train', 'full']:
            # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
            train_data, val_data, test_data, feature_cols, target_cols = load_cached_data_if_exists(logger)
            
            if train_data is not None:
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
                logger.info("üéØ –ò—Å–ø–æ–ª—å–∑—É–µ–º –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –≤—Å–µ—Ö —Ä–µ–∂–∏–º–æ–≤")
                train_loader, val_loader, test_loader, config_updated = create_unified_data_loaders(
                    train_data, val_data, test_data, feature_cols, target_cols, config, logger
                )
            elif args.mode in ['data', 'full']:
                # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –∏—Ö –Ω–µ—Ç –∏ —ç—Ç–æ —Ä–µ–∂–∏–º data/full
                logger.info("üîÑ –ö—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã, —Å–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–µ...")
                train_loader, val_loader, test_loader = prepare_data(config, logger)
                config_updated = config  # –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—É—é –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
            else:
                # –†–µ–∂–∏–º train –±–µ–∑ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
                logger.error("‚ùå –†–µ–∂–∏–º train —Ç—Ä–µ–±—É–µ—Ç –Ω–∞–ª–∏—á–∏—è –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö!")
                logger.error("–ó–∞–ø—É—Å—Ç–∏—Ç–µ —Å–Ω–∞—á–∞–ª–∞: python prepare_trading_data.py")
                return
        
        if args.mode in ['train', 'full']:
            # –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ —Å —É–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π
            model, model_path, train_loader = train_model(config_updated, train_loader, val_loader, logger)
        
        if args.mode in ['backtest', 'full']:
            if args.mode == 'backtest':
                if not args.model_path:
                    logger.error("–ù–µ–æ–±—Ö–æ–¥–∏–º–æ —É–∫–∞–∑–∞—Ç—å --model-path –¥–ª—è —Ä–µ–∂–∏–º–∞ backtest")
                    return
                
                logger.info(f"üì• –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏: {args.model_path}")
                # –ó–¥–µ—Å—å –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –∑–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
                
            results = backtest_strategy(config, model, test_loader, train_loader, logger)
            
            validation_passed = analyze_results(config, results, logger)
        
        if args.mode == 'demo':
            logger.info("üéØ –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–æ–Ω–Ω—ã–π —Ä–µ–∂–∏–º - —Ç–æ–ª—å–∫–æ –ø—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –ë–î")
            from data.data_loader import CryptoDataLoader
            
            data_loader = CryptoDataLoader(config)
            available_symbols = data_loader.get_available_symbols()
            
            logger.info(f"‚úÖ –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –ë–î —É—Å–ø–µ—à–Ω–æ")
            logger.info(f"üìä –ù–∞–π–¥–µ–Ω–æ {len(available_symbols)} —Å–∏–º–≤–æ–ª–æ–≤")
            logger.info(f"üîç –ü–µ—Ä–≤—ã–µ 10 —Å–∏–º–≤–æ–ª–æ–≤: {available_symbols[:10]}")
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –Ω–µ–±–æ–ª—å—à–æ–π –æ–±—Ä–∞–∑–µ—Ü –¥–∞–Ω–Ω—ã—Ö
            sample_data = data_loader.load_data(
                symbols=available_symbols[:2],
                start_date="2025-06-01",
                end_date="2025-06-16"
            )
            
            logger.info(f"üìà –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(sample_data)} –∑–∞–ø–∏—Å–µ–π –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏")
        
        logger.info("="*80)
        logger.info("‚úÖ –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ —É—Å–ø–µ—à–Ω–æ!")
        logger.info("="*80)
        
    except Exception as e:
        logger.log_error(e, "main")
        logger.critical("‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞! –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –ø—Ä–µ—Ä–≤–∞–Ω–æ.")
        raise

if __name__ == "__main__":
    main()