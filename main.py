#!/usr/bin/env python3
"""
Crypto AI Trading System - –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è —Ç–æ—á–∫–∞ –≤—Ö–æ–¥–∞
–ó–∞—â–∏—Ç–∞ –æ—Ç –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è –≤—Å—Ç—Ä–æ–µ–Ω–∞ –≤ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É
"""

import argparse
import yaml
from pathlib import Path
import torch
import pandas as pd
import numpy as np
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

from utils.logger import get_logger

# –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è GPU –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω
if torch.cuda.is_available():
    torch.backends.cudnn.benchmark = True
    torch.backends.cudnn.enabled = True
    # –£—Å—Ç–∞–Ω–æ–≤–∫–∞ float32 matmul precision –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è –Ω–∞ –Ω–æ–≤—ã—Ö GPU
    torch.set_float32_matmul_precision('high')
    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –¥–ª—è Ampere+ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã (RTX 5090)
    torch.backends.cuda.matmul.allow_tf32 = True
    torch.backends.cudnn.allow_tf32 = True

# –í–µ—Ä—Å–∏—è —Å–∏—Å—Ç–µ–º—ã
__version__ = "2.0.0"

def load_config(config_path: str) -> dict:
    """–ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏"""
    with open(config_path, 'r', encoding='utf-8') as f:
        return yaml.safe_load(f)

def load_cached_data_if_exists(logger) -> tuple:
    """–¶–µ–Ω—Ç—Ä–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    
    Returns:
        tuple: (train_data, val_data, test_data, feature_cols, target_cols) –∏–ª–∏ (None, None, None, None, None)
    """
    logger.info("üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö...")
    
    processed_dir = Path("data/processed")
    train_file = processed_dir / "train_data.parquet"
    val_file = processed_dir / "val_data.parquet"
    test_file = processed_dir / "test_data.parquet"
    
    if all(f.exists() for f in [train_file, val_file, test_file]):
        logger.info("‚úÖ –ù–∞–π–¥–µ–Ω—ã –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ, –∑–∞–≥—Ä—É–∂–∞–µ–º...")
        
        train_data = pd.read_parquet(train_file)
        val_data = pd.read_parquet(val_file)
        test_data = pd.read_parquet(test_file)
        
        logger.info(f"üìä –†–∞–∑–º–µ—Ä—ã –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö:")
        logger.info(f"   - Train: {len(train_data):,} –∑–∞–ø–∏—Å–µ–π")
        logger.info(f"   - Val: {len(val_data):,} –∑–∞–ø–∏—Å–µ–π")
        logger.info(f"   - Test: {len(test_data):,} –∑–∞–ø–∏—Å–µ–π")
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏ —Ü–µ–ª–µ–≤—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –∏–∑ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        from data.constants import (
            get_feature_columns, get_target_columns, 
            validate_data_structure, TRADING_TARGET_VARIABLES
        )
        
        try:
            data_info = validate_data_structure(train_data)
            feature_cols = data_info['feature_cols']
            target_cols = data_info['target_cols']
            
            logger.info(f"üìà –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö:")
            logger.info(f"   - –í—Å–µ–≥–æ –∫–æ–ª–æ–Ω–æ–∫: {len(train_data.columns)}")
            logger.info(f"   - –ü—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –º–æ–¥–µ–ª–∏: {len(feature_cols)}")
            logger.info(f"   - –¶–µ–ª–µ–≤—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö: {len(target_cols)}")
            logger.info(f"   - –°–ª—É–∂–µ–±–Ω—ã—Ö –∫–æ–ª–æ–Ω–æ–∫: {len(train_data.columns) - len(feature_cols) - len(target_cols)}")
            
            return train_data, val_data, test_data, feature_cols, target_cols
            
        except ValueError as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö: {e}")
            return None, None, None, None, None
    else:
        logger.info("‚ùå –ö—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
        missing_files = [f.name for f in [train_file, val_file, test_file] if not f.exists()]
        logger.info(f"   –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç —Ñ–∞–π–ª—ã: {missing_files}")
        return None, None, None, None, None

def create_unified_data_loaders(train_data, val_data, test_data, feature_cols, target_cols, config, logger):
    """–£–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Å–æ–∑–¥–∞–Ω–∏–µ DataLoader'–æ–≤ –¥–ª—è –≤—Å–µ—Ö —Ä–µ–∂–∏–º–æ–≤
    
    Args:
        train_data, val_data, test_data: DataFrame'—ã —Å –¥–∞–Ω–Ω—ã–º–∏
        feature_cols, target_cols: —Å–ø–∏—Å–∫–∏ –∫–æ–ª–æ–Ω–æ–∫
        config: –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
        logger: –ª–æ–≥–≥–µ—Ä
        
    Returns:
        tuple: (train_loader, val_loader, test_loader)
    """
    logger.info("üèóÔ∏è –°–æ–∑–¥–∞–Ω–∏–µ —É–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö DataLoader'–æ–≤...")
    
    from data.dataset import create_data_loaders
    from data.precomputed_dataset import create_precomputed_data_loaders
    
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º PrecomputedDataset –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
    use_precomputed = config.get('performance', {}).get('use_precomputed_dataset', True)
    
    # –û–±–Ω–æ–≤–ª—è–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é —á—Ç–æ–±—ã —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–æ–≤–∞—Ç—å —Ä–µ–∞–ª—å–Ω—ã–º –¥–∞–Ω–Ω—ã–º
    config_updated = config.copy()
    config_updated['model']['input_features'] = len(feature_cols)
    config_updated['model']['n_features'] = len(feature_cols)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö —Å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π –º–æ–¥–µ–ª–∏
    task_type = config['model'].get('task_type', 'regression')
    
    if task_type == 'trading':
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –í–°–ï –¥–æ—Å—Ç—É–ø–Ω—ã–µ —Ç–æ—Ä–≥–æ–≤—ã–µ —Ü–µ–ª–µ–≤—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –∏–∑ –∫—ç—à–∞
        config_updated['model']['target_variables'] = target_cols
        logger.info(f"‚úÖ –¢–æ—Ä–≥–æ–≤–∞—è –º–æ–¥–µ–ª—å: –∏—Å–ø–æ–ª—å–∑—É–µ–º –≤—Å–µ {len(target_cols)} —Ü–µ–ª–µ–≤—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö")
        logger.info(f"   –ü–µ—Ä–≤—ã–µ 5 –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö: {target_cols[:5]}")
    else:
        # –î–ª—è —Ä–µ–≥—Ä–µ—Å—Å–∏–∏ –≤—ã–±–∏—Ä–∞–µ–º –æ—Å–Ω–æ–≤–Ω—É—é —Ü–µ–ª–µ–≤—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é
        main_target = [col for col in target_cols if col.startswith('future_return_')]
        if main_target:
            config_updated['model']['target_variable'] = main_target[0]
            logger.info(f"‚úÖ –†–µ–≥—Ä–µ—Å—Å–∏—è: –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ü–µ–ª–µ–≤—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é {main_target[0]}")
        else:
            logger.error("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–∞ —Ü–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è –¥–ª—è —Ä–µ–≥—Ä–µ—Å—Å–∏–∏!")
            raise ValueError("–ù–µ—Ç –ø–æ–¥—Ö–æ–¥—è—â–µ–π —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –¥–ª—è —Ä–µ–≥—Ä–µ—Å—Å–∏–∏")
    
    # –°–æ–∑–¥–∞–Ω–∏–µ DataLoader'–æ–≤ —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
    if use_precomputed:
        logger.info("üöÄ –ò—Å–ø–æ–ª—å–∑—É–µ–º PrecomputedDataset –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π —Å–∫–æ—Ä–æ—Å—Ç–∏")
        train_loader, val_loader, test_loader = create_precomputed_data_loaders(
            train_data=train_data,
            val_data=val_data, 
            test_data=test_data,
            config=config_updated,
            feature_cols=feature_cols,
            target_cols=target_cols
        )
    else:
        logger.info("üìä –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π Dataset")
        train_loader, val_loader, test_loader = create_data_loaders(
            train_data=train_data,
            val_data=val_data, 
            test_data=test_data,
            config=config_updated,
            feature_cols=feature_cols,
            target_cols=target_cols
        )
    
    logger.info("‚úÖ DataLoader'—ã —Å–æ–∑–¥–∞–Ω—ã —É—Å–ø–µ—à–Ω–æ")
    return train_loader, val_loader, test_loader, config_updated

def prepare_data(config: dict, logger):
    """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è —Å –∑–∞—â–∏—Ç–æ–π –æ—Ç data leakage"""
    logger.start_stage("data_preparation")
    
    logger.info("üì• –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ PostgreSQL...")
    
    # –ò–º–ø–æ—Ä—Ç –∑–¥–µ—Å—å –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è —Ü–∏–∫–ª–∏—á–µ—Å–∫–∏—Ö –∏–º–ø–æ—Ä—Ç–æ–≤
    from data.data_loader import CryptoDataLoader
    from data.feature_engineering import FeatureEngineer
    from data.dataset import create_data_loaders, TradingDataset
    
    data_loader = CryptoDataLoader(config)
    
    # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ —Å–∏–º–≤–æ–ª–æ–≤
    if config['data']['symbols'] == 'all':
        available_symbols = data_loader.get_available_symbols()
        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–∏–º–≤–æ–ª–æ–≤ –¥–ª—è –¥–µ–º–æ
        max_symbols = config.get('data', {}).get('max_symbols', 10)
        symbols_to_load = available_symbols[:max_symbols]
        logger.info(f"üìä –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–≤—ã–µ {max_symbols} —Å–∏–º–≤–æ–ª–æ–≤ –∏–∑ {len(available_symbols)}: {symbols_to_load}")
    else:
        symbols_to_load = config['data']['symbols']
        logger.info(f"üìä –ó–∞–≥—Ä—É–∂–∞–µ–º —É–∫–∞–∑–∞–Ω–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã: {symbols_to_load}")
    
    raw_data = data_loader.load_data(
        symbols=symbols_to_load,
        start_date=config['data']['start_date'],
        end_date=config['data']['end_date']
    )
    
    logger.info("üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –¥–∞–Ω–Ω—ã—Ö...")
    quality_report = data_loader.validate_data_quality(raw_data)
    
    for symbol, report in quality_report.items():
        if report['anomalies']:
            logger.warning(f"–ê–Ω–æ–º–∞–ª–∏–∏ –≤ –¥–∞–Ω–Ω—ã—Ö {symbol}: {report['anomalies']}")
    
    logger.info("üõ†Ô∏è –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å –∑–∞—â–∏—Ç–æ–π –æ—Ç data leakage...")
    feature_engineer = FeatureEngineer(config)
    
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–æ–≤—ã–π –º–µ—Ç–æ–¥ —Å –∑–∞—â–∏—Ç–æ–π –æ—Ç data leakage
    train_data, val_data, test_data = feature_engineer.create_features_with_train_split(
        raw_data,
        train_ratio=config['data']['train_ratio'],
        val_ratio=config['data']['val_ratio']
    )
    
    logger.info("üèóÔ∏è –°–æ–∑–¥–∞–Ω–∏–µ datasets...")
    
    # –°–æ–∑–¥–∞–Ω–∏–µ DataLoader'–æ–≤ —á–µ—Ä–µ–∑ —É–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—É—é —Å–∏—Å—Ç–µ–º—É
    from data.constants import get_feature_columns, get_target_columns, validate_data_structure
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–∞–Ω–Ω—ã—Ö
    data_info = validate_data_structure(train_data)
    feature_cols = data_info['feature_cols']
    target_cols = data_info['target_cols']
    
    train_loader, val_loader, test_loader, _ = create_unified_data_loaders(
        train_data, val_data, test_data, feature_cols, target_cols, config, logger
    )
    
    logger.info(f"üìä –†–∞–∑–º–µ—Ä—ã datasets:")
    logger.info(f"   - Train: {len(train_data)} –∑–∞–ø–∏—Å–µ–π")
    logger.info(f"   - Val: {len(val_data)} –∑–∞–ø–∏—Å–µ–π")
    logger.info(f"   - Test: {len(test_data)} –∑–∞–ø–∏—Å–µ–π")
    
    logger.end_stage("data_preparation", 
                    train_size=len(train_data),
                    val_size=len(val_data),
                    test_size=len(test_data))
    
    return train_loader, val_loader, test_loader

def train_model(config: dict, train_loader, val_loader, logger):
    """–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏"""
    logger.start_stage("model_training")
    
    logger.info("üèóÔ∏è –°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ PatchTST...")
    
    # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –¥–∞–Ω–Ω—ã—Ö –∏–∑ –ø–µ—Ä–≤–æ–≥–æ –±–∞—Ç—á–∞
    sample_batch = next(iter(train_loader))
    X_sample, y_sample, _ = sample_batch
    
    n_features = X_sample.shape[-1]  # –ü–æ—Å–ª–µ–¥–Ω—è—è —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å
    n_targets = y_sample.shape[-1] if y_sample is not None else 1
    
    logger.info(f"üìä –í—Ö–æ–¥–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏: {n_features}, –¶–µ–ª–µ–≤—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ: {n_targets}")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π
    config_input_size = config['model'].get('input_size', 100)
    config_output_size = config['model'].get('output_size', 1)
    task_type = config['model'].get('task_type', 'regression')
    
    if n_features != config_input_size:
        logger.warning(f"‚ö†Ô∏è –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –Ω–µ —Å–æ–≤–ø–∞–¥–∞–µ—Ç: –¥–∞–Ω–Ω—ã–µ={n_features}, –∫–æ–Ω—Ñ–∏–≥={config_input_size}")
        logger.info(f"üîß –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–±–Ω–æ–≤–ª—è–µ–º input_size –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏")
        config['model']['input_size'] = n_features
    
    if task_type == 'trading':
        # –î–ª—è —Ç–æ—Ä–≥–æ–≤–æ–π –º–æ–¥–µ–ª–∏ —Å –±–æ–ª—å—à–∏–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º —Ü–µ–ª–µ–π –∏—Å–ø–æ–ª—å–∑—É–µ–º –±–∞–∑–æ–≤—É—é –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É
        if config['model']['name'] == 'UnifiedPatchTST':  # –ò—Å–ø–æ–ª—å–∑—É–µ–º —É–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—É—é –º–æ–¥–µ–ª—å
            logger.info(f"üìä –¢–æ—Ä–≥–æ–≤–∞—è –º–æ–¥–µ–ª—å: {n_targets} —Ü–µ–ª–µ–≤—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö - –∏—Å–ø–æ–ª—å–∑—É–µ–º –≥–∏–±–∫—É—é –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É")
            config['model']['output_size'] = n_targets
        else:
            logger.info(f"üìä –¢–æ—Ä–≥–æ–≤–∞—è –º–æ–¥–µ–ª—å: –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è PatchTSTForTrading —Å –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ –≤—ã—Ö–æ–¥–∞–º–∏")
    else:
        if n_targets != config_output_size:
            logger.warning(f"‚ö†Ô∏è –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å —Ü–µ–ª–µ–π –Ω–µ —Å–æ–≤–ø–∞–¥–∞–µ—Ç: –¥–∞–Ω–Ω—ã–µ={n_targets}, –∫–æ–Ω—Ñ–∏–≥={config_output_size}")
            logger.info(f"üîß –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–±–Ω–æ–≤–ª—è–µ–º output_size –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏")
            config['model']['output_size'] = n_targets
    
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ñ–∞–±—Ä–∏–∫—É –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏
    from models.patchtst import create_patchtst_model
    from models.patchtst_unified import create_unified_model, UnifiedPatchTSTForTrading
    
    # Ensemble –æ–±—É—á–µ–Ω–∏–µ
    ensemble_count = config.get('training', {}).get('ensemble_count', 1)
    
    if ensemble_count > 1:
        logger.info(f"üé≠ –°–æ–∑–¥–∞–Ω–∏–µ –∞–Ω—Å–∞–º–±–ª—è –∏–∑ {ensemble_count} –º–æ–¥–µ–ª–µ–π")
        models = []
        
        for i in range(ensemble_count):
            logger.info(f"üìä –°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ {i+1}/{ensemble_count}")
            
            # –í–∞—Ä–∏–∞—Ç–∏–≤–Ω–æ—Å—Ç—å –¥–ª—è –∫–∞–∂–¥–æ–π –º–æ–¥–µ–ª–∏ –≤ –∞–Ω—Å–∞–º–±–ª–µ
            model_config = config.copy()
            model_config['model']['random_seed'] = config.get('model', {}).get('random_seed', 42) + i
            
            # –ù–µ–±–æ–ª—å—à–∏–µ –≤–∞—Ä–∏–∞—Ü–∏–∏ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –¥–ª—è —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏—è
            if i > 0:
                # –í–∞—Ä–∏–∞—Ü–∏—è dropout
                original_dropout = model_config['model'].get('dropout', 0.1)
                model_config['model']['dropout'] = original_dropout + (i * 0.05)
                
                # –í–∞—Ä–∏–∞—Ü–∏—è learning rate  
                original_lr = model_config['model'].get('learning_rate', 2e-5)
                model_config['model']['learning_rate'] = original_lr * (1 + (i-1) * 0.2)
            
            # –°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏
            if task_type == 'trading' and n_targets > 10:
                model_config['model']['name'] = 'UnifiedPatchTST'
                model_config['model']['output_size'] = n_targets
                model = create_unified_model(model_config)
            elif model_config['model']['name'] == 'UnifiedPatchTST':
                model = create_unified_model(model_config)
            else:
                model = create_patchtst_model(model_config)
            
            models.append(model)
        
        logger.info(f"‚úÖ –ê–Ω—Å–∞–º–±–ª—å –∏–∑ {len(models)} –º–æ–¥–µ–ª–µ–π —Å–æ–∑–¥–∞–Ω")
        
        # –î–ª—è –ø—Ä–æ—Å—Ç–æ—Ç—ã, –æ–±—É—á–∞–µ–º –ø–µ—Ä–≤—É—é –º–æ–¥–µ–ª—å (–≤ –±—É–¥—É—â–µ–º –º–æ–∂–Ω–æ —Ä–∞—Å—à–∏—Ä–∏—Ç—å)
        model = models[0] 
        logger.info(f"üéØ –û–±—É—á–µ–Ω–∏–µ –ø–µ—Ä–≤–æ–π –º–æ–¥–µ–ª–∏ –∏–∑ –∞–Ω—Å–∞–º–±–ª—è (–º–æ–¥–µ–ª—å 1/{ensemble_count})")
        
    else:
        # –û–¥–∏–Ω–æ—á–Ω–∞—è –º–æ–¥–µ–ª—å
        # –ö–†–ò–¢–ò–ß–ï–°–ö–û–ï –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –í—Å–µ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑—É–µ–º UnifiedPatchTST –¥–ª—è 36 —Ü–µ–ª–µ–≤—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö
        if task_type == 'trading' and n_targets > 10:
            logger.info(f"üéØ –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ {n_targets} —Ü–µ–ª–µ–≤—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö - –∏—Å–ø–æ–ª—å–∑—É–µ–º UnifiedPatchTST")
            config['model']['name'] = 'UnifiedPatchTST'
            config['model']['output_size'] = n_targets
            model = create_unified_model(config)
            logger.info(f"‚úÖ UnifiedPatchTST —Å–æ–∑–¥–∞–Ω —Å {n_targets} –≤—ã—Ö–æ–¥–∞–º–∏ –¥–ª—è —Ç–æ—Ä–≥–æ–≤–æ–π –º–æ–¥–µ–ª–∏")
            logger.info("‚ö†Ô∏è torch.compile –æ—Ç–∫–ª—é—á–µ–Ω –¥–ª—è RTX 5090 (sm_120) - —Ç—Ä–µ–±—É–µ—Ç—Å—è –ø–æ–¥–¥–µ—Ä–∂–∫–∞ –≤ –±—É–¥—É—â–∏—Ö –≤–µ—Ä—Å–∏—è—Ö PyTorch")
        elif config['model']['name'] == 'UnifiedPatchTST':
            model = create_unified_model(config)
            logger.info("üìä –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è UnifiedPatchTST —Å 36 –≤—ã—Ö–æ–¥–∞–º–∏")
            logger.info("‚ö†Ô∏è torch.compile –æ—Ç–∫–ª—é—á–µ–Ω –¥–ª—è RTX 5090 (sm_120)")
        else:
            model = create_patchtst_model(config)
            # –õ–æ–≥–∏—Ä—É–µ–º —Ç–∏–ø –º–æ–¥–µ–ª–∏
            if hasattr(model, 'long_model'):
                logger.info("‚úÖ –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è PatchTSTForTrading —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π LONG/SHORT")
            else:
                logger.info("üìä –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –±–∞–∑–æ–≤–∞—è PatchTSTForPrediction")
    
    # –í–ê–ñ–ù–û: –Ø–≤–Ω–æ –ø–µ—Ä–µ–º–µ—â–∞–µ–º –º–æ–¥–µ–ª—å –Ω–∞ GPU –ø–µ—Ä–µ–¥ —Å–æ–∑–¥–∞–Ω–∏–µ–º —Ç—Ä–µ–π–Ω–µ—Ä–∞
    if torch.cuda.is_available():
        device = torch.device('cuda')
        model = model.to(device)
        logger.info(f"üî• –ú–æ–¥–µ–ª—å –ø–µ—Ä–µ–º–µ—â–µ–Ω–∞ –Ω–∞ GPU: {torch.cuda.get_device_name(0)}")
        logger.info(f"üíæ GPU –ø–∞–º—è—Ç—å –¥–æ—Å—Ç—É–ø–Ω–∞: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB")
    else:
        device = torch.device('cpu')
        logger.warning("‚ö†Ô∏è GPU –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è CPU")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω—É–∂–Ω–æ –ª–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø–æ—ç—Ç–∞–ø–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ
    if config.get('production', {}).get('staged_training', {}).get('enabled', False):
        logger.info("üéØ –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ø–æ—ç—Ç–∞–ø–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ (StagedTrainer)")
        from training.staged_trainer import StagedTrainer
        trainer = StagedTrainer(model, config, device=device)
    else:
        # –°–æ–∑–¥–∞–Ω–∏–µ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Ç—Ä–µ–π–Ω–µ—Ä–∞ —Å —è–≤–Ω—ã–º —É–∫–∞–∑–∞–Ω–∏–µ–º —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞
        from training.optimized_trainer import OptimizedTrainer
        trainer = OptimizedTrainer(model, config, device=device)
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑–º–µ—â–µ–Ω–∏—è –º–æ–¥–µ–ª–∏
    logger.info(f"‚úÖ –ú–æ–¥–µ–ª—å –Ω–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–µ: {next(model.parameters()).device}")
    logger.info(f"‚úÖ –¢—Ä–µ–π–Ω–µ—Ä –∏—Å–ø–æ–ª—å–∑—É–µ—Ç: {trainer.device}")
    
    # DataLoader'—ã —É–∂–µ —Å–æ–∑–¥–∞–Ω—ã, –∏—Å–ø–æ–ª—å–∑—É–µ–º –∏—Ö –Ω–∞–ø—Ä—è–º—É—é
    
    # –û–±—É—á–µ–Ω–∏–µ
    logger.info("üöÄ –ù–∞—á–∞–ª–æ –æ–±—É—á–µ–Ω–∏—è...")
    training_results = trainer.train(
        train_loader=train_loader,
        val_loader=val_loader
    )
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏
    if hasattr(trainer, 'checkpoint_dir'):
        # –î–ª—è OptimizedTrainer
        best_model_path = trainer.checkpoint_dir / "best_model.pth"
    else:
        # –î–ª—è StagedTrainer - —Å–æ–∑–¥–∞–µ–º –ø—É—Ç—å –≤—Ä—É—á–Ω—É—é
        from pathlib import Path
        checkpoint_dir = Path(config['model'].get('checkpoint_dir', 'models_saved'))
        checkpoint_dir.mkdir(exist_ok=True, parents=True)
        best_model_path = checkpoint_dir / "best_model.pth"
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å
        torch.save({
            'model_state_dict': model.state_dict(),
            'config': config,
            'training_results': training_results
        }, best_model_path)
        logger.info(f"üíæ –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ {best_model_path}")
    
    logger.info(f"‚úÖ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ. –õ—É—á—à–∞—è –º–æ–¥–µ–ª—å: {best_model_path}")
    
    logger.end_stage("model_training", model_path=str(best_model_path))
    
    return model, best_model_path, train_loader

def backtest_strategy(config: dict, model, test_loader, train_loader, logger):
    """–ë—ç–∫—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏"""
    logger.start_stage("backtesting")
    
    logger.info("üí∞ –ó–∞–ø—É—Å–∫ –±—ç–∫—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è...")
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ —Ç–æ—Ä–≥–æ–≤–ª–∏
    from trading.risk_manager import RiskManager
    from trading.signals import SignalGenerator
    from trading.backtester import Backtester
    
    risk_manager = RiskManager(config)
    signal_generator = SignalGenerator(config)
    backtester = Backtester(config)
    
    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –º–æ–¥–µ–ª–∏ (—Ñ–∏–∫—Ç–∏–≤–Ω—ã—Ö –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏)
    logger.info("üîÆ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –º–æ–¥–µ–ª–∏...")
    
    # –°–æ–∑–¥–∞–µ–º —Ñ–∏–∫—Ç–∏–≤–Ω—ã–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–∞–Ω–Ω—ã—Ö
    sample_batch = next(iter(test_loader))
    X_sample, y_sample, _ = sample_batch
    
    n_samples = len(test_loader.dataset) if hasattr(test_loader, 'dataset') else 1000
    n_targets = y_sample.shape[-1] if y_sample is not None else 1
    
    predictions = {
        'price_pred': np.random.random((n_samples, config['model']['pred_len'], n_targets)),
        'confidence': np.random.uniform(0.5, 0.9, n_samples)
    }
    
    # –°–æ–∑–¥–∞–µ–º —Ñ–∏–∫—Ç–∏–≤–Ω—ã–µ —Ä—ã–Ω–æ—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏
    test_data = pd.DataFrame({
        'datetime': pd.date_range('2025-01-01', periods=n_samples, freq='15min'),
        'symbol': np.random.choice(['BTCUSDT', 'ETHUSDT'], n_samples),
        'close': np.random.uniform(30000, 70000, n_samples),
        'volume': np.random.uniform(1000, 10000, n_samples)
    })
    
    # –ó–∞–ø—É—Å–∫ –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥–∞
    logger.info("üèÉ –ó–∞–ø—É—Å–∫ –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥–∞...")
    backtest_results = backtester.run_backtest(
        market_data=test_data,
        features=test_data,  # –£–ø—Ä–æ—â–µ–Ω–∏–µ –¥–ª—è –¥–µ–º–æ
        model_predictions=predictions
    )
    
    # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    logger.info("üìà –†–ï–ó–£–õ–¨–¢–ê–¢–´ –ë–≠–ö–¢–ï–°–¢–ò–ù–ì–ê:")
    logger.info(f"  –ù–∞—á–∞–ª—å–Ω—ã–π –∫–∞–ø–∏—Ç–∞–ª: ${backtest_results['initial_capital']:,.2f}")
    logger.info(f"  –§–∏–Ω–∞–ª—å–Ω—ã–π –∫–∞–ø–∏—Ç–∞–ª: ${backtest_results['final_capital']:,.2f}")
    logger.info(f"  –û–±—â–∞—è –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å: {backtest_results['total_return_pct']:.2f}%")
    logger.info(f"  –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –®–∞—Ä–ø–∞: {backtest_results['sharpe_ratio']:.2f}")
    logger.info(f"  –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –ø—Ä–æ—Å–∞–¥–∫–∞: {backtest_results['max_drawdown_pct']:.2f}%")
    logger.info(f"  Win Rate: {backtest_results['win_rate_pct']:.2f}%")
    logger.info(f"  –í—Å–µ–≥–æ —Å–¥–µ–ª–æ–∫: {backtest_results['total_trades']}")
    
    logger.end_stage("backtesting", 
                    total_return=backtest_results['total_return_pct'],
                    sharpe_ratio=backtest_results['sharpe_ratio'])
    
    return backtest_results

def analyze_results(config: dict, results: dict, logger):
    """–ê–Ω–∞–ª–∏–∑ –∏ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"""
    logger.start_stage("results_analysis")
    
    logger.info("üìä –ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤...")
    
    min_sharpe = config['validation']['min_sharpe_ratio']
    min_win_rate = config['validation']['min_win_rate']
    max_dd = config['validation']['max_drawdown']
    
    passed_validation = True
    
    if results['sharpe_ratio'] < min_sharpe:
        logger.warning(f"‚ö†Ô∏è Sharpe Ratio ({results['sharpe_ratio']:.2f}) –Ω–∏–∂–µ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–≥–æ ({min_sharpe})")
        passed_validation = False
    
    if results['win_rate'] < min_win_rate:
        logger.warning(f"‚ö†Ô∏è Win Rate ({results['win_rate']:.2%}) –Ω–∏–∂–µ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–≥–æ ({min_win_rate:.2%})")
        passed_validation = False
    
    if abs(results['max_drawdown']) > max_dd:
        logger.warning(f"‚ö†Ô∏è Max Drawdown ({results['max_drawdown']:.2%}) –ø—Ä–µ–≤—ã—à–∞–µ—Ç –ª–∏–º–∏—Ç ({max_dd:.2%})")
        passed_validation = False
    
    if passed_validation:
        logger.info("‚úÖ –í—Å–µ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ç–µ—Å—Ç—ã –ø—Ä–æ–π–¥–µ–Ω—ã!")
    else:
        logger.warning("‚ùå –ù–µ–∫–æ—Ç–æ—Ä—ã–µ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ç–µ—Å—Ç—ã –Ω–µ –ø—Ä–æ–π–¥–µ–Ω—ã")
    
    logger.end_stage("results_analysis", validation_passed=passed_validation)
    
    return passed_validation

def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    parser = argparse.ArgumentParser(description='Crypto AI Trading System')
    parser.add_argument('--config', type=str, default='config/config.yaml',
                       help='–ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏')
    parser.add_argument('--mode', type=str, default='full',
                       choices=['data', 'train', 'backtest', 'full', 'demo', 'interactive', 'production'],
                       help='–†–µ–∂–∏–º —Ä–∞–±–æ—Ç—ã')
    parser.add_argument('--model-path', type=str, default=None,
                       help='–ü—É—Ç—å –∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ (–¥–ª—è —Ä–µ–∂–∏–º–∞ backtest)')
    parser.add_argument('--use-improved-model', action='store_true',
                       help='–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —É–ª—É—á—à–µ–Ω–Ω—É—é –≤–µ—Ä—Å–∏—é –º–æ–¥–µ–ª–∏ —Å FeatureAttention')
    parser.add_argument('--validate-only', action='store_true',
                       help='–¢–æ–ª—å–∫–æ –≤–∞–ª–∏–¥–∞—Ü–∏—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –±–µ–∑ –∑–∞–ø—É—Å–∫–∞')
    parser.add_argument('--prepare-data', action='store_true',
                       help='–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∑–∞–ø—É—Å—Ç–∏—Ç—å prepare_trading_data.py –µ—Å–ª–∏ –Ω–µ—Ç –∫–µ—à–∞')
    
    # –ù–æ–≤—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è
    parser.add_argument('--target-focus', type=str, default='all',
                       choices=['all', 'returns', 'directions', 'long_profits', 'short_profits', 'risk_metrics'],
                       help='–§–æ–∫—É—Å –Ω–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –≥—Ä—É–ø–ø–µ —Ü–µ–ª–µ–≤—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö')
    parser.add_argument('--loss-type', type=str, default='unified',
                       choices=['unified', 'directional', 'profit_aware', 'ensemble'],
                       help='–¢–∏–ø loss —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏')
    parser.add_argument('--ensemble-count', type=int, default=1,
                       help='–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –º–æ–¥–µ–ª–µ–π –≤ –∞–Ω—Å–∞–º–±–ª–µ (1 = –±–µ–∑ –∞–Ω—Å–∞–º–±–ª—è)')
    parser.add_argument('--direction-focus', action='store_true',
                       help='–°–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –Ω–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–∏ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è –¥–≤–∏–∂–µ–Ω–∏—è —Ü–µ–Ω—ã')
    parser.add_argument('--large-movement-weight', type=float, default=1.0,
                       help='–ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –≤–µ—Å–∞ –¥–ª—è –∫—Ä—É–ø–Ω—ã—Ö –¥–≤–∏–∂–µ–Ω–∏–π —Ü–µ–Ω—ã (1.0 = –±–µ–∑ –≤–µ—Å–∞)')
    parser.add_argument('--min-movement-threshold', type=float, default=0.005,
                       help='–ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –ø–æ—Ä–æ–≥ –¥–≤–∏–∂–µ–Ω–∏—è –¥–ª—è —Ç–æ—Ä–≥–æ–≤—ã—Ö —Å–∏–≥–Ω–∞–ª–æ–≤ (0.5%)')
    parser.add_argument('--production', action='store_true',
                       help='–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å production –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é (config_production.yaml)')
    parser.add_argument('--checkpoint', type=str, default=None,
                       help='–ü—É—Ç—å –∫ checkpoint –¥–ª—è fine-tuning (–Ω–∞–ø—Ä–∏–º–µ—Ä: models_saved/best_model_20250710_150018.pth)')
    
    args = parser.parse_args()
    
    # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º production –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –¥–ª—è production —Ä–µ–∂–∏–º–∞
    if args.production or args.mode == 'production':
        config_path = 'config/config_production.yaml'
        logger_name = "CryptoAI-Production"
    else:
        config_path = args.config
        logger_name = "CryptoAI"
    
    config = load_config(config_path)
    
    # –°–æ–∑–¥–∞–µ–º logger —Å—Ä–∞–∑—É
    logger = get_logger(logger_name)
    
    # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ñ–ª–∞–≥ —É–ª—É—á—à–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ –∫ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
    if args.use_improved_model:
        config['model']['use_improvements'] = True
        config['model']['feature_attention'] = True
        config['model']['multi_scale_patches'] = True
    
    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–æ–≤—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –æ–±—É—á–µ–Ω–∏—è
    # –°–æ–∑–¥–∞–µ–º —Å–µ–∫—Ü–∏—é training –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç
    if 'training' not in config:
        config['training'] = {}
    
    if args.target_focus != 'all':
        config['training']['target_focus'] = args.target_focus
        logger.info(f"üéØ –§–æ–∫—É—Å –Ω–∞ —Ü–µ–ª–µ–≤—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö: {args.target_focus}")
    
    if args.loss_type != 'unified':
        config['training']['loss_type'] = args.loss_type
        logger.info(f"üîß –¢–∏–ø loss —Ñ—É–Ω–∫—Ü–∏–∏: {args.loss_type}")
    
    if args.ensemble_count > 1:
        config['training']['ensemble_count'] = args.ensemble_count
        config['model']['use_ensemble'] = True
        logger.info(f"üé≠ –ê–Ω—Å–∞–º–±–ª—å –∏–∑ {args.ensemble_count} –º–æ–¥–µ–ª–µ–π")
    
    if args.direction_focus:
        config['training']['direction_focus'] = True
        config['model']['task_type'] = 'direction_prediction'
        logger.info("üéØ –°–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –Ω–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–∏ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è –¥–≤–∏–∂–µ–Ω–∏—è")
    
    if args.large_movement_weight != 1.0:
        config['training']['large_movement_weight'] = args.large_movement_weight
        logger.info(f"‚öñÔ∏è –í–µ—Å –∫—Ä—É–ø–Ω—ã—Ö –¥–≤–∏–∂–µ–Ω–∏–π: {args.large_movement_weight}")
    
    if args.min_movement_threshold != 0.005:
        config['training']['min_movement_threshold'] = args.min_movement_threshold
        logger.info(f"üìè –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –ø–æ—Ä–æ–≥ –¥–≤–∏–∂–µ–Ω–∏—è: {args.min_movement_threshold:.3f} ({args.min_movement_threshold*100:.1f}%)")
    
    logger.info("="*80)
    logger.info("üöÄ –ó–∞–ø—É—Å–∫ Crypto AI Trading System")
    logger.info(f"üìã –†–µ–∂–∏–º: {args.mode}")
    logger.info(f"‚öôÔ∏è –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è: {config_path}")
    if args.production or args.mode == 'production':
        logger.info("üè≠ PRODUCTION MODE - –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è")
        logger.info("üìä –û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏ production —Ä–µ–∂–∏–º–∞:")
        logger.info("   - –£–º–µ–Ω—å—à–µ–Ω–Ω—ã–π batch size (512) –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏")
        logger.info("   - –£—Å–∏–ª–µ–Ω–Ω–∞—è —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è (dropout=0.5, weight_decay=0.01)")
        logger.info("   - –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–µ –≤–µ—Å–∞ –∫–ª–∞—Å—Å–æ–≤ –¥–ª—è –±–æ—Ä—å–±—ã —Å –¥–∏—Å–±–∞–ª–∞–Ω—Å–æ–º")
        logger.info("   - –£–≤–µ–ª–∏—á–µ–Ω–Ω—ã–π –≤–µ—Å direction loss (15.0)")
        logger.info("   - Focal Loss —Å –∞–≥—Ä–µ—Å—Å–∏–≤–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏")
    if args.use_improved_model:
        logger.info("üî• –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —É–ª—É—á—à–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å —Å FeatureAttention")
    logger.info("="*80)
    
    # –í–∞–ª–∏–¥–∞—Ü–∏—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
    if args.validate_only:
        logger.info("üîç –†–µ–∂–∏–º –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏...")
        from utils.config_validator import validate_config
        is_valid = validate_config(config)
        if is_valid:
            logger.info("‚úÖ –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –≤–∞–ª–∏–¥–Ω–∞!")
        else:
            logger.error("‚ùå –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Å–æ–¥–µ—Ä–∂–∏—Ç –æ—à–∏–±–∫–∏!")
        return
    
    # –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π —Ä–µ–∂–∏–º
    if args.mode == 'interactive':
        logger.info("üéÆ –ó–∞–ø—É—Å–∫ –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ–≥–æ —Ä–µ–∂–∏–º–∞...")
        from run_interactive import run_interactive_mode
        run_interactive_mode(config)
        return
    
    try:
        # –¶–µ–Ω—Ç—Ä–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –≤—Å–µ—Ö —Ä–µ–∂–∏–º–æ–≤
        train_data, val_data, test_data, feature_cols, target_cols = None, None, None, None, None
        train_loader, val_loader, test_loader = None, None, None
        config_updated = config.copy()
        
        if args.mode in ['data', 'train', 'full', 'production']:
            # Production —Ä–µ–∂–∏–º —ç–∫–≤–∏–≤–∞–ª–µ–Ω—Ç–µ–Ω train —Å production –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π
            if args.mode == 'production':
                logger.info("üè≠ Production —Ä–µ–∂–∏–º –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω - –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏")
                
            # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
            train_data, val_data, test_data, feature_cols, target_cols = load_cached_data_if_exists(logger)
            
            if train_data is not None:
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
                logger.info("üéØ –ò—Å–ø–æ–ª—å–∑—É–µ–º –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –≤—Å–µ—Ö —Ä–µ–∂–∏–º–æ–≤")
                
                # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–∏–º–≤–æ–ª–æ–≤ –µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω–æ –≤ –∫–æ–Ω—Ñ–∏–≥–µ
                max_symbols = config.get('data', {}).get('max_symbols', None)
                if max_symbols:
                    logger.info(f"üéØ –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–æ {max_symbols} —Å–∏–º–≤–æ–ª–æ–≤")
                    unique_symbols = train_data['symbol'].unique()[:max_symbols]
                    train_data = train_data[train_data['symbol'].isin(unique_symbols)]
                    val_data = val_data[val_data['symbol'].isin(unique_symbols)]
                    test_data = test_data[test_data['symbol'].isin(unique_symbols)]
                    logger.info(f"üìä –ü–æ—Å–ª–µ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è: train={len(train_data):,}, val={len(val_data):,}, test={len(test_data):,}")
                
                train_loader, val_loader, test_loader, config_updated = create_unified_data_loaders(
                    train_data, val_data, test_data, feature_cols, target_cols, config, logger
                )
            elif args.mode in ['data', 'full']:
                # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –∏—Ö –Ω–µ—Ç –∏ —ç—Ç–æ —Ä–µ–∂–∏–º data/full
                logger.info("üîÑ –ö—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã, —Å–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–µ...")
                train_loader, val_loader, test_loader = prepare_data(config, logger)
                config_updated = config  # –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—É—é –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
            else:
                # –†–µ–∂–∏–º train –±–µ–∑ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
                logger.error("‚ùå –†–µ–∂–∏–º train —Ç—Ä–µ–±—É–µ—Ç –Ω–∞–ª–∏—á–∏—è –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö!")
                
                if args.prepare_data:
                    logger.info("üîÑ –ó–∞–ø—É—Å–∫–∞–µ–º prepare_trading_data.py –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –∫–µ—à–∞...")
                    import subprocess
                    result = subprocess.run(
                        ["python", "prepare_trading_data.py", "--config", args.config],
                        capture_output=True,
                        text=True
                    )
                    
                    if result.returncode == 0:
                        logger.info("‚úÖ –î–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω—ã!")
                        # –ü–æ–≤—Ç–æ—Ä–Ω–æ –ø—ã—Ç–∞–µ–º—Å—è –∑–∞–≥—Ä—É–∑–∏—Ç—å –∫–µ—à
                        train_data, val_data, test_data, feature_cols, target_cols = load_cached_data_if_exists(logger)
                        if train_data is not None:
                            train_loader, val_loader, test_loader, config_updated = create_unified_data_loaders(
                                train_data, val_data, test_data, feature_cols, target_cols, config, logger
                            )
                        else:
                            logger.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –ø–æ—Å–ª–µ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏")
                            return
                    else:
                        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–µ –¥–∞–Ω–Ω—ã—Ö: {result.stderr}")
                        return
                else:
                    logger.error("–ó–∞–ø—É—Å—Ç–∏—Ç–µ: python prepare_trading_data.py")
                    logger.error("–ò–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Ñ–ª–∞–≥ --prepare-data –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –∑–∞–ø—É—Å–∫–∞")
                    return
        
        if args.mode in ['train', 'full', 'production']:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω—É–∂–Ω–æ –ª–∏ –¥–µ–ª–∞—Ç—å fine-tuning
            if config_updated.get('fine_tuning', {}).get('enabled', False) and args.checkpoint:
                logger.info("üéØ Fine-tuning —Ä–µ–∂–∏–º –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω")
                from training.fine_tuner import create_fine_tuner
                
                # –°–æ–∑–¥–∞–µ–º FineTuner —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º checkpoint
                fine_tuner = create_fine_tuner(config_updated, args.checkpoint)
                
                # –û–±–Ω–æ–≤–ª—è–µ–º learning rate –¥–ª—è fine-tuning
                fine_tuning_lr = config_updated.get('fine_tuning', {}).get('learning_rate', 0.00002)
                for param_group in fine_tuner.optimizer.param_groups:
                    param_group['lr'] = fine_tuning_lr
                
                # –ó–∞–ø—É—Å–∫–∞–µ–º fine-tuning
                fine_tuning_epochs = config_updated.get('fine_tuning', {}).get('epochs', 30)
                best_val_loss = float('inf')
                
                for epoch in range(fine_tuning_epochs):
                    fine_tuner.current_epoch = epoch
                    
                    # Train
                    train_metrics = fine_tuner.train_epoch(train_loader)
                    
                    # Validate
                    val_metrics = fine_tuner.validate(val_loader)
                    
                    # Scheduler step
                    if fine_tuner.scheduler:
                        fine_tuner.scheduler.step(val_metrics['loss'])
                    
                    # Save best model
                    if val_metrics['loss'] < best_val_loss:
                        best_val_loss = val_metrics['loss']
                        model_path = fine_tuner.save_checkpoint(epoch, val_metrics, is_best=True)
                    
                    logger.info(f"Epoch {epoch+1}/{fine_tuning_epochs} - "
                              f"Train Loss: {train_metrics['loss']:.4f}, "
                              f"Val Loss: {val_metrics['loss']:.4f}, "
                              f"Direction Acc: {val_metrics.get('direction_accuracy', 0):.3f}")
                
                model = fine_tuner.model
                
            else:
                # –û–±—ã—á–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ —Å —É–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π
                model, model_path, train_loader = train_model(config_updated, train_loader, val_loader, logger)
        
        if args.mode in ['backtest', 'full']:
            if args.mode == 'backtest':
                if not args.model_path:
                    logger.error("–ù–µ–æ–±—Ö–æ–¥–∏–º–æ —É–∫–∞–∑–∞—Ç—å --model-path –¥–ª—è —Ä–µ–∂–∏–º–∞ backtest")
                    return
                
                logger.info(f"üì• –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏: {args.model_path}")
                
                # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
                checkpoint = torch.load(args.model_path, map_location='cuda' if torch.cuda.is_available() else 'cpu')
                
                # –°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ —Å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π
                from models.patchtst_unified import UnifiedPatchTSTForTrading
                model = UnifiedPatchTSTForTrading(config_updated)
                
                # –ó–∞–≥—Ä—É–∑–∫–∞ –≤–µ—Å–æ–≤
                if 'model_state_dict' in checkpoint:
                    model.load_state_dict(checkpoint['model_state_dict'])
                else:
                    model.load_state_dict(checkpoint)
                
                model.eval()
                logger.info("‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
                
            results = backtest_strategy(config, model, test_loader, train_loader, logger)
            
            validation_passed = analyze_results(config, results, logger)
        
        if args.mode == 'demo':
            logger.info("üéØ –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–æ–Ω–Ω—ã–π —Ä–µ–∂–∏–º - —Ç–æ–ª—å–∫–æ –ø—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –ë–î")
            from data.data_loader import CryptoDataLoader
            
            data_loader = CryptoDataLoader(config)
            available_symbols = data_loader.get_available_symbols()
            
            logger.info(f"‚úÖ –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –ë–î —É—Å–ø–µ—à–Ω–æ")
            logger.info(f"üìä –ù–∞–π–¥–µ–Ω–æ {len(available_symbols)} —Å–∏–º–≤–æ–ª–æ–≤")
            logger.info(f"üîç –ü–µ—Ä–≤—ã–µ 10 —Å–∏–º–≤–æ–ª–æ–≤: {available_symbols[:10]}")
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –Ω–µ–±–æ–ª—å—à–æ–π –æ–±—Ä–∞–∑–µ—Ü –¥–∞–Ω–Ω—ã—Ö
            sample_data = data_loader.load_data(
                symbols=available_symbols[:2],
                start_date="2025-06-01",
                end_date="2025-06-16"
            )
            
            logger.info(f"üìà –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(sample_data)} –∑–∞–ø–∏—Å–µ–π –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏")
        
        logger.info("="*80)
        logger.info("‚úÖ –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ —É—Å–ø–µ—à–Ω–æ!")
        logger.info("="*80)
        
    except Exception as e:
        logger.log_error(e, "main")
        logger.critical("‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞! –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –ø—Ä–µ—Ä–≤–∞–Ω–æ.")
        raise

if __name__ == "__main__":
    main()