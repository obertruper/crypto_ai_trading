#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –ø–µ—Ä–µ—Å–æ–∑–¥–∞–Ω–∏—è –∫—ç—à–∞ –¥–∞–Ω–Ω—ã—Ö —Å –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–º —Ä–∞—Å—á–µ—Ç–æ–º VWAP
"""

import sys
import os
import pandas as pd
import numpy as np
from pathlib import Path
import yaml
import pickle
from datetime import datetime
import gc

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –ø—Ä–æ–µ–∫—Ç—É
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from data.data_loader import CryptoDataLoader
from utils.logger import get_logger

def verify_vwap_fix():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ —á—Ç–æ VWAP –∏—Å–ø—Ä–∞–≤–ª–µ–Ω"""
    logger = get_logger("VWAPVerification")
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
    with open('config/config.yaml', 'r') as f:
        config = yaml.safe_load(f)
    
    # –°–æ–∑–¥–∞–µ–º –∑–∞–≥—Ä—É–∑—á–∏–∫ –¥–∞–Ω–Ω—ã—Ö
    loader = CryptoDataLoader(config)
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –Ω–µ–±–æ–ª—å—à–æ–π —Å—ç–º–ø–ª –¥–∞–Ω–Ω—ã—Ö
    logger.info("üîç –ó–∞–≥—Ä—É–∑–∫–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö...")
    test_df = loader.load_raw_data(symbols=['BTCUSDT'], limit=1000)
    
    # –ü—Ä–∏–º–µ–Ω—è–µ–º feature engineering
    logger.info("üîß –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ feature engineering...")
    from data.feature_engineering import FeatureEngineer
    engineer = FeatureEngineer(config)
    featured_df = engineer.create_features(test_df)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º close_vwap_ratio
    vwap_stats = featured_df['close_vwap_ratio'].describe()
    logger.info(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ close_vwap_ratio:")
    logger.info(f"   Min: {vwap_stats['min']:.4f}")
    logger.info(f"   Max: {vwap_stats['max']:.4f}")
    logger.info(f"   Mean: {vwap_stats['mean']:.4f}")
    logger.info(f"   Std: {vwap_stats['std']:.4f}")
    
    if vwap_stats['max'] > 10:
        logger.error("‚ùå VWAP –≤—Å–µ –µ—â–µ –∏–º–µ–µ—Ç —ç–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è!")
        return False
    
    logger.info("‚úÖ VWAP –∏—Å–ø—Ä–∞–≤–ª–µ–Ω —É—Å–ø–µ—à–Ω–æ!")
    return True

def recreate_cache():
    """–ü–µ—Ä–µ—Å–æ–∑–¥–∞–Ω–∏–µ –∫—ç—à–∞ —Å –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏"""
    logger = get_logger("CacheRecreation")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ
    if not verify_vwap_fix():
        logger.error("‚ùå –ü—Ä–µ—Ä—ã–≤–∞–Ω–∏–µ: VWAP –Ω–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω")
        return
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
    with open('config/config.yaml', 'r') as f:
        config = yaml.safe_load(f)
    
    # –°–æ–∑–¥–∞–µ–º –∑–∞–≥—Ä—É–∑—á–∏–∫ –¥–∞–Ω–Ω—ã—Ö
    loader = CryptoDataLoader(config)
    
    # –ü—É—Ç—å –∫ –∫—ç—à—É
    cache_dir = Path('data/processed')
    cache_dir.mkdir(parents=True, exist_ok=True)
    
    # –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–π –∫—ç—à
    logger.info("üóëÔ∏è –£–¥–∞–ª–µ–Ω–∏–µ —Å—Ç–∞—Ä–æ–≥–æ –∫—ç—à–∞...")
    for file in ['train_data.parquet', 'val_data.parquet', 'test_data.parquet', 
                 'feature_columns.pkl', 'target_columns.pkl']:
        file_path = cache_dir / file
        if file_path.exists():
            file_path.unlink()
            logger.info(f"   –£–¥–∞–ª–µ–Ω: {file}")
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ
    logger.info("üìä –ó–∞–≥—Ä—É–∑–∫–∞ –ø–æ–ª–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –∏–∑ –ë–î...")
    train_data, val_data, test_data = loader.prepare_trading_data(
        force_recreate=True,  # –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–µ –ø–µ—Ä–µ—Å–æ–∑–¥–∞–Ω–∏–µ
        use_cache=False       # –ù–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∫—ç—à
    )
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    logger.info("\nüìà –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö:")
    
    for name, df in [('Train', train_data), ('Val', val_data), ('Test', test_data)]:
        if 'close_vwap_ratio' in df.columns:
            stats = df['close_vwap_ratio'].describe()
            logger.info(f"\n{name} - close_vwap_ratio:")
            logger.info(f"   Min: {stats['min']:.4f}")
            logger.info(f"   Max: {stats['max']:.4f}")
            logger.info(f"   Mean: {stats['mean']:.4f}")
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —ç–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
            extreme_count = (df['close_vwap_ratio'] > 10).sum()
            if extreme_count > 0:
                logger.warning(f"   ‚ö†Ô∏è –≠–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π (>10): {extreme_count}")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä—ã —Ñ–∞–π–ª–æ–≤
    logger.info("\nüíæ –†–∞–∑–º–µ—Ä—ã –∫—ç—à-—Ñ–∞–π–ª–æ–≤:")
    for file in cache_dir.glob('*.parquet'):
        size_mb = file.stat().st_size / (1024 * 1024)
        logger.info(f"   {file.name}: {size_mb:.2f} MB")
    
    logger.info("\n‚úÖ –ö—ç—à —É—Å–ø–µ—à–Ω–æ –ø–µ—Ä–µ—Å–æ–∑–¥–∞–Ω —Å –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏!")
    logger.info("üöÄ –¢–µ–ø–µ—Ä—å –º–æ–∂–Ω–æ –∑–∞–ø—É—Å–∫–∞—Ç—å –æ–±—É—á–µ–Ω–∏–µ: python main.py --mode train")

def check_current_cache():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç–µ–∫—É—â–µ–≥–æ –∫—ç—à–∞ –Ω–∞ –Ω–∞–ª–∏—á–∏–µ –ø—Ä–æ–±–ª–µ–º"""
    logger = get_logger("CacheCheck")
    
    cache_dir = Path('data/processed')
    
    logger.info("üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç–µ–∫—É—â–µ–≥–æ –∫—ç—à–∞...")
    
    for file_name in ['train_data.parquet', 'val_data.parquet', 'test_data.parquet']:
        file_path = cache_dir / file_name
        
        if not file_path.exists():
            logger.warning(f"   ‚ùå {file_name} –Ω–µ –Ω–∞–π–¥–µ–Ω")
            continue
            
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        df = pd.read_parquet(file_path)
        logger.info(f"\nüìä {file_name}:")
        logger.info(f"   –†–∞–∑–º–µ—Ä: {len(df):,} –∑–∞–ø–∏—Å–µ–π")
        
        if 'close_vwap_ratio' in df.columns:
            stats = df['close_vwap_ratio'].describe()
            logger.info(f"   close_vwap_ratio - Min: {stats['min']:.2f}, Max: {stats['max']:.2f}")
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —ç–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
            extreme_count = (df['close_vwap_ratio'] > 10).sum()
            if extreme_count > 0:
                logger.error(f"   ‚ùå –ù–∞–π–¥–µ–Ω–æ {extreme_count:,} —ç–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π!")
                
                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–∏–º–µ—Ä—ã
                extreme_samples = df[df['close_vwap_ratio'] > 10][['symbol', 'datetime', 'close_vwap_ratio']].head(5)
                logger.error(f"   –ü—Ä–∏–º–µ—Ä—ã:\n{extreme_samples}")

if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description='–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∫—ç—à–µ–º –¥–∞–Ω–Ω—ã—Ö')
    parser.add_argument('--check', action='store_true', help='–ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Ç–µ–∫—É—â–∏–π –∫—ç—à')
    parser.add_argument('--recreate', action='store_true', help='–ü–µ—Ä–µ—Å–æ–∑–¥–∞—Ç—å –∫—ç—à —Å –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è–º–∏')
    parser.add_argument('--verify', action='store_true', help='–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ VWAP')
    
    args = parser.parse_args()
    
    if args.check:
        check_current_cache()
    elif args.verify:
        verify_vwap_fix()
    elif args.recreate:
        recreate_cache()
    else:
        # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é - –ø—Ä–æ–≤–µ—Ä–∫–∞ –∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –ø–µ—Ä–µ—Å–æ–∑–¥–∞—Ç—å
        check_current_cache()
        print("\n" + "="*80)
        print("–î–ª—è –ø–µ—Ä–µ—Å–æ–∑–¥–∞–Ω–∏—è –∫—ç—à–∞ —Å –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è–º–∏ –∑–∞–ø—É—Å—Ç–∏—Ç–µ:")
        print("python recreate_cache_fixed.py --recreate")
        print("="*80)