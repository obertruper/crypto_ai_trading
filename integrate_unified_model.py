#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –ø–æ–ª–Ω–æ–π –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ —É–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏
–£–¥–∞–ª—è–µ—Ç –¥—É–±–ª–∏ –∏ –ø—Ä–∏–≤–æ–¥–∏—Ç –∫–æ–¥ –∫ –µ–¥–∏–Ω–æ–º—É —Ñ–æ—Ä–º–∞—Ç—É
"""

import os
import sys
import shutil
from datetime import datetime
from pathlib import Path

def backup_file(filepath):
    """–°–æ–∑–¥–∞–µ—Ç —Ä–µ–∑–µ—Ä–≤–Ω—É—é –∫–æ–ø–∏—é —Ñ–∞–π–ª–∞"""
    if os.path.exists(filepath):
        backup = f"{filepath}.backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        shutil.copy2(filepath, backup)
        print(f"‚úÖ Backup: {backup}")
        return backup
    return None

def update_main_py():
    """–û–±–Ω–æ–≤–ª—è–µ—Ç main.py –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —É–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏"""
    print("\nüìù –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ main.py...")
    
    main_path = "main.py"
    backup_file(main_path)
    
    with open(main_path, 'r') as f:
        content = f.read()
    
    # –î–æ–±–∞–≤–ª—è–µ–º –∏–º–ø–æ—Ä—Ç —É–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏
    if 'from models.patchtst_unified' not in content:
        # –ù–∞—Ö–æ–¥–∏–º –±–ª–æ–∫ –∏–º–ø–æ—Ä—Ç–æ–≤ –º–æ–¥–µ–ª–µ–π
        import_pos = content.find('from models.')
        if import_pos != -1:
            # –ù–∞—Ö–æ–¥–∏–º –∫–æ–Ω–µ—Ü —Å—Ç—Ä–æ–∫–∏
            line_end = content.find('\n', import_pos)
            # –í—Å—Ç–∞–≤–ª—è–µ–º –Ω–æ–≤—ã–π –∏–º–ø–æ—Ä—Ç
            new_import = "\nfrom models.patchtst_unified import create_unified_model, UnifiedPatchTSTForTrading"
            content = content[:line_end] + new_import + content[line_end:]
    
    # –ó–∞–º–µ–Ω—è–µ–º –ª–æ–≥–∏–∫—É —Å–æ–∑–¥–∞–Ω–∏—è –º–æ–¥–µ–ª–∏
    # –ù–∞—Ö–æ–¥–∏–º –±–ª–æ–∫ —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π n_targets > 13
    old_logic = """if n_targets > 13:  # PatchTSTForTrading –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Ç–æ–ª—å–∫–æ 13 –≤—ã—Ö–æ–¥–æ–≤"""
    new_logic = """if config['model']['name'] == 'UnifiedPatchTST':  # –ò—Å–ø–æ–ª—å–∑—É–µ–º —É–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—É—é –º–æ–¥–µ–ª—å"""
    
    content = content.replace(old_logic, new_logic)
    
    # –ó–∞–º–µ–Ω—è–µ–º —Å–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏
    if 'model = models.create_model(config)' in content:
        content = content.replace(
            'model = models.create_model(config)',
            """# –°–æ–∑–¥–∞–µ–º –º–æ–¥–µ–ª—å –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
    if config['model']['name'] == 'UnifiedPatchTST':
        model = create_unified_model(config)
        logger.info("üìä –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è UnifiedPatchTST —Å 36 –≤—ã—Ö–æ–¥–∞–º–∏")
    else:
        model = models.create_model(config)"""
        )
    
    # –£–±–∏—Ä–∞–µ–º —Å—Ç–∞—Ä—ã–µ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –ø—Ä–æ 13 –≤—ã—Ö–æ–¥–æ–≤
    content = content.replace(
        "# PatchTSTForTrading –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Ç–æ–ª—å–∫–æ 13 –≤—ã—Ö–æ–¥–æ–≤",
        "# –£–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –º–æ–¥–µ–ª—å –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –≤—Å–µ 36 –≤—ã—Ö–æ–¥–æ–≤"
    )
    
    with open(main_path, 'w') as f:
        f.write(content)
    
    print("‚úÖ main.py –æ–±–Ω–æ–≤–ª–µ–Ω")

def update_trainer_py():
    """–ü—Ä–∏–º–µ–Ω—è–µ—Ç –ø–∞—Ç—á –∫ trainer.py"""
    print("\nüìù –ü–∞—Ç—á–∏–Ω–≥ trainer.py...")
    
    trainer_path = "training/trainer.py"
    backup_file(trainer_path)
    
    with open(trainer_path, 'r') as f:
        content = f.read()
    
    # –ü–∞—Ç—á 1: –î–æ–±–∞–≤–ª—è–µ–º –ø–æ–¥–¥–µ—Ä–∂–∫—É UnifiedPatchTST –≤ —Å–æ–∑–¥–∞–Ω–∏–µ loss
    if 'UnifiedPatchTST' not in content:
        old_loss = """# –ü—Ä–æ–≤–µ—Ä—è–µ–º –µ—Å–ª–∏ —ç—Ç–æ —Ç–æ—Ä–≥–æ–≤–∞—è loss —Ñ—É–Ω–∫—Ü–∏—è
        if 'trading' in loss_name:
            from models.trading_losses import get_trading_loss_function
            return get_trading_loss_function(self.config, loss_type='multi_task')"""
        
        new_loss = """# –ü—Ä–æ–≤–µ—Ä—è–µ–º –µ—Å–ª–∏ —ç—Ç–æ —Ç–æ—Ä–≥–æ–≤–∞—è loss —Ñ—É–Ω–∫—Ü–∏—è
        if 'trading' in loss_name:
            from models.trading_losses import get_trading_loss_function
            return get_trading_loss_function(self.config, loss_type='multi_task')
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –µ—Å–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —É–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –º–æ–¥–µ–ª—å
        model_name = self.config.get('model', {}).get('name', '')
        if model_name == 'UnifiedPatchTST':
            from models.patchtst_unified import UnifiedTradingLoss
            return UnifiedTradingLoss(self.config)"""
        
        content = content.replace(old_loss, new_loss)
    
    # –ü–∞—Ç—á 2: –£–ª—É—á—à–∞–µ–º _compute_loss –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å —Ç–µ–Ω–∑–æ—Ä–∞–º–∏
    compute_loss_start = content.find("def _compute_loss(self")
    if compute_loss_start != -1:
        # –ù–∞—Ö–æ–¥–∏–º –∫–æ–Ω–µ—Ü –º–µ—Ç–æ–¥–∞
        next_def = content.find("\n    def ", compute_loss_start + 1)
        if next_def == -1:
            next_def = len(content)
        
        # –ù–æ–≤–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è
        new_compute_loss = '''    def _compute_loss(self, outputs: Union[torch.Tensor, Dict], 
                     targets: Union[torch.Tensor, Dict]) -> torch.Tensor:
        """–í—ã—á–∏—Å–ª–µ–Ω–∏–µ –ø–æ—Ç–µ—Ä—å —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π —É–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏"""
        
        # –î–ª—è —É–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ - –ø—Ä—è–º–æ–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ loss
        if isinstance(outputs, torch.Tensor) and isinstance(targets, torch.Tensor):
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–µ–π
            if outputs.dim() == 2 and targets.dim() == 2:
                # –£–±–µ–∂–¥–∞–µ–º—Å—è —á—Ç–æ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ —Å–æ–≤–ø–∞–¥–∞—é—Ç
                if outputs.shape[-1] != targets.shape[-1]:
                    self.logger.warning(f"–†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ –Ω–µ —Å–æ–≤–ø–∞–¥–∞—é—Ç: outputs {outputs.shape} vs targets {targets.shape}")
                    min_size = min(outputs.shape[-1], targets.shape[-1])
                    outputs = outputs[..., :min_size]
                    targets = targets[..., :min_size]
                
                # –ü—Ä–∏–º–µ–Ω—è–µ–º loss –Ω–∞–ø—Ä—è–º—É—é
                loss = self.criterion(outputs, targets)
                
                # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ NaN/Inf
                if torch.isnan(loss) or torch.isinf(loss):
                    self.logger.warning("Loss is NaN/Inf, returning zero loss")
                    return torch.tensor(0.0, device=outputs.device, requires_grad=True)
                
                return loss
        
        # –î–ª—è —Å—Ç–∞—Ä–æ–π –ª–æ–≥–∏–∫–∏ —Å MultiTaskLoss
        if isinstance(self.criterion, MultiTaskLoss):
            # [–æ—Å—Ç–∞–≤–ª—è–µ–º —Å—Ç–∞—Ä—É—é –ª–æ–≥–∏–∫—É –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏]
            losses = {}
            
            if isinstance(outputs, dict) and isinstance(targets, dict):
                # ... —Å—Ç–∞—Ä–∞—è –ª–æ–≥–∏–∫–∞ ...
                pass
            
            return self.criterion(losses) if losses else torch.tensor(0.0, device=outputs.device)
        
        # Fallback –¥–ª—è –ø—Ä–æ—Å—Ç—ã—Ö —Å–ª—É—á–∞–µ–≤
        if isinstance(outputs, dict):
            outputs = list(outputs.values())[0]
        if isinstance(targets, dict):
            targets = list(targets.values())[0]
        
        return self.criterion(outputs, targets)'''
        
        # –ó–∞–º–µ–Ω—è–µ–º –º–µ—Ç–æ–¥
        content = content[:compute_loss_start] + new_compute_loss + content[next_def:]
    
    # –ü–∞—Ç—á 3: –î–æ–±–∞–≤–ª—è–µ–º –ø–æ–¥–¥–µ—Ä–∂–∫—É OneCycleLR
    scheduler_section = content.find("scheduler_name = scheduler_config.get('name'")
    if scheduler_section != -1 and "OneCycleLR" not in content[scheduler_section:scheduler_section+500]:
        insert_pos = content.find("return get_scheduler(", scheduler_section)
        if insert_pos != -1:
            patch = """
        # –°–ø–µ—Ü–∏–∞–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª—è OneCycleLR
        if scheduler_name == 'OneCycleLR':
            # OneCycleLR —Ç—Ä–µ–±—É–µ—Ç total_steps
            if hasattr(self, 'train_loader'):
                total_steps = self.epochs * len(self.train_loader)
            else:
                total_steps = self.epochs * 1000  # –ü—Ä–∏–º–µ—Ä–Ω–∞—è –æ—Ü–µ–Ω–∫–∞
            scheduler_config['params']['total_steps'] = total_steps
            scheduler_config['params']['epochs'] = self.epochs
        
        """
            content = content[:insert_pos] + patch + content[insert_pos:]
    
    with open(trainer_path, 'w') as f:
        f.write(content)
    
    print("‚úÖ trainer.py –æ–±–Ω–æ–≤–ª–µ–Ω")

def update_models_init():
    """–û–±–Ω–æ–≤–ª—è–µ—Ç models/__init__.py –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞ —É–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏"""
    print("\nüìù –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ models/__init__.py...")
    
    init_path = "models/__init__.py"
    
    if os.path.exists(init_path):
        backup_file(init_path)
        
        with open(init_path, 'r') as f:
            content = f.read()
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∏–º–ø–æ—Ä—Ç —É–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏
        if 'patchtst_unified' not in content:
            content += "\n# –£–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –º–æ–¥–µ–ª—å\nfrom .patchtst_unified import UnifiedPatchTSTForTrading, create_unified_model\n"
        
        with open(init_path, 'w') as f:
            f.write(content)
        
        print("‚úÖ models/__init__.py –æ–±–Ω–æ–≤–ª–µ–Ω")

def verify_integration():
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ø—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç—å –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏"""
    print("\nüîç –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏...")
    
    checks = []
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏–º–ø–æ—Ä—Ç–æ–≤ –≤ main.py
    with open('main.py', 'r') as f:
        main_content = f.read()
        checks.append(('UnifiedPatchTST –≤ main.py', 'UnifiedPatchTST' in main_content))
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ trainer.py
    with open('training/trainer.py', 'r') as f:
        trainer_content = f.read()
        checks.append(('UnifiedTradingLoss –≤ trainer.py', 'UnifiedTradingLoss' in trainer_content or 'UnifiedPatchTST' in trainer_content))
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ config.yaml
    with open('config/config.yaml', 'r') as f:
        config_content = f.read()
        checks.append(('UnifiedPatchTST –≤ config', 'name: UnifiedPatchTST' in config_content))
        checks.append(('output_size: 36 –≤ config', 'output_size: 36' in config_content))
        checks.append(('learning_rate: 0.001', 'learning_rate: 0.001' in config_content))
    
    # –í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    all_good = True
    for check_name, result in checks:
        if result:
            print(f"‚úÖ {check_name}")
        else:
            print(f"‚ùå {check_name}")
            all_good = False
    
    return all_good

def create_final_run_script():
    """–°–æ–∑–¥–∞–µ—Ç —Ñ–∏–Ω–∞–ª—å–Ω—ã–π —Å–∫—Ä–∏–ø—Ç –∑–∞–ø—É—Å–∫–∞"""
    print("\nüìù –°–æ–∑–¥–∞–Ω–∏–µ —Å–∫—Ä–∏–ø—Ç–∞ –∑–∞–ø—É—Å–∫–∞...")
    
    script = '''#!/bin/bash
# –§–∏–Ω–∞–ª—å–Ω—ã–π —Å–∫—Ä–∏–ø—Ç –∑–∞–ø—É—Å–∫–∞ –æ–±—É—á–µ–Ω–∏—è —Å —É–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª—å—é

echo "üöÄ –ó–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è —Å UnifiedPatchTST (36 –≤—ã—Ö–æ–¥–æ–≤)..."
echo "üìä –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è:"
echo "  - Learning Rate: 0.001 (—É–≤–µ–ª–∏—á–µ–Ω –≤ 10 —Ä–∞–∑)"
echo "  - Batch Size: 128 (—É–º–µ–Ω—å—à–µ–Ω –¥–ª—è —á–∞—Å—Ç—ã—Ö –æ–±–Ω–æ–≤–ª–µ–Ω–∏–π)"
echo "  - Scheduler: OneCycleLR"
echo "  - Model: UnifiedPatchTST —Å 36 –≤—ã—Ö–æ–¥–∞–º–∏"

# –ê–∫—Ç–∏–≤–∞—Ü–∏—è –æ–∫—Ä—É–∂–µ–Ω–∏—è
if [ -f "venv_crypto/bin/activate" ]; then
    source venv_crypto/bin/activate
fi

# –ü—Ä–æ–≤–µ—Ä–∫–∞ checkpoint
CHECKPOINT="models_saved/best_model_20250701_120952.pth"
if [ -f "$CHECKPOINT" ]; then
    echo "‚úÖ –ù–∞–π–¥–µ–Ω checkpoint: $CHECKPOINT"
    read -p "–ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å —Å checkpoint? (y/n): " -n 1 -r
    echo
    if [[ $REPLY =~ ^[Yy]$ ]]; then
        RESUME="--resume $CHECKPOINT"
    else
        RESUME=""
    fi
else
    RESUME=""
fi

# –ó–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è
echo "üèÉ –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ..."
python main.py --mode train \\
    --config config/config.yaml \\
    --log_every 50 \\
    --save_every 1 \\
    $RESUME

echo "‚úÖ –ì–æ—Ç–æ–≤–æ!"
'''
    
    with open('run_unified_training.sh', 'w') as f:
        f.write(script)
    
    os.chmod('run_unified_training.sh', 0o755)
    print("‚úÖ –°–æ–∑–¥–∞–Ω run_unified_training.sh")

def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    print("üîß –ò–ù–¢–ï–ì–†–ê–¶–ò–Ø –£–ù–ò–§–ò–¶–ò–†–û–í–ê–ù–ù–û–ô –ú–û–î–ï–õ–ò\n")
    
    # –í—ã–ø–æ–ª–Ω—è–µ–º –≤—Å–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è
    update_main_py()
    update_trainer_py()
    update_models_init()
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—é
    if verify_integration():
        print("\n‚úÖ –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")
        create_final_run_script()
        
        print("\nüìã –ò–ù–°–¢–†–£–ö–¶–ò–ò:")
        print("1. –û—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ —Ç–µ–∫—É—â–µ–µ –æ–±—É—á–µ–Ω–∏–µ (Ctrl+C)")
        print("2. –ó–∞–ø—É—Å—Ç–∏—Ç–µ: ./run_unified_training.sh")
        print("3. –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥: python web_monitor.py")
    else:
        print("\n‚ùå –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –ø—Ä–æ–±–ª–µ–º—ã! –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ñ–∞–π–ª—ã –≤—Ä—É—á–Ω—É—é.")

if __name__ == "__main__":
    main()