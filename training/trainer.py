"""
–û—Å–Ω–æ–≤–Ω–æ–π –º–æ–¥—É–ª—å –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π
"""

import torch
import torch.nn as nn
from torch.utils.data import DataLoader
from torch.cuda.amp import GradScaler, autocast
import numpy as np
from typing import Dict, List, Optional, Tuple, Callable, Union
from pathlib import Path
import time
from tqdm import tqdm
import json
from datetime import datetime

from utils.logger import get_logger
from models.losses import get_loss_function, MultiTaskLoss
from training.optimizer import get_optimizer, get_scheduler
from utils.metrics import MetricsTracker

class Trainer:
    """–û—Å–Ω–æ–≤–Ω–æ–π –∫–ª–∞—Å—Å –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π"""
    
    def __init__(self,
                 model: nn.Module,
                 config: Dict,
                 device: Optional[torch.device] = None):
        """
        Args:
            model: –º–æ–¥–µ–ª—å –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
            config: –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –æ–±—É—á–µ–Ω–∏—è
            device: —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
        """
        self.model = model
        self.config = config
        self.logger = get_logger("Trainer")
        
        # –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ
        if device is None:
            self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        else:
            self.device = device
        
        self.model.to(self.device)
        
        # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö GPU –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω—ã
        if torch.cuda.device_count() > 1 and self.device.type == 'cuda':
            self.logger.info(f"üî• –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è {torch.cuda.device_count()} GPU –¥–ª—è –æ–±—É—á–µ–Ω–∏—è")
            self.model = nn.DataParallel(self.model)
            self.is_data_parallel = True
        else:
            self.is_data_parallel = False
        
        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–±—É—á–µ–Ω–∏—è
        self.epochs = config['model']['epochs']
        self.learning_rate = config['model']['learning_rate']
        self.gradient_clip = config['model'].get('gradient_clip', 1.0)
        self.early_stopping_patience = config['model'].get('early_stopping_patience', 10)
        
        # Mixed precision training
        self.use_amp = config['performance'].get('mixed_precision', False)
        if self.use_amp:
            self.scaler = GradScaler()
        
        # –û–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä –∏ –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫
        self.optimizer = self._create_optimizer()
        self.scheduler = self._create_scheduler()
        
        # –§—É–Ω–∫—Ü–∏–∏ –ø–æ—Ç–µ—Ä—å
        self.criterion = self._create_loss_function()
        
        # –ú–µ—Ç—Ä–∏–∫–∏
        self.metrics_tracker = MetricsTracker(config)
        
        # –î–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
        self.checkpoint_dir = Path("models_saved")
        self.checkpoint_dir.mkdir(exist_ok=True)
        
        # –ò—Å—Ç–æ—Ä–∏—è –æ–±—É—á–µ–Ω–∏—è
        self.history = {
            'train_loss': [],
            'val_loss': [],
            'train_metrics': [],
            'val_metrics': [],
            'learning_rates': []
        }
        
        # Early stopping (—É–ª—É—á—à–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è –¥–ª—è –±–æ—Ä—å–±—ã —Å –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ–º)
        self.best_val_loss = float('inf')
        self.patience_counter = 0
        self.best_model_state = None
        self.min_delta = config['model'].get('min_delta', 1e-4)  # –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ
        self.overfitting_threshold = config['model'].get('overfitting_threshold', 0.1)  # –ü–æ—Ä–æ–≥ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è
        self.consecutive_overfitting = 0  # –°—á–µ—Ç—á–∏–∫ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ–≥–æ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è
        
    def _create_optimizer(self) -> torch.optim.Optimizer:
        """–°–æ–∑–¥–∞–Ω–∏–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–∞"""
        optimizer_config = self.config.get('optimizer', {})
        optimizer_name = optimizer_config.get('name', 'AdamW')
        
        return get_optimizer(
            optimizer_name,
            self.model.parameters(),
            lr=self.learning_rate,
            **optimizer_config.get('params', {})
        )
    
    def _create_scheduler(self) -> Optional[torch.optim.lr_scheduler._LRScheduler]:
        """–°–æ–∑–¥–∞–Ω–∏–µ –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫–∞ learning rate"""
        scheduler_config = self.config.get('scheduler', {})
        
        if not scheduler_config:
            return None
        
        scheduler_name = scheduler_config.get('name', 'CosineAnnealingLR')
        return get_scheduler(
            scheduler_name,
            self.optimizer,
            **scheduler_config.get('params', {})
        )
    
    def _create_loss_function(self) -> nn.Module:
        """–°–æ–∑–¥–∞–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏ –ø–æ—Ç–µ—Ä—å"""
        loss_config = self.config.get('loss', {})
        
        # –ú–Ω–æ–≥–æ–∑–∞–¥–∞—á–Ω–∞—è –ø–æ—Ç–µ—Ä—è –¥–ª—è —Ç–æ—Ä–≥–æ–≤–æ–π –º–æ–¥–µ–ª–∏
        if loss_config.get('multitask', False):
            task_losses = {}
            task_weights = {}
            
            # –ü–æ—Ç–µ—Ä—è –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Ü–µ–Ω—ã
            task_losses['price'] = get_loss_function(
                loss_config.get('price_loss', 'mse')
            )
            task_weights['price'] = loss_config.get('price_weight', 1.0)
            
            # –ü–æ—Ç–µ—Ä—è –¥–ª—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π TP
            task_losses['tp'] = get_loss_function(
                loss_config.get('tp_loss', 'bce')
            )
            task_weights['tp'] = loss_config.get('tp_weight', 1.0)
            
            # –ü–æ—Ç–µ—Ä—è –¥–ª—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ SL
            task_losses['sl'] = get_loss_function(
                loss_config.get('sl_loss', 'bce')
            )
            task_weights['sl'] = loss_config.get('sl_weight', 1.0)
            
            # –ü–æ—Ç–µ—Ä—è –¥–ª—è –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏
            task_losses['volatility'] = get_loss_function(
                loss_config.get('volatility_loss', 'mse')
            )
            task_weights['volatility'] = loss_config.get('volatility_weight', 0.5)
            
            return MultiTaskLoss(
                task_weights=task_weights,
                uncertainty_weighting=loss_config.get('uncertainty_weighting', False)
            )
        else:
            # –û–¥–Ω–∞ —Ñ—É–Ω–∫—Ü–∏—è –ø–æ—Ç–µ—Ä—å
            loss_name = loss_config.get('name', 'mse')
            return get_loss_function(loss_name, **loss_config.get('params', {}))
    
    def train_epoch(self, train_loader: DataLoader) -> Dict[str, float]:
        """–û–±—É—á–µ–Ω–∏–µ –æ–¥–Ω–æ–π —ç–ø–æ—Ö–∏"""
        self.model.train()
        
        epoch_loss = 0.0
        epoch_metrics = {}
        
        progress_bar = tqdm(train_loader, desc="Training", leave=False)
        
        for batch_idx, (inputs, targets, info) in enumerate(progress_bar):
            # –ü–µ—Ä–µ–Ω–æ—Å –Ω–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ
            inputs = inputs.to(self.device)
            if isinstance(targets, torch.Tensor):
                targets = targets.to(self.device)
            elif isinstance(targets, dict):
                targets = {k: v.to(self.device) for k, v in targets.items()}
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –Ω–∞ NaN
            if torch.isnan(inputs).any():
                self.logger.warning(f"NaN –≤–æ –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –±–∞—Ç—á–∞ {batch_idx}, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
                continue
                
            # Forward pass
            if self.use_amp:
                with autocast():
                    outputs = self.model(inputs)
                    loss = self._compute_loss(outputs, targets)
            else:
                outputs = self.model(inputs)
                loss = self._compute_loss(outputs, targets)
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ NaN/Inf
            if torch.isnan(loss) or torch.isinf(loss):
                self.logger.warning(f"Loss is NaN/Inf at batch {batch_idx}: {loss.item()}")
                # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞
                self.logger.warning(f"  Outputs stats: min={outputs.min().item():.4f}, max={outputs.max().item():.4f}, mean={outputs.mean().item():.4f}")
                if isinstance(targets, torch.Tensor):
                    self.logger.warning(f"  Targets stats: min={targets.min().item():.4f}, max={targets.max().item():.4f}, mean={targets.mean().item():.4f}")
                continue  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —ç—Ç–æ—Ç –±–∞—Ç—á
            
            # Backward pass
            self.optimizer.zero_grad()
            
            if self.use_amp:
                self.scaler.scale(loss).backward()
                
                # Gradient clipping
                if self.gradient_clip > 0:
                    self.scaler.unscale_(self.optimizer)
                    torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.gradient_clip)
                
                self.scaler.step(self.optimizer)
                self.scaler.update()
            else:
                loss.backward()
                
                # Gradient clipping —Å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–æ–π
                if self.gradient_clip > 0:
                    grad_norm = torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.gradient_clip)
                    if grad_norm > self.gradient_clip * 10:  # –°–ª–∏—à–∫–æ–º –±–æ–ª—å—à–∏–µ –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã
                        self.logger.warning(f"–û—á–µ–Ω—å –±–æ–ª—å—à–∞—è –Ω–æ—Ä–º–∞ –≥—Ä–∞–¥–∏–µ–Ω—Ç–∞: {grad_norm:.4f}")
                
                self.optimizer.step()
            
            # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫
            epoch_loss += loss.item()
            batch_metrics = self.metrics_tracker.metrics_calculator.compute_batch_metrics(outputs, targets)
            
            for key, value in batch_metrics.items():
                if key not in epoch_metrics:
                    epoch_metrics[key] = 0.0
                epoch_metrics[key] += value
            
            # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ progress bar
            progress_bar.set_postfix({
                'loss': f'{loss.item():.4f}',
                'avg_loss': f'{epoch_loss / (batch_idx + 1):.4f}'
            })
        
        # –£—Å—Ä–µ–¥–Ω–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫
        num_batches = len(train_loader)
        epoch_loss /= num_batches
        epoch_metrics = {k: v / num_batches for k, v in epoch_metrics.items()}
        epoch_metrics['loss'] = epoch_loss
        
        return epoch_metrics
    
    def validate(self, val_loader: DataLoader) -> Dict[str, float]:
        """–í–∞–ª–∏–¥–∞—Ü–∏—è –º–æ–¥–µ–ª–∏"""
        self.model.eval()
        
        val_loss = 0.0
        val_metrics = {}
        
        with torch.no_grad():
            for batch_idx, (inputs, targets, info) in enumerate(val_loader):
                # –ü–µ—Ä–µ–Ω–æ—Å –Ω–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ
                inputs = inputs.to(self.device)
                if isinstance(targets, torch.Tensor):
                    targets = targets.to(self.device)
                elif isinstance(targets, dict):
                    targets = {k: v.to(self.device) for k, v in targets.items()}
                
                # Forward pass
                if self.use_amp:
                    with autocast():
                        outputs = self.model(inputs)
                        loss = self._compute_loss(outputs, targets)
                else:
                    outputs = self.model(inputs)
                    loss = self._compute_loss(outputs, targets)
                
                # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫
                val_loss += loss.item()
                batch_metrics = self.metrics_tracker.metrics_calculator.compute_batch_metrics(outputs, targets)
                
                for key, value in batch_metrics.items():
                    if key not in val_metrics:
                        val_metrics[key] = 0.0
                    val_metrics[key] += value
        
        # –£—Å—Ä–µ–¥–Ω–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫
        num_batches = len(val_loader)
        val_loss /= num_batches
        val_metrics = {k: v / num_batches for k, v in val_metrics.items()}
        val_metrics['loss'] = val_loss
        
        return val_metrics
    
    def _compute_loss(self, outputs: Union[torch.Tensor, Dict], 
                     targets: Union[torch.Tensor, Dict]) -> torch.Tensor:
        """–í—ã—á–∏—Å–ª–µ–Ω–∏–µ –ø–æ—Ç–µ—Ä—å"""
        
        if isinstance(self.criterion, MultiTaskLoss):
            # –ú–Ω–æ–≥–æ–∑–∞–¥–∞—á–Ω–∞—è –ø–æ—Ç–µ—Ä—è
            losses = {}
            
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—ã—Ö–æ–¥–æ–≤ –∏ —Ü–µ–ª–µ–π
            if isinstance(outputs, dict) and isinstance(targets, dict):
                # –ü–æ–ª–Ω–∞—è –º–Ω–æ–≥–æ–∑–∞–¥–∞—á–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞
                if 'price_pred' in outputs and 'future_returns' in targets:
                    losses['price'] = self.criterion.task_losses['price'](
                        outputs['price_pred'], targets['future_returns']
                    )
                
                if 'tp_probs' in outputs and 'tp_targets' in targets:
                    losses['tp'] = self.criterion.task_losses['tp'](
                        outputs['tp_probs'], targets['tp_targets']
                    )
                
                if 'sl_prob' in outputs and 'sl_target' in targets:
                    losses['sl'] = self.criterion.task_losses['sl'](
                        outputs['sl_prob'], targets['sl_target']
                    )
                
                if 'volatility' in outputs and 'volatility_target' in targets:
                    losses['volatility'] = self.criterion.task_losses['volatility'](
                        outputs['volatility'], targets['volatility_target']
                    )
            else:
                # –ü—Ä–æ—Å—Ç–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ - –∏—Å–ø–æ–ª—å–∑—É–µ–º –±–∞–∑–æ–≤—É—é –ø–æ—Ç–µ—Ä—é –¥–ª—è —Ü–µ–Ω—ã
                if isinstance(outputs, dict):
                    outputs = outputs.get('price_pred', outputs.get('prediction', list(outputs.values())[0]))
                if isinstance(targets, dict):
                    targets = targets.get('future_returns', targets.get('target', list(targets.values())[0]))
                
                # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–µ–π
                outputs, targets = self._align_dimensions(outputs, targets)
                
                losses['price'] = self.criterion.task_losses['price'](outputs, targets)
            
            return self.criterion(losses) if losses else torch.tensor(0.0, device=outputs.device if torch.is_tensor(outputs) else 'cpu')
        else:
            # –ü—Ä–æ—Å—Ç–∞—è –ø–æ—Ç–µ—Ä—è
            if isinstance(outputs, dict):
                outputs = outputs.get('price_pred', outputs.get('prediction', list(outputs.values())[0]))
            if isinstance(targets, dict):
                targets = targets.get('future_returns', targets.get('target', list(targets.values())[0]))
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏ –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–µ–π
            outputs, targets = self._align_dimensions(outputs, targets)
            
            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ NaN –ø–µ—Ä–µ–¥ –≤—ã—á–∏—Å–ª–µ–Ω–∏–µ–º loss
            if torch.isnan(outputs).any() or torch.isnan(targets).any():
                self.logger.warning("NaN –æ–±–Ω–∞—Ä—É–∂–µ–Ω—ã –≤ outputs –∏–ª–∏ targets –ø–µ—Ä–µ–¥ –≤—ã—á–∏—Å–ª–µ–Ω–∏–µ–º loss")
                # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –±–æ–ª—å—à—É—é –Ω–æ –∫–æ–Ω–µ—á–Ω—É—é loss –≤–º–µ—Å—Ç–æ NaN
                return torch.tensor(1e6, device=outputs.device, requires_grad=True)
            
            return self.criterion(outputs, targets)
    
    def _align_dimensions(self, outputs: torch.Tensor, targets: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:
        """–í—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–µ–π –≤—ã—Ö–æ–¥–æ–≤ –∏ —Ü–µ–ª–µ–π"""
        if outputs.shape != targets.shape:
            # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è
            self.logger.debug(f"–ù–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–µ–π: outputs {outputs.shape}, targets {targets.shape}")
            
            # –ï—Å–ª–∏ —É outputs –µ—Å—Ç—å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–µ –∏–∑–º–µ—Ä–µ–Ω–∏–µ –ø–æ –ø—Ä–∏–∑–Ω–∞–∫–∞–º
            if outputs.dim() == 3 and targets.dim() == 3 and outputs.shape[-1] != targets.shape[-1]:
                # –ë–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ –Ω—É–∂–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏–∑ outputs
                if outputs.shape[-1] > targets.shape[-1]:
                    outputs = outputs[..., :targets.shape[-1]]
                else:
                    # –ò–ª–∏ –Ω–∞–æ–±–æ—Ä–æ—Ç, –µ—Å–ª–∏ targets –±–æ–ª—å—à–µ
                    targets = targets[..., :outputs.shape[-1]]
            
            # –ï—Å–ª–∏ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ –≤—Å–µ –µ—â–µ –Ω–µ —Å–æ–≤–ø–∞–¥–∞—é—Ç
            if outputs.shape != targets.shape:
                # –ü–æ–ø—ã—Ç–∫–∞ –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏—è –ø–æ –±–∞—Ç—á–∞–º –∏ –≤—Ä–µ–º–µ–Ω–Ω—ã–º —à–∞–≥–∞–º
                if outputs.dim() == 3 and targets.dim() == 2:
                    # outputs: (batch, time, features), targets: (batch, features)
                    # –ë–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π –≤—Ä–µ–º–µ–Ω–Ω–æ–π —à–∞–≥ –∏–∑ outputs
                    outputs = outputs[:, -1, :]
                elif outputs.dim() == 2 and targets.dim() == 3:
                    # outputs: (batch, features), targets: (batch, time, features)
                    # –ë–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π –≤—Ä–µ–º–µ–Ω–Ω–æ–π —à–∞–≥ –∏–∑ targets
                    targets = targets[:, -1, :]
                elif outputs.dim() == 3 and targets.dim() == 3:
                    # –û–±–∞ –∏–º–µ—é—Ç 3 –∏–∑–º–µ—Ä–µ–Ω–∏—è, –Ω–æ —Ä–∞–∑–Ω—ã–µ —Ä–∞–∑–º–µ—Ä—ã –ø–æ –≤—Ä–µ–º–µ–Ω–∏
                    min_time = min(outputs.shape[1], targets.shape[1])
                    outputs = outputs[:, :min_time, :]
                    targets = targets[:, :min_time, :]
                
                # –§–∏–Ω–∞–ª—å–Ω–∞—è –ø–æ–ø—ã—Ç–∫–∞ - flatten –¥–æ 2D
                if outputs.shape != targets.shape:
                    if outputs.dim() > 2:
                        outputs = outputs.reshape(outputs.shape[0], -1)
                    if targets.dim() > 2:
                        targets = targets.reshape(targets.shape[0], -1)
                    
                    # –í—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–µ –ø–æ –ø–æ—Å–ª–µ–¥–Ω–µ–º—É –∏–∑–º–µ—Ä–µ–Ω–∏—é
                    min_size = min(outputs.shape[-1], targets.shape[-1])
                    outputs = outputs[..., :min_size]
                    targets = targets[..., :min_size]
        
        return outputs, targets
    
    def train(self, 
              train_loader: DataLoader,
              val_loader: DataLoader,
              callbacks: Optional[List[Callable]] = None) -> Dict:
        """–ü–æ–ª–Ω—ã–π —Ü–∏–∫–ª –æ–±—É—á–µ–Ω–∏—è"""
        
        self.logger.info(f"–ù–∞—á–∞–ª–æ –æ–±—É—á–µ–Ω–∏—è –Ω–∞ {self.epochs} —ç–ø–æ—Ö")
        self.logger.info(f"–£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {self.device}")
        self.logger.info(f"–†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞: {train_loader.batch_size}")
        self.logger.info(f"Learning rate: {self.learning_rate}")
        
        start_time = time.time()
        
        for epoch in range(self.epochs):
            epoch_start_time = time.time()
            
            # –û–±—É—á–µ–Ω–∏–µ
            train_metrics = self.train_epoch(train_loader)
            
            # –í–∞–ª–∏–¥–∞—Ü–∏—è
            val_metrics = self.validate(val_loader)
            
            # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ learning rate
            current_lr = self.optimizer.param_groups[0]['lr']  # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–µ—Ä–µ–¥ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º
            
            if self.scheduler is not None:
                if isinstance(self.scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau):
                    old_lr = current_lr  # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å—Ç–∞—Ä–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
                    self.scheduler.step(val_metrics['loss'])
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏–∑–º–µ–Ω–µ–Ω–∏–µ LR
                    current_lr = self.optimizer.param_groups[0]['lr']
                    if old_lr != current_lr:
                        self.logger.info(f"üìâ Learning rate —Å–Ω–∏–∂–µ–Ω —Å {old_lr:.2e} –¥–æ {current_lr:.2e}")
                else:
                    self.scheduler.step()
                    current_lr = self.optimizer.param_groups[0]['lr']
            
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏—Å—Ç–æ—Ä–∏–∏
            self.history['train_loss'].append(train_metrics['loss'])
            self.history['val_loss'].append(val_metrics['loss'])
            self.history['train_metrics'].append(train_metrics)
            self.history['val_metrics'].append(val_metrics)
            self.history['learning_rates'].append(current_lr)
            
            # –£–ª—É—á—à–µ–Ω–Ω–∞—è –ª–æ–≥–∏–∫–∞ –±–æ—Ä—å–±—ã —Å –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ–º
            improvement = self.best_val_loss - val_metrics['loss']
            overfitting_ratio = val_metrics['loss'] / train_metrics['loss'] if train_metrics['loss'] > 0 else 1.0
            
            # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
            self.logger.info(f"üìä –ú–µ—Ç—Ä–∏–∫–∏ —ç–ø–æ—Ö–∏ {epoch + 1}: train_loss={train_metrics['loss']:.4f}, val_loss={val_metrics['loss']:.4f}, "
                           f"overfitting_ratio={overfitting_ratio:.3f}, improvement={improvement:.6f}, current_lr={current_lr:.2e}")
            
            if improvement > self.min_delta:
                # –ó–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ
                self.best_val_loss = val_metrics['loss']
                self.patience_counter = 0
                self.consecutive_overfitting = 0
                self.best_model_state = self.model.state_dict().copy()
                self._save_checkpoint(epoch, val_metrics['loss'], is_best=True)
                self.logger.info(f"‚úÖ –ù–æ–≤–∞—è –ª—É—á—à–∞—è –º–æ–¥–µ–ª—å! Val loss —É–ª—É—á—à–µ–Ω –Ω–∞ {improvement:.6f}")
            else:
                self.patience_counter += 1
                
                # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ —Å "–ø—Ä–æ–≥—Ä–µ–≤–æ–º"
                # –ù–µ –ø—Ä–æ–≤–µ—Ä—è–µ–º –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ –ø–µ—Ä–≤—ã–µ 3 —ç–ø–æ—Ö–∏ - –¥–∞–µ–º –º–æ–¥–µ–ª–∏ —Å—Ç–∞–±–∏–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å—Å—è
                if epoch >= 3:  # –ù–∞—á–∏–Ω–∞–µ–º –ø—Ä–æ–≤–µ—Ä–∫—É —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ 3-–π —ç–ø–æ—Ö–∏
                    if overfitting_ratio > (1.0 + self.overfitting_threshold):
                        self.consecutive_overfitting += 1
                        self.logger.warning(f"‚ö†Ô∏è  –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ! Train: {train_metrics['loss']:.4f}, Val: {val_metrics['loss']:.4f} (ratio: {overfitting_ratio:.3f})")
                        
                        # –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º—Å—è —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ 3 –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—ã—Ö –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–π
                        if self.consecutive_overfitting >= 3:
                            self.logger.info(f"üõë –û—Å—Ç–∞–Ω–æ–≤–∫–∞ –∏–∑-–∑–∞ —É—Å—Ç–æ–π—á–∏–≤–æ–≥–æ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è (3 —ç–ø–æ—Ö–∏ –ø–æ–¥—Ä—è–¥)")
                            break
                    else:
                        self.consecutive_overfitting = 0
                else:
                    # –ü–µ—Ä–≤—ã–µ 3 —ç–ø–æ—Ö–∏ - —Ç–æ–ª—å–∫–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
                    if overfitting_ratio > 1.5:  # 50% —Ä–∞–∑–Ω–∏—Ü–∞
                        self.logger.info(f"üìà –≠–ø–æ—Ö–∞ {epoch + 1}: –≤—ã—Å–æ–∫–∏–π val_loss –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ train_loss (ratio: {overfitting_ratio:.3f}), –Ω–æ —ç—Ç–æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ –≤ –Ω–∞—á–∞–ª–µ –æ–±—É—á–µ–Ω–∏—è")
            
            # –ö–†–ò–¢–ò–ß–ù–û: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ - –µ—Å–ª–∏ val_loss –Ω–µ —É–ª—É—á—à–∞–µ—Ç—Å—è —Å–ª–∏—à–∫–æ–º –¥–æ–ª–≥–æ
            if self.patience_counter >= self.early_stopping_patience:
                self.logger.info(f"üõë Early stopping: val_loss –Ω–µ —É–ª—É—á—à–∞–µ—Ç—Å—è {self.patience_counter} —ç–ø–æ—Ö (patience={self.early_stopping_patience})")
                break
            
            # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
            epoch_time = time.time() - epoch_start_time
            self.logger.log_model_metrics(
                epoch=epoch + 1,
                metrics={
                    'train_loss': train_metrics['loss'],
                    'val_loss': val_metrics['loss'],
                    'learning_rate': current_lr,
                    'epoch_time': epoch_time
                }
            )
            
            # Callbacks
            if callbacks:
                for callback in callbacks:
                    callback(self, epoch, train_metrics, val_metrics)
        
        # –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏
        if self.best_model_state is not None:
            self.model.load_state_dict(self.best_model_state)
        
        total_time = time.time() - start_time
        self.logger.info(f"–û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ –∑–∞ {total_time:.2f} —Å–µ–∫—É–Ω–¥")
        
        # –§–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç
        self._save_training_report()
        
        return self.history
    
    def _save_checkpoint(self, epoch: int, val_loss: float, is_best: bool = False):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ checkpoint'–∞"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω–æ –¥–ª—è DataParallel
        model_state = self.model.module.state_dict() if self.is_data_parallel else self.model.state_dict()
        
        checkpoint = {
            'epoch': epoch,
            'model_state_dict': model_state,
            'optimizer_state_dict': self.optimizer.state_dict(),
            'scheduler_state_dict': self.scheduler.state_dict() if self.scheduler else None,
            'val_loss': val_loss,
            'config': self.config,
            'history': self.history,
            'is_data_parallel': self.is_data_parallel
        }
        
        if is_best:
            path = self.checkpoint_dir / f"best_model_{timestamp}.pth"
        else:
            path = self.checkpoint_dir / f"checkpoint_epoch_{epoch}_{timestamp}.pth"
        
        torch.save(checkpoint, path)
        self.logger.info(f"Checkpoint —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {path}")
    
    def _save_training_report(self):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ—Ç—á–µ—Ç–∞ –æ–± –æ–±—É—á–µ–Ω–∏–∏"""
        report = {
            'config': self.config,
            'history': self.history,
            'best_val_loss': self.best_val_loss,
            'total_epochs': len(self.history['train_loss']),
            'model_architecture': str(self.model),
            'total_parameters': sum(p.numel() for p in self.model.parameters()),
            'trainable_parameters': sum(p.numel() for p in self.model.parameters() if p.requires_grad)
        }
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        report_path = self.checkpoint_dir / f"training_report_{timestamp}.json"
        
        with open(report_path, 'w') as f:
            json.dump(report, f, indent=4, default=str)
        
        self.logger.info(f"–û—Ç—á–µ—Ç –æ–± –æ–±—É—á–µ–Ω–∏–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {report_path}")
    
    def load_checkpoint(self, checkpoint_path: str):
        """–ó–∞–≥—Ä—É–∑–∫–∞ checkpoint'–∞"""
        checkpoint = torch.load(checkpoint_path, map_location=self.device)
        
        self.model.load_state_dict(checkpoint['model_state_dict'])
        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
        
        if self.scheduler and checkpoint.get('scheduler_state_dict'):
            self.scheduler.load_state_dict(checkpoint['scheduler_state_dict'])
        
        self.history = checkpoint.get('history', self.history)
        
        self.logger.info(f"Checkpoint –∑–∞–≥—Ä—É–∂–µ–Ω: {checkpoint_path}")
        
        return checkpoint['epoch']