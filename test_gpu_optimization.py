#!/usr/bin/env python3
"""
–¢–µ—Å—Ç –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–π GPU –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏
"""

import torch
import pandas as pd
import numpy as np
from pathlib import Path
import time
import yaml

from data.optimized_dataset import create_optimized_dataloaders
from training.optimized_trainer import OptimizedTrainer
from models.patchtst_unified import create_unified_model
from utils.logger import get_logger

def test_gpu_optimization():
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ pipeline"""
    logger = get_logger("GPUOptimizationTest")
    
    logger.info("üöÄ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ GPU –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–π")
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
    with open('config/config.yaml', 'r') as f:
        config = yaml.safe_load(f)
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ GPU
    if not torch.cuda.is_available():
        logger.error("‚ùå GPU –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω!")
        return
    
    device = torch.device('cuda')
    logger.info(f"‚úÖ –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è GPU: {torch.cuda.get_device_name()}")
    logger.info(f"   –ü–∞–º—è—Ç—å: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    logger.info("üìä –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö...")
    try:
        train_data = pd.read_parquet('cache/train_data.parquet')
        val_data = pd.read_parquet('cache/val_data.parquet')
        test_data = pd.read_parquet('cache/test_data.parquet')
        
        # –î–ª—è —Ç–µ—Å—Ç–∞ –±–µ—Ä–µ–º –Ω–µ–±–æ–ª—å—à—É—é —á–∞—Å—Ç—å
        train_data = train_data.head(50000)
        val_data = val_data.head(10000)
        test_data = test_data.head(10000)
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö: {e}")
        logger.info("–°–æ–∑–¥–∞–µ–º —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Ç–µ—Å—Ç–∞...")
        
        # –°–æ–∑–¥–∞–µ–º —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ
        n_samples = 50000
        n_features = 171
        n_targets = 37
        
        # –°–æ–∑–¥–∞–µ–º DataFrame —Å –Ω—É–∂–Ω—ã–º–∏ –∫–æ–ª–æ–Ω–∫–∞–º–∏
        feature_cols = [f'feature_{i}' for i in range(n_features)]
        target_cols = ['future_return_1', 'future_return_2', 'future_return_3', 'future_return_4',
                      'long_tp1_hit', 'long_tp1_time', 'long_tp2_hit', 'long_tp2_time',
                      'long_tp3_hit', 'long_tp3_time', 'long_sl_hit', 'long_sl_time',
                      'short_tp1_hit', 'short_tp1_time', 'short_tp2_hit', 'short_tp2_time',
                      'short_tp3_hit', 'short_tp3_time', 'short_sl_hit', 'short_sl_time',
                      'long_optimal_entry_improvement', 'short_optimal_entry_improvement',
                      'long_tp1_reached', 'long_tp2_reached', 'long_tp3_reached', 'long_sl_reached',
                      'short_tp1_reached', 'short_tp2_reached', 'short_tp3_reached', 'short_sl_reached',
                      'long_expected_value', 'short_expected_value',
                      'long_optimal_entry_time', 'short_optimal_entry_time',
                      'best_direction', 'signal_strength', 'target_return_1h']
        
        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö
        data = {}
        data['symbol'] = np.random.choice(['BTCUSDT', 'ETHUSDT'], n_samples)
        data['datetime'] = pd.date_range('2024-01-01', periods=n_samples, freq='15min')
        
        for col in feature_cols:
            data[col] = np.random.randn(n_samples).astype(np.float32)
        
        for col in target_cols:
            if 'hit' in col or 'reached' in col:
                data[col] = np.random.choice([0, 1], n_samples).astype(np.float32)
            elif col == 'best_direction':
                data[col] = np.random.choice([0, 1, 2], n_samples).astype(np.float32)
            else:
                data[col] = np.random.randn(n_samples).astype(np.float32)
        
        train_data = pd.DataFrame(data)
        val_data = train_data.copy()
        test_data = train_data.copy()
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –∫–æ–Ω—Ñ–∏–≥
        config['feature_cols'] = feature_cols
        config['target_cols'] = target_cols
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö DataLoader'–æ–≤
    logger.info("üîß –°–æ–∑–¥–∞–Ω–∏–µ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö DataLoader'–æ–≤...")
    start_time = time.time()
    
    train_loader, val_loader, test_loader = create_optimized_dataloaders(
        train_data, val_data, test_data, config, logger
    )
    
    logger.info(f"‚úÖ DataLoader'—ã —Å–æ–∑–¥–∞–Ω—ã –∑–∞ {time.time() - start_time:.1f}—Å")
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏
    logger.info("üèóÔ∏è –°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏...")
    model = create_unified_model(config)
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Ç—Ä–µ–Ω–µ—Ä–∞
    logger.info("üéØ –°–æ–∑–¥–∞–Ω–∏–µ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Ç—Ä–µ–Ω–µ—Ä–∞...")
    trainer = OptimizedTrainer(model, config, device)
    
    # –¢–µ—Å—Ç —Å–∫–æ—Ä–æ—Å—Ç–∏ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö
    logger.info("\nüìä –¢–µ—Å—Ç —Å–∫–æ—Ä–æ—Å—Ç–∏ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö:")
    test_batches = 10
    
    # –ë–µ–∑ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–π (–¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è)
    logger.info("1. –ë–∞–∑–æ–≤–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ (–±–µ–∑ pin_memory):")
    start = time.time()
    for i, (inputs, targets, info) in enumerate(train_loader):
        if i >= test_batches:
            break
        inputs = inputs.to(device)
        targets = targets.to(device)
    elapsed = time.time() - start
    logger.info(f"   –í—Ä–µ–º—è: {elapsed:.2f}—Å ({test_batches/elapsed:.1f} batches/s)")
    
    # –° –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è–º–∏
    logger.info("2. –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ (pin_memory + non_blocking):")
    start = time.time()
    for i, (inputs, targets, info) in enumerate(train_loader):
        if i >= test_batches:
            break
        inputs = inputs.to(device, non_blocking=True)
        targets = targets.to(device, non_blocking=True)
    torch.cuda.synchronize()
    elapsed = time.time() - start
    logger.info(f"   –í—Ä–µ–º—è: {elapsed:.2f}—Å ({test_batches/elapsed:.1f} batches/s)")
    
    # –¢–µ—Å—Ç –æ–¥–Ω–æ–π —ç–ø–æ—Ö–∏ –æ–±—É—á–µ–Ω–∏—è
    logger.info("\nüèÉ –¢–µ—Å—Ç –æ–±—É—á–µ–Ω–∏—è (1 —ç–ø–æ—Ö–∞):")
    
    # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –±–∞—Ç—á–µ–π –¥–ª—è —Ç–µ—Å—Ç–∞
    config['model']['epochs'] = 1
    trainer.epochs = 1
    
    # –ó–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è
    start = time.time()
    history = trainer.train(train_loader, val_loader)
    elapsed = time.time() - start
    
    logger.info(f"\n‚úÖ –¢–µ—Å—Ç –∑–∞–≤–µ—Ä—à–µ–Ω –∑–∞ {elapsed:.1f}—Å")
    logger.info(f"   Train loss: {history['train_loss'][-1]:.4f}")
    if history['val_loss']:
        logger.info(f"   Val loss: {history['val_loss'][-1]:.4f}")
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —É—Ç–∏–ª–∏–∑–∞—Ü–∏–∏ GPU
    if torch.cuda.is_available():
        logger.info("\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ GPU:")
        logger.info(f"   –í—ã–¥–µ–ª–µ–Ω–æ –ø–∞–º—è—Ç–∏: {torch.cuda.memory_allocated() / 1024**3:.2f} GB")
        logger.info(f"   –ó–∞—Ä–µ–∑–µ—Ä–≤–∏—Ä–æ–≤–∞–Ω–æ: {torch.cuda.memory_reserved() / 1024**3:.2f} GB")
        logger.info(f"   –ú–∞–∫—Å–∏–º—É–º –ø–∞–º—è—Ç–∏: {torch.cuda.max_memory_allocated() / 1024**3:.2f} GB")
    
    logger.info("\n‚úÖ –í—Å–µ —Ç–µ—Å—Ç—ã –ø—Ä–æ–π–¥–µ–Ω—ã —É—Å–ø–µ—à–Ω–æ!")
    
    # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
    logger.info("\nüí° –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –æ–±—É—á–µ–Ω–∏—è:")
    logger.info("1. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã:")
    logger.info("   - from data.optimized_dataset import create_optimized_dataloaders")
    logger.info("   - from training.optimized_trainer import OptimizedTrainer")
    logger.info("2. –£–±–µ–¥–∏—Ç–µ—Å—å —á—Ç–æ –≤ –∫–æ–Ω—Ñ–∏–≥–µ:")
    logger.info("   - num_workers: 4 (–∏–ª–∏ –±–æ–ª—å—à–µ)")
    logger.info("   - use_amp: true")
    logger.info("   - compile_model: true (–¥–ª—è PyTorch 2.0+)")
    logger.info("3. –ó–∞–ø—É—Å—Ç–∏—Ç–µ –ø–æ–ª–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ:")
    logger.info("   python main.py --mode train --use-optimized")


if __name__ == "__main__":
    test_gpu_optimization()