"""
Ð¡ÐºÑ€Ð¸Ð¿Ñ‚ Ð´Ð»Ñ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ ÑÐ¿ÐµÑ†Ð¸Ð°Ð»Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ð¾Ð¹ Ð¼Ð¾Ð´ÐµÐ»Ð¸ Ð¿Ñ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð¸Ñ Ð½Ð°Ð¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð¸Ñ
Ð¤Ð¾ÐºÑƒÑ Ð½Ð° Ð¼Ð°ÐºÑÐ¸Ð¼Ð¸Ð·Ð°Ñ†Ð¸Ð¸ directional accuracy Ð¸ Ð¿Ñ€Ð¸Ð±Ñ‹Ð»ÑŒÐ½Ð¾ÑÑ‚Ð¸
"""

import torch
import torch.nn as nn
from torch.utils.data import DataLoader
import numpy as np
import pandas as pd
from pathlib import Path
import argparse
from datetime import datetime
import json
from typing import Dict, List, Tuple
import matplotlib.pyplot as plt
import seaborn as sns
from tqdm import tqdm

from models.direction_predictor import DirectionPredictor, DirectionalTradingLoss
from data.dataset import TimeSeriesDataset
from data.data_loader import CryptoDataLoader
from training.trainer import Trainer
from utils.logger import get_logger, setup_logging
from utils.config import load_config
from utils.metrics import MetricsCalculator


class DirectionDatasetAdapter(TimeSeriesDataset):
    """ÐÐ´Ð°Ð¿Ñ‚ÐµÑ€ Ð´Ð»Ñ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸Ñ ÑÑƒÑ‰ÐµÑÑ‚Ð²ÑƒÑŽÑ‰ÐµÐ³Ð¾ Ð´Ð°Ñ‚Ð°ÑÐµÑ‚Ð° Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ñ direction targets"""
    
    def __init__(self, *args, **kwargs):
        # Ð¤Ð¸Ð»ÑŒÑ‚Ñ€ÑƒÐµÐ¼ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ direction targets
        if 'target_cols' in kwargs:
            kwargs['target_cols'] = [col for col in kwargs['target_cols'] 
                                   if col.startswith('direction_')]
        
        # ÐŸÐµÑ€ÐµÐ´Ð°ÐµÐ¼ normalize Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€
        if 'normalize' not in kwargs:
            kwargs['normalize'] = False
            
        super().__init__(*args, **kwargs)
        
        # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸ÑŽ Ð¾ Ñ†ÐµÐ½Ð¾Ð²Ñ‹Ñ… Ð¸Ð·Ð¼ÐµÐ½ÐµÐ½Ð¸ÑÑ… Ð´Ð»Ñ loss
        self.price_change_cols = [
            'future_return_15m', 'future_return_1h', 
            'future_return_4h', 'future_return_12h'
        ]
        
    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, Dict, Dict]:
        """Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚ features, targets Ð¸ price changes"""
        # Ð’Ñ‹Ð·Ñ‹Ð²Ð°ÐµÐ¼ Ð±Ð°Ð·Ð¾Ð²Ñ‹Ð¹ Ð¼ÐµÑ‚Ð¾Ð´ Ð´Ð»Ñ Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ñ Ð¾ÑÐ½Ð¾Ð²Ð½Ñ‹Ñ… Ð´Ð°Ð½Ð½Ñ‹Ñ…
        features_tensor, targets_tensor, base_info = super().__getitem__(idx)
        
        # ÐŸÑ€ÐµÐ¾Ð±Ñ€Ð°Ð·ÑƒÐµÐ¼ targets Ð² ÑÐ»Ð¾Ð²Ð°Ñ€ÑŒ Ð´Ð»Ñ direction Ð¼Ð¾Ð´ÐµÐ»Ð¸
        targets_dict = {}
        
        # Ð•ÑÐ»Ð¸ Ñƒ Ð½Ð°Ñ ÐµÑÑ‚ÑŒ direction targets
        if targets_tensor.numel() > 0:
            # targets_tensor Ð¸Ð¼ÐµÐµÑ‚ Ñ„Ð¾Ñ€Ð¼Ñƒ (1, n_targets) Ð¸Ð»Ð¸ (n_targets,)
            if targets_tensor.dim() > 1:
                targets_tensor = targets_tensor.squeeze(0)
                
            for i, col in enumerate(self.target_cols):
                if i < targets_tensor.shape[0]:
                    # ÐšÐ¾Ð½Ð²ÐµÑ€Ñ‚Ð¸Ñ€ÑƒÐµÐ¼ Ð² LongTensor Ð´Ð»Ñ ÐºÐ»Ð°ÑÑÐ¸Ñ„Ð¸ÐºÐ°Ñ†Ð¸Ð¸
                    # ÐšÐ°Ð¶Ð´Ñ‹Ð¹ target Ð´Ð¾Ð»Ð¶ÐµÐ½ Ð±Ñ‹Ñ‚ÑŒ ÑÐºÐ°Ð»ÑÑ€Ð¾Ð¼
                    # Ð‘ÐµÑ€ÐµÐ¼ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð¿ÐµÑ€Ð²Ð¾Ðµ Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ðµ, Ñ‚Ð°Ðº ÐºÐ°Ðº ÑÑ‚Ð¾ ÐºÐ°Ñ‚ÐµÐ³Ð¾Ñ€Ð¸Ð°Ð»ÑŒÐ½Ñ‹Ð¹ ÐºÐ¾Ð´
                    target_value = targets_tensor[i]
                    if target_value.numel() > 1:
                        target_value = target_value[0]  # Ð‘ÐµÑ€ÐµÐ¼ Ð¿ÐµÑ€Ð²Ð¾Ðµ Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ðµ
                    targets_dict[col] = target_value.long()
        
        # ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸ÑŽ Ð¾ Ð¸Ð½Ð´ÐµÐºÑÐ°Ñ… Ð¸Ð· Ð±Ð°Ð·Ð¾Ð²Ð¾Ð³Ð¾ ÐºÐ»Ð°ÑÑÐ°
        index_info = self.indices[idx]
        context_end = index_info['context_end_idx']
        
        # Price changes Ð´Ð»Ñ loss
        price_changes = {}
        for col in self.price_change_cols:
            if col in self.data.columns:
                change = self.data.iloc[context_end][col]
                timeframe = col.split('_')[-1]  # 15m, 1h, etc.
                price_changes[timeframe] = torch.FloatTensor([change / 100.0])  # ÐšÐ¾Ð½Ð²ÐµÑ€Ñ‚Ð¸Ñ€ÑƒÐµÐ¼ Ð² Ð´Ð¾Ð»Ð¸
        
        # ÐžÐ±Ð½Ð¾Ð²Ð»ÑÐµÐ¼ info
        info = base_info.copy()
        info['price_changes'] = price_changes
        
        return features_tensor, targets_dict, info


class DirectionModelTrainer(Trainer):
    """Ð¡Ð¿ÐµÑ†Ð¸Ð°Ð»Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ð¹ trainer Ð´Ð»Ñ direction Ð¼Ð¾Ð´ÐµÐ»Ð¸"""
    
    def __init__(self, model: nn.Module, config: Dict, device: torch.device = None):
        super().__init__(model, config, device)
        
        # Ð¡Ð¿ÐµÑ†Ð¸Ð°Ð»ÑŒÐ½Ð°Ñ loss Ð´Ð»Ñ direction
        self.criterion = DirectionalTradingLoss(
            commission=config.get('loss', {}).get('commission', 0.00055),
            profit_focus_weight=config.get('loss', {}).get('profit_focus_weight', 10.0)
        )
        
        # ÐœÐµÑ‚Ñ€Ð¸ÐºÐ¸ Ð´Ð»Ñ Ð¾Ñ‚ÑÐ»ÐµÐ¶Ð¸Ð²Ð°Ð½Ð¸Ñ
        self.metrics_history = {
            'directional_accuracy': [],
            'profit_factor': [],
            'win_rate': [],
            'avg_profit': [],
            'avg_loss': []
        }
        
    def train_epoch(self, train_loader: DataLoader) -> Dict[str, float]:
        """ÐžÐ±ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ñ Ñ€Ð°ÑÑ‡ÐµÑ‚Ð¾Ð¼ Ñ‚Ð¾Ñ€Ð³Ð¾Ð²Ñ‹Ñ… Ð¼ÐµÑ‚Ñ€Ð¸Ðº"""
        self.model.train()
        
        epoch_loss = 0.0
        all_predictions = []
        all_targets = []
        all_profits = []
        
        progress_bar = tqdm(train_loader, desc="Training", leave=False)
        self.optimizer.zero_grad(set_to_none=True)
        
        for batch_idx, (inputs, targets, info) in enumerate(progress_bar):
            # ÐŸÐµÑ€ÐµÐ½Ð¾Ñ Ð½Ð° ÑƒÑÑ‚Ñ€Ð¾Ð¹ÑÑ‚Ð²Ð¾
            inputs = inputs.to(self.device)
            targets = {k: v.to(self.device).squeeze() for k, v in targets.items()}
            price_changes = {k: v.to(self.device) for k, v in info['price_changes'].items()}
            
            # Forward pass
            if self.use_amp:
                with torch.cuda.amp.autocast():
                    outputs = self.model(inputs)
                    loss = self.criterion(outputs, targets, price_changes)
            else:
                outputs = self.model(inputs)
                loss = self.criterion(outputs, targets, price_changes)
            
            # Backward pass
            loss = loss / self.gradient_accumulation_steps
            
            if self.use_amp:
                self.scaler.scale(loss).backward()
            else:
                loss.backward()
            
            # Gradient accumulation
            if (batch_idx + 1) % self.gradient_accumulation_steps == 0:
                if self.use_amp:
                    self.scaler.unscale_(self.optimizer)
                    torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.gradient_clip)
                    self.scaler.step(self.optimizer)
                    self.scaler.update()
                else:
                    torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.gradient_clip)
                    self.optimizer.step()
                
                self.optimizer.zero_grad(set_to_none=True)
            
            # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ Ð´Ð»Ñ Ð¼ÐµÑ‚Ñ€Ð¸Ðº
            epoch_loss += loss.item() * self.gradient_accumulation_steps
            
            # Ð Ð°ÑÑ‡ÐµÑ‚ directional accuracy Ð¸ profit
            with torch.no_grad():
                for timeframe in ['4h']:  # Ð¤Ð¾ÐºÑƒÑ Ð½Ð° 4h ÐºÐ°Ðº Ð¾ÑÐ½Ð¾Ð²Ð½Ð¾Ð¼
                    key = f'direction_{timeframe}'
                    if key in outputs:
                        pred_direction = outputs[key].argmax(dim=1)
                        true_direction = targets[key]
                        
                        # Directional accuracy
                        correct = (pred_direction == true_direction).float()
                        all_predictions.extend(pred_direction.cpu().numpy())
                        all_targets.extend(true_direction.cpu().numpy())
                        
                        # Ð Ð°ÑÑ‡ÐµÑ‚ Ð¿Ñ€Ð¸Ð±Ñ‹Ð»Ð¸ (ÑƒÐ¿Ñ€Ð¾Ñ‰ÐµÐ½Ð½Ñ‹Ð¹)
                        price_change = price_changes[timeframe].squeeze()
                        profits = torch.zeros_like(price_change)
                        
                        # LONG
                        long_mask = pred_direction == 0
                        profits[long_mask] = price_change[long_mask] - 0.001  # Ð¼Ð¸Ð½ÑƒÑ ÐºÐ¾Ð¼Ð¸ÑÑÐ¸Ñ
                        
                        # SHORT
                        short_mask = pred_direction == 1
                        profits[short_mask] = -price_change[short_mask] - 0.001
                        
                        all_profits.extend(profits.cpu().numpy())
            
            # ÐžÐ±Ð½Ð¾Ð²Ð»ÐµÐ½Ð¸Ðµ progress bar
            progress_bar.set_postfix({
                'loss': f'{loss.item():.4f}',
                'dir_acc': f'{np.mean(correct.cpu().numpy()):.2%}'
            })
        
        # Ð Ð°ÑÑ‡ÐµÑ‚ Ð¼ÐµÑ‚Ñ€Ð¸Ðº ÑÐ¿Ð¾Ñ…Ð¸
        metrics = self._calculate_trading_metrics(all_predictions, all_targets, all_profits)
        metrics['loss'] = epoch_loss / len(train_loader)
        
        return metrics
    
    def _calculate_trading_metrics(self, predictions: List, targets: List, profits: List) -> Dict:
        """Ð Ð°ÑÑ‡ÐµÑ‚ Ñ‚Ð¾Ñ€Ð³Ð¾Ð²Ñ‹Ñ… Ð¼ÐµÑ‚Ñ€Ð¸Ðº"""
        predictions = np.array(predictions)
        targets = np.array(targets)
        profits = np.array(profits)
        
        # Directional accuracy (Ð¸ÑÐºÐ»ÑŽÑ‡Ð°Ñ FLAT)
        non_flat_mask = targets != 2
        if non_flat_mask.sum() > 0:
            directional_accuracy = (predictions[non_flat_mask] == targets[non_flat_mask]).mean()
        else:
            directional_accuracy = 0.0
        
        # Ð¢Ð¾Ñ€Ð³Ð¾Ð²Ñ‹Ðµ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸
        trading_mask = predictions != 2  # ÐšÐ¾Ð³Ð´Ð° Ð¼Ð¾Ð´ÐµÐ»ÑŒ Ñ€ÐµÑˆÐ¸Ð»Ð° Ñ‚Ð¾Ñ€Ð³Ð¾Ð²Ð°Ñ‚ÑŒ
        if trading_mask.sum() > 0:
            trading_profits = profits[trading_mask]
            
            winning_trades = trading_profits > 0
            win_rate = winning_trades.mean()
            
            if winning_trades.sum() > 0:
                avg_profit = trading_profits[winning_trades].mean()
            else:
                avg_profit = 0.0
                
            losing_trades = trading_profits < 0
            if losing_trades.sum() > 0:
                avg_loss = abs(trading_profits[losing_trades].mean())
            else:
                avg_loss = 0.0
                
            if avg_loss > 0:
                profit_factor = avg_profit / avg_loss
            else:
                profit_factor = float('inf') if avg_profit > 0 else 0.0
        else:
            win_rate = 0.0
            avg_profit = 0.0
            avg_loss = 0.0
            profit_factor = 0.0
        
        return {
            'directional_accuracy': directional_accuracy,
            'win_rate': win_rate,
            'avg_profit': avg_profit,
            'avg_loss': avg_loss,
            'profit_factor': profit_factor,
            'total_trades': trading_mask.sum()
        }
    
    def log_epoch_results(self, epoch: int, train_metrics: Dict, val_metrics: Dict):
        """Ð›Ð¾Ð³Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ Ñ Ñ„Ð¾ÐºÑƒÑÐ¾Ð¼ Ð½Ð° Ñ‚Ð¾Ñ€Ð³Ð¾Ð²Ñ‹Ðµ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸"""
        self.logger.info(f"\n{'='*60}")
        self.logger.info(f"Ð­Ð¿Ð¾Ñ…Ð° {epoch + 1} Ð·Ð°Ð²ÐµÑ€ÑˆÐµÐ½Ð°")
        self.logger.info(f"{'='*60}")
        
        self.logger.info("ðŸ“Š ÐžÑÐ½Ð¾Ð²Ð½Ñ‹Ðµ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸:")
        self.logger.info(f"  Train Loss: {train_metrics['loss']:.4f}, Val Loss: {val_metrics['loss']:.4f}")
        self.logger.info(f"  Train Dir Acc: {train_metrics['directional_accuracy']:.2%}, "
                        f"Val Dir Acc: {val_metrics['directional_accuracy']:.2%}")
        
        self.logger.info("\nðŸ’° Ð¢Ð¾Ñ€Ð³Ð¾Ð²Ñ‹Ðµ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸ (Val):")
        self.logger.info(f"  Win Rate: {val_metrics['win_rate']:.2%}")
        self.logger.info(f"  Profit Factor: {val_metrics['profit_factor']:.2f}")
        self.logger.info(f"  Avg Profit: {val_metrics['avg_profit']:.4%}")
        self.logger.info(f"  Avg Loss: {val_metrics['avg_loss']:.4%}")
        self.logger.info(f"  Total Trades: {val_metrics['total_trades']}")
        
        # ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ° Ð³Ð¾Ñ‚Ð¾Ð²Ð½Ð¾ÑÑ‚Ð¸ Ðº Ñ‚Ð¾Ñ€Ð³Ð¾Ð²Ð»Ðµ
        is_profitable = (
            val_metrics['directional_accuracy'] > 0.55 and
            val_metrics['win_rate'] > 0.50 and
            val_metrics['profit_factor'] > 1.2
        )
        
        if is_profitable:
            self.logger.info("\nâœ… ÐœÐ¾Ð´ÐµÐ»ÑŒ Ð¿Ð¾ÐºÐ°Ð·Ñ‹Ð²Ð°ÐµÑ‚ ÐŸÐ Ð˜Ð‘Ð«Ð›Ð¬ÐÐ«Ð• Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹!")
        else:
            self.logger.info("\nâš ï¸ ÐœÐ¾Ð´ÐµÐ»ÑŒ ÐµÑ‰Ðµ ÐÐ• Ð³Ð¾Ñ‚Ð¾Ð²Ð° Ðº Ð¿Ñ€Ð¸Ð±Ñ‹Ð»ÑŒÐ½Ð¾Ð¹ Ñ‚Ð¾Ñ€Ð³Ð¾Ð²Ð»Ðµ")


def create_direction_config(base_config: Dict) -> Dict:
    """Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¸Ðµ ÑÐ¿ÐµÑ†Ð¸Ð°Ð»Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ð¾Ð¹ ÐºÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸Ð¸ Ð´Ð»Ñ direction Ð¼Ð¾Ð´ÐµÐ»Ð¸"""
    config = base_config.copy()
    
    # ÐœÐ¾Ð´Ð¸Ñ„Ð¸ÐºÐ°Ñ†Ð¸Ð¸ Ð´Ð»Ñ direction Ð¼Ð¾Ð´ÐµÐ»Ð¸
    config['model']['name'] = 'DirectionPredictor'
    # n_features Ð±ÑƒÐ´ÐµÑ‚ ÑƒÑÑ‚Ð°Ð½Ð¾Ð²Ð»ÐµÐ½ Ð¿Ð¾Ð·Ð¶Ðµ Ð¸Ð· Ð´Ð°Ð½Ð½Ñ‹Ñ…
    config['model']['n_features'] = 254  # Ð’Ñ€ÐµÐ¼ÐµÐ½Ð½Ð¾, Ð±ÑƒÐ´ÐµÑ‚ Ð¾Ð±Ð½Ð¾Ð²Ð»ÐµÐ½Ð¾
    
    # ÐžÐ¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ðµ Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ñ‹ Ð´Ð»Ñ direction
    config['model']['learning_rate'] = 1e-4  # Ð’Ñ‹ÑˆÐµ Ð´Ð»Ñ Ð±Ñ‹ÑÑ‚Ñ€Ð¾Ð¹ ÑÑ…Ð¾Ð´Ð¸Ð¼Ð¾ÑÑ‚Ð¸
    config['model']['batch_size'] = 256  # ÐœÐµÐ½ÑŒÑˆÐµ Ð´Ð»Ñ Ð»ÑƒÑ‡ÑˆÐµÐ¹ Ð³ÐµÐ½ÐµÑ€Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ð¸
    config['model']['dropout'] = 0.3  # Ð‘Ð¾Ð»ÑŒÑˆÐµ dropout Ð¿Ñ€Ð¾Ñ‚Ð¸Ð² Ð¿ÐµÑ€ÐµÐ¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ
    
    # Scheduler Ð´Ð»Ñ direction
    config['scheduler'] = {
        'name': 'CosineAnnealingWarmRestarts',
        'params': {
            'T_0': 10,
            'T_mult': 2,
            'eta_min': 1e-6
        }
    }
    
    return config


def visualize_results(history: Dict, save_path: Path):
    """Ð’Ð¸Ð·ÑƒÐ°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¾Ð² Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ñ"""
    fig, axes = plt.subplots(2, 2, figsize=(15, 10))
    fig.suptitle('Direction Model Training Results', fontsize=16)
    
    # Loss
    ax = axes[0, 0]
    ax.plot(history['train_loss'], label='Train Loss')
    ax.plot(history['val_loss'], label='Val Loss')
    ax.set_xlabel('Epoch')
    ax.set_ylabel('Loss')
    ax.set_title('Training Progress')
    ax.legend()
    ax.grid(True)
    
    # Directional Accuracy
    ax = axes[0, 1]
    train_acc = [m.get('directional_accuracy', 0) for m in history['train_metrics']]
    val_acc = [m.get('directional_accuracy', 0) for m in history['val_metrics']]
    ax.plot(train_acc, label='Train Accuracy')
    ax.plot(val_acc, label='Val Accuracy')
    ax.axhline(y=0.55, color='r', linestyle='--', label='Profitable Threshold')
    ax.set_xlabel('Epoch')
    ax.set_ylabel('Directional Accuracy')
    ax.set_title('Directional Accuracy Progress')
    ax.legend()
    ax.grid(True)
    
    # Win Rate
    ax = axes[1, 0]
    val_wr = [m.get('win_rate', 0) for m in history['val_metrics']]
    ax.plot(val_wr, label='Val Win Rate')
    ax.axhline(y=0.50, color='r', linestyle='--', label='Break Even')
    ax.set_xlabel('Epoch')
    ax.set_ylabel('Win Rate')
    ax.set_title('Win Rate Progress')
    ax.legend()
    ax.grid(True)
    
    # Profit Factor
    ax = axes[1, 1]
    val_pf = [m.get('profit_factor', 0) for m in history['val_metrics']]
    ax.plot(val_pf, label='Val Profit Factor')
    ax.axhline(y=1.0, color='r', linestyle='--', label='Break Even')
    ax.axhline(y=1.5, color='g', linestyle='--', label='Good')
    ax.set_xlabel('Epoch')
    ax.set_ylabel('Profit Factor')
    ax.set_title('Profit Factor Progress')
    ax.legend()
    ax.grid(True)
    
    plt.tight_layout()
    plt.savefig(save_path / 'direction_training_results.png', dpi=300, bbox_inches='tight')
    plt.close()
    
    # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ðµ Ñ„Ð¸Ð½Ð°Ð»ÑŒÐ½Ð¾Ð³Ð¾ Ð¾Ñ‚Ñ‡ÐµÑ‚Ð°
    final_metrics = history['val_metrics'][-1] if history['val_metrics'] else {}
    report = f"""
DIRECTION MODEL TRAINING REPORT
==============================

Final Validation Metrics:
- Directional Accuracy: {final_metrics.get('directional_accuracy', 0):.2%}
- Win Rate: {final_metrics.get('win_rate', 0):.2%}
- Profit Factor: {final_metrics.get('profit_factor', 0):.2f}
- Average Profit: {final_metrics.get('avg_profit', 0):.4%}
- Average Loss: {final_metrics.get('avg_loss', 0):.4%}

Model Status: {'PROFITABLE' if final_metrics.get('directional_accuracy', 0) > 0.55 else 'NOT YET PROFITABLE'}
Recommended for Trading: {'YES' if final_metrics.get('profit_factor', 0) > 1.5 else 'NO'}
"""
    
    with open(save_path / 'direction_model_report.txt', 'w') as f:
        f.write(report)


def main():
    parser = argparse.ArgumentParser(description='Train Direction Prediction Model')
    parser.add_argument('--config', type=str, default='config/config.yaml',
                       help='Path to config file')
    parser.add_argument('--symbol', type=str, default=None,
                       help='Train on specific symbol only')
    parser.add_argument('--epochs', type=int, default=50,
                       help='Number of epochs')
    parser.add_argument('--resume', type=str, default=None,
                       help='Resume from checkpoint')
    
    args = parser.parse_args()
    
    # Setup
    config = load_config(args.config)
    config = create_direction_config(config)
    
    if args.epochs:
        config['model']['epochs'] = args.epochs
    
    # Ð›Ð¾Ð³Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    log_dir = Path(f"logs/direction_training_{timestamp}")
    log_dir.mkdir(parents=True, exist_ok=True)
    
    # ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ° Ð»Ð¾Ð³Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ
    import logging
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler(log_dir / "training.log"),
            logging.StreamHandler()
        ]
    )
    logger = get_logger("DirectionTraining")
    
    logger.info("ðŸŽ¯ ÐÐ°Ñ‡Ð¸Ð½Ð°ÐµÐ¼ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ðµ Direction Prediction Model")
    logger.info(f"ÐšÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸Ñ: {json.dumps(config['model'], indent=2)}")
    
    # Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ð´Ð°Ð½Ð½Ñ‹Ñ…
    logger.info("ðŸ“Š Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ð´Ð°Ð½Ð½Ñ‹Ñ…...")
    
    # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ ÑÑƒÑ‰ÐµÑÑ‚Ð²ÑƒÑŽÑ‰Ð¸Ðµ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ð½Ð½Ñ‹Ðµ Ð´Ð°Ð½Ð½Ñ‹Ðµ
    processed_train = Path("data/processed/train_data.parquet")
    processed_val = Path("data/processed/val_data.parquet")
    processed_test = Path("data/processed/test_data.parquet")
    
    if processed_train.exists() and processed_val.exists() and not args.symbol:
        logger.info("ðŸ“‚ ÐÐ°Ð¹Ð´ÐµÐ½Ñ‹ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ð½Ð½Ñ‹Ðµ Ð´Ð°Ð½Ð½Ñ‹Ðµ, Ð·Ð°Ð³Ñ€ÑƒÐ¶Ð°ÐµÐ¼...")
        
        try:
            import pandas as pd
            train_data = pd.read_parquet(processed_train)
            val_data = pd.read_parquet(processed_val)
            test_data = pd.read_parquet(processed_test)
            
            logger.info(f"âœ… Ð—Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ð¾ Ð¸Ð· processed: train={len(train_data)}, val={len(val_data)}, test={len(test_data)}")
            logger.info(f"ðŸ“… ÐŸÐµÑ€Ð¸Ð¾Ð´ Ð´Ð°Ð½Ð½Ñ‹Ñ…: {train_data['datetime'].min()} - {test_data['datetime'].max()}")
            logger.info(f"ðŸª™ Ð¡Ð¸Ð¼Ð²Ð¾Ð»Ñ‹: {train_data['symbol'].unique()}")
            
            # ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ ÑÐ¿Ð¸ÑÐºÐ¸ ÐºÐ¾Ð»Ð¾Ð½Ð¾Ðº Ð¸Ð· Ð´Ð°Ð½Ð½Ñ‹Ñ…
            feature_columns = [col for col in train_data.columns 
                             if col not in ['id', 'symbol', 'datetime', 'timestamp']
                             and not col.startswith(('target_', 'future_', 'direction_', 'optimal_'))]
            
            target_columns = [col for col in train_data.columns 
                            if col.startswith('direction_')]
            
            logger.info(f"ðŸ“Š ÐŸÑ€Ð¸Ð·Ð½Ð°ÐºÐ¾Ð²: {len(feature_columns)}, Ð¦ÐµÐ»ÐµÐ²Ñ‹Ñ…: {len(target_columns)}")
            
        except Exception as e:
            logger.warning(f"âš ï¸ ÐžÑˆÐ¸Ð±ÐºÐ° Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÐ¸ processed Ð´Ð°Ð½Ð½Ñ‹Ñ…: {e}")
            logger.info("Ð—Ð°Ð³Ñ€ÑƒÐ¶Ð°ÐµÐ¼ Ð´Ð°Ð½Ð½Ñ‹Ðµ ÑÑ‚Ð°Ð½Ð´Ð°Ñ€Ñ‚Ð½Ñ‹Ð¼ ÑÐ¿Ð¾ÑÐ¾Ð±Ð¾Ð¼...")
            
            data_loader = CryptoDataLoader(config)
            if args.symbol:
                data = data_loader.load_data(symbols=[args.symbol])
            else:
                # ÐÐ°Ñ‡Ð¸Ð½Ð°ÐµÐ¼ Ñ Ñ‚Ð¾Ð¿ ÑÐ¸Ð¼Ð²Ð¾Ð»Ð¾Ð²
                top_symbols = ['BTCUSDT', 'ETHUSDT', 'SOLUSDT', 'BNBUSDT']
                data = data_loader.load_data(symbols=top_symbols)
            
            train_data, val_data, test_data = data_loader.split_data(data)
            feature_columns = data_loader.feature_columns
            target_columns = data_loader.target_columns
    else:
        # Ð¡Ñ‚Ð°Ð½Ð´Ð°Ñ€Ñ‚Ð½Ð°Ñ Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÐ°
        data_loader = CryptoDataLoader(config)
        
        if args.symbol:
            data = data_loader.load_data(symbols=[args.symbol])
        else:
            # ÐÐ°Ñ‡Ð¸Ð½Ð°ÐµÐ¼ Ñ Ñ‚Ð¾Ð¿ ÑÐ¸Ð¼Ð²Ð¾Ð»Ð¾Ð²
            top_symbols = ['BTCUSDT', 'ETHUSDT', 'SOLUSDT', 'BNBUSDT']
            data = data_loader.load_data(symbols=top_symbols)
        
        # ÐŸÐ¾Ð´Ð³Ð¾Ñ‚Ð¾Ð²ÐºÐ° Ð´Ð°Ñ‚Ð°ÑÐµÑ‚Ð¾Ð²
        logger.info("ðŸ”§ ÐŸÐ¾Ð´Ð³Ð¾Ñ‚Ð¾Ð²ÐºÐ° Ð´Ð°Ñ‚Ð°ÑÐµÑ‚Ð¾Ð²...")
        train_data, val_data, test_data = data_loader.split_data(data)
        feature_columns = data_loader.feature_columns
        target_columns = data_loader.target_columns
    
    # Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¸Ðµ Ð´Ð°Ñ‚Ð°ÑÐµÑ‚Ð¾Ð² Ñ Ð°Ð´Ð°Ð¿Ñ‚ÐµÑ€Ð¾Ð¼
    train_dataset = DirectionDatasetAdapter(
        train_data,
        context_window=config['model']['context_window'],
        feature_cols=feature_columns,
        target_cols=target_columns,
        stride=1,  # Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ Ð²ÑÐµ Ð´Ð°Ð½Ð½Ñ‹Ðµ
        normalize=False  # ÐžÑ‚ÐºÐ»ÑŽÑ‡Ð°ÐµÐ¼ Ð½Ð¾Ñ€Ð¼Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸ÑŽ Ð´Ð»Ñ Ð¿Ñ€Ð¾ÑÑ‚Ð¾Ñ‚Ñ‹
    )
    
    val_dataset = DirectionDatasetAdapter(
        val_data,
        context_window=config['model']['context_window'],
        feature_cols=feature_columns,
        target_cols=target_columns,
        stride=4,  # ÐœÐµÐ½ÑŒÑˆÐµ Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð´Ð»Ñ Ð²Ð°Ð»Ð¸Ð´Ð°Ñ†Ð¸Ð¸
        normalize=False  # ÐžÑ‚ÐºÐ»ÑŽÑ‡Ð°ÐµÐ¼ Ð½Ð¾Ñ€Ð¼Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸ÑŽ Ð´Ð»Ñ Ð¿Ñ€Ð¾ÑÑ‚Ð¾Ñ‚Ñ‹
    )
    
    # DataLoaders
    train_loader = DataLoader(
        train_dataset,
        batch_size=config['model']['batch_size'],
        shuffle=True,
        num_workers=config['performance']['num_workers'],
        pin_memory=config['performance']['pin_memory']
    )
    
    val_loader = DataLoader(
        val_dataset,
        batch_size=config['model']['batch_size'],
        shuffle=False,
        num_workers=config['performance']['num_workers'],
        pin_memory=config['performance']['pin_memory']
    )
    
    logger.info(f"âœ… Ð”Ð°Ð½Ð½Ñ‹Ðµ Ð·Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ñ‹: {len(train_dataset)} train, {len(val_dataset)} val")
    
    # ÐžÐ±Ð½Ð¾Ð²Ð»ÑÐµÐ¼ n_features Ð² ÐºÐ¾Ð½Ñ„Ð¸Ð³Ðµ
    config['model']['n_features'] = len(feature_columns)
    
    # Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¸Ðµ Ð¼Ð¾Ð´ÐµÐ»Ð¸
    logger.info("ðŸ—ï¸ Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¸Ðµ Ð¼Ð¾Ð´ÐµÐ»Ð¸...")
    model = DirectionPredictor(config['model'])
    
    # Trainer
    trainer = DirectionModelTrainer(model, config)
    
    # Resume ÐµÑÐ»Ð¸ ÑƒÐºÐ°Ð·Ð°Ð½Ð¾
    start_epoch = 0
    if args.resume:
        logger.info(f"ðŸ“‚ Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° checkpoint: {args.resume}")
        start_epoch = trainer.load_checkpoint(args.resume)
    
    # ÐžÐ±ÑƒÑ‡ÐµÐ½Ð¸Ðµ
    logger.info("ðŸš€ ÐÐ°Ñ‡Ð¸Ð½Ð°ÐµÐ¼ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ðµ...")
    
    for epoch in range(start_epoch, config['model']['epochs']):
        # Train
        train_metrics = trainer.train_epoch(train_loader)
        
        # Validate
        val_metrics = trainer.validate(val_loader)
        
        # Update learning rate
        if trainer.scheduler:
            if hasattr(trainer.scheduler, 'step'):
                if isinstance(trainer.scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau):
                    trainer.scheduler.step(val_metrics['loss'])
                else:
                    trainer.scheduler.step()
        
        # Logging
        trainer.log_epoch_results(epoch, train_metrics, val_metrics)
        
        # Save checkpoint if best
        if val_metrics.get('directional_accuracy', 0) > getattr(trainer, 'best_metric', 0):
            trainer.best_metric = val_metrics['directional_accuracy']
            # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ Ñ Ð¿Ñ€Ð°Ð²Ð¸Ð»ÑŒÐ½Ñ‹Ð¼ Ð¸Ð¼ÐµÐ½ÐµÐ¼ Ð´Ð»Ñ direction Ð¼Ð¾Ð´ÐµÐ»Ð¸
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            checkpoint_path = Path("models_saved") / f"best_direction_model_{timestamp}.pth"
            
            checkpoint = {
                'epoch': epoch,
                'model_state_dict': trainer.model.state_dict(),
                'optimizer_state_dict': trainer.optimizer.state_dict(),
                'scheduler_state_dict': trainer.scheduler.state_dict() if trainer.scheduler else None,
                'val_loss': val_metrics['loss'],
                'val_metrics': val_metrics,
                'config': config,
                'history': trainer.history
            }
            
            torch.save(checkpoint, checkpoint_path)
            logger.info(f"ðŸ’¾ Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð° Ð»ÑƒÑ‡ÑˆÐ°Ñ Ð¼Ð¾Ð´ÐµÐ»ÑŒ Ñ accuracy: {trainer.best_metric:.2%}")
            logger.info(f"ðŸ“ ÐŸÑƒÑ‚ÑŒ: {checkpoint_path}")
        
        # Early stopping Ð½Ð° Ð¾ÑÐ½Ð¾Ð²Ðµ directional accuracy
        if epoch > 10 and val_metrics.get('directional_accuracy', 0) < 0.52:
            logger.warning("âš ï¸ Directional accuracy ÑÐ»Ð¸ÑˆÐºÐ¾Ð¼ Ð½Ð¸Ð·ÐºÐ°Ñ, Ñ‚Ñ€ÐµÐ±ÑƒÐµÑ‚ÑÑ Ð¿ÐµÑ€ÐµÑÐ¼Ð¾Ñ‚Ñ€ Ð¿Ð¾Ð´Ñ…Ð¾Ð´Ð°")
    
    # Ð¤Ð¸Ð½Ð°Ð»ÑŒÐ½Ð°Ñ Ð²Ð¸Ð·ÑƒÐ°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ
    logger.info("ðŸ“Š Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¸Ðµ Ñ„Ð¸Ð½Ð°Ð»ÑŒÐ½Ð¾Ð³Ð¾ Ð¾Ñ‚Ñ‡ÐµÑ‚Ð°...")
    visualize_results(trainer.history, log_dir)
    
    logger.info("âœ… ÐžÐ±ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ð·Ð°Ð²ÐµÑ€ÑˆÐµÐ½Ð¾!")
    logger.info(f"ðŸ“ Ð ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹ ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ñ‹ Ð²: {log_dir}")


if __name__ == "__main__":
    main()