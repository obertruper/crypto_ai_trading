#!/usr/bin/env python3
"""
–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –≤—Å–µ—Ö production —É–ª—É—á—à–µ–Ω–∏–π
"""

import torch
import yaml
from pathlib import Path
import numpy as np

def test_weighted_loss():
    """–¢–µ—Å—Ç weighted loss –¥–ª—è –¥–∏—Å–±–∞–ª–∞–Ω—Å–∞ –∫–ª–∞—Å—Å–æ–≤"""
    print("\nüß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ Weighted Loss...")
    
    from models.patchtst_unified import DirectionalMultiTaskLoss
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
    with open('config/config.yaml', 'r') as f:
        config = yaml.safe_load(f)
    
    # –°–æ–∑–¥–∞–µ–º loss —Ñ—É–Ω–∫—Ü–∏—é
    loss_fn = DirectionalMultiTaskLoss(config)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤–µ—Å–∞ –∫–ª–∞—Å—Å–æ–≤
    print(f"‚úÖ –í–µ—Å–∞ –∫–ª–∞—Å—Å–æ–≤ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã: {loss_fn.class_weights}")
    print(f"   LONG weight: {loss_fn.class_weights[0]:.2f}")
    print(f"   SHORT weight: {loss_fn.class_weights[1]:.2f}")
    print(f"   FLAT weight: {loss_fn.class_weights[2]:.2f}")
    
    # –¢–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ —Å —Å–∏–ª—å–Ω—ã–º –¥–∏—Å–±–∞–ª–∞–Ω—Å–æ–º (–∫–∞–∫ –≤ —Ä–µ–∞–ª—å–Ω–æ—Å—Ç–∏)
    batch_size = 100
    outputs = torch.randn(batch_size, 20, requires_grad=True)
    targets = torch.randn(batch_size, 20)
    
    # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º direction –∫–ª–∞—Å—Å—ã —Å –¥–∏—Å–±–∞–ª–∞–Ω—Å–æ–º
    # 80% FLAT, 10% LONG, 10% SHORT
    direction_classes = torch.zeros(batch_size, 4)
    direction_classes[:80, :] = 2  # FLAT
    direction_classes[80:90, :] = 0  # LONG
    direction_classes[90:, :] = 1  # SHORT
    targets[:, 4:8] = direction_classes
    
    # –°–æ–∑–¥–∞–µ–º direction_logits
    direction_logits = torch.randn(batch_size, 4, 3, requires_grad=True)
    outputs._direction_logits = direction_logits
    
    # –í—ã—á–∏—Å–ª—è–µ–º loss
    loss = loss_fn(outputs, targets)
    
    print(f"‚úÖ Loss –≤—ã—á–∏—Å–ª–µ–Ω —É—Å–ø–µ—à–Ω–æ: {loss.item():.4f}")
    print(f"‚úÖ Loss —Ç—Ä–µ–±—É–µ—Ç –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã: {loss.requires_grad}")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º backward
    loss.backward()
    print("‚úÖ Backward pass –≤—ã–ø–æ–ª–Ω–µ–Ω —É—Å–ø–µ—à–Ω–æ")
    
    return True


def test_bias_initialization():
    """–¢–µ—Å—Ç –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ bias –¥–ª—è direction head"""
    print("\nüß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ Direction Head...")
    
    from models.patchtst_unified import UnifiedPatchTSTForTrading
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
    with open('config/config.yaml', 'r') as f:
        config = yaml.safe_load(f)
    
    # –°–æ–∑–¥–∞–µ–º –º–æ–¥–µ–ª—å
    model = UnifiedPatchTSTForTrading(config)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º bias –≤ direction head
    for name, param in model.direction_head.named_parameters():
        if 'bias' in name and param.shape[0] == 12:
            biases = param.detach().view(4, 3)  # 4 —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞ x 3 –∫–ª–∞—Å—Å–∞
            
            print("‚úÖ Direction Head biases:")
            for tf in range(4):
                print(f"   –¢–∞–π–º—Ñ—Ä–µ–π–º {tf+1}:")
                print(f"      LONG bias:  {biases[tf, 0]:.3f}")
                print(f"      SHORT bias: {biases[tf, 1]:.3f}")
                print(f"      FLAT bias:  {biases[tf, 2]:.3f}")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ FLAT –∏–º–µ–µ—Ç –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–π bias
            flat_biases = biases[:, 2]
            if (flat_biases < 0).all():
                print("‚úÖ –í—Å–µ FLAT biases –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–µ - —Ö–æ—Ä–æ—à–æ!")
            else:
                print("‚ùå –ù–µ –≤—Å–µ FLAT biases –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–µ!")
                return False
    
    return True


def test_config_updates():
    """–¢–µ—Å—Ç –æ–±–Ω–æ–≤–ª–µ–Ω–∏–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏"""
    print("\nüß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏...")
    
    with open('config/config.yaml', 'r') as f:
        config = yaml.safe_load(f)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º learning rate
    lr = config['model']['learning_rate']
    print(f"‚úÖ Learning rate: {lr}")
    if lr != 0.001:
        print(f"‚ùå Learning rate –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å 0.001, –∞ –Ω–µ {lr}")
        return False
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º warmup
    warmup = config['model'].get('warmup_steps', 0)
    print(f"‚úÖ Warmup steps: {warmup}")
    # Warmup –µ—Å—Ç—å, —ç—Ç–æ –≥–ª–∞–≤–Ω–æ–µ
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤–µ—Å direction loss
    direction_weight = config['loss']['task_weights']['directions']
    print(f"‚úÖ Direction loss weight: {direction_weight}")
    if direction_weight != 10.0:
        print(f"‚ùå Direction weight –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å 10.0, –∞ –Ω–µ {direction_weight}")
        return False
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º focal loss –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
    focal_alpha = config['loss'].get('focal_alpha', 0.25)
    focal_gamma = config['loss'].get('focal_gamma', 2.0)
    print(f"‚úÖ Focal loss –ø–∞—Ä–∞–º–µ—Ç—Ä—ã: alpha={focal_alpha}, gamma={focal_gamma}")
    
    return True


def test_diversity_monitoring():
    """–¢–µ—Å—Ç –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π"""
    print("\nüß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏—è...")
    
    from training.optimized_trainer import OptimizedTrainer
    
    # –°–æ–∑–¥–∞–µ–º —Ñ–∏–∫—Ç–∏–≤–Ω—É—é –º–æ–¥–µ–ª—å
    import torch.nn as nn
    model = nn.Linear(10, 20)
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
    with open('config/config.yaml', 'r') as f:
        config = yaml.safe_load(f)
    
    trainer = OptimizedTrainer(model, config, device=torch.device('cpu'))
    
    # –¢–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
    batch_size = 100
    outputs = torch.randn(batch_size, 20)
    targets = torch.randn(batch_size, 20)
    
    # –°–æ–∑–¥–∞–µ–º direction_logits —Å —Ä–∞–∑–Ω—ã–º —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ–º
    # –¢–µ—Å—Ç 1: –°–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ
    direction_logits = torch.randn(batch_size, 4, 3)
    outputs._direction_logits = direction_logits
    
    # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ü–µ–ª–µ–≤—ã–µ –∫–ª–∞—Å—Å—ã
    targets[:, 4:8] = torch.randint(0, 3, (batch_size, 4)).float()
    
    # –í—ã—á–∏—Å–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏
    metrics = trainer.compute_direction_metrics(outputs, targets)
    
    print("‚úÖ –ú–µ—Ç—Ä–∏–∫–∏ –¥–ª—è —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è:")
    print(f"   –≠–Ω—Ç—Ä–æ–ø–∏—è: {metrics.get('pred_entropy_overall', 0):.3f}")
    print(f"   LONG ratio: {metrics.get('pred_long_ratio_overall', 0):.1%}")
    print(f"   SHORT ratio: {metrics.get('pred_short_ratio_overall', 0):.1%}")
    print(f"   FLAT ratio: {metrics.get('pred_flat_ratio_overall', 0):.1%}")
    
    # –¢–µ—Å—Ç 2: –ù–µ—Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ (–≤—Å–µ FLAT)
    direction_logits = torch.zeros(batch_size, 4, 3)
    direction_logits[:, :, 2] = 10  # –°–∏–ª—å–Ω–æ–µ –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏–µ FLAT
    outputs._direction_logits = direction_logits
    
    metrics = trainer.compute_direction_metrics(outputs, targets)
    
    print("\n‚úÖ –ú–µ—Ç—Ä–∏–∫–∏ –¥–ª—è –Ω–µ—Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è (–≤—Å–µ FLAT):")
    print(f"   –≠–Ω—Ç—Ä–æ–ø–∏—è: {metrics.get('pred_entropy_overall', 0):.3f}")
    print(f"   FLAT ratio: {metrics.get('pred_flat_ratio_overall', 0):.1%}")
    
    if metrics.get('pred_entropy_overall', 1) < 0.1:
        print("‚úÖ –ù–∏–∑–∫–∞—è —ç–Ω—Ç—Ä–æ–ø–∏—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∞!")
    
    return True


def test_production_ready_main():
    """–¢–µ—Å—Ç production-ready main.py"""
    print("\nüß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ Production-Ready —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª–∞...")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ main_production.py
    if Path('main_production.py').exists():
        print("‚úÖ main_production.py —Å–æ–∑–¥–∞–Ω")
        
        # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –∏ –ø—Ä–æ–≤–µ—Ä—è–µ–º –∫–ª–∞—Å—Å—ã
        try:
            from main_production import ProductionConfig, ModelValidator, ProductionInference
            print("‚úÖ Production –∫–ª–∞—Å—Å—ã –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω—ã —É—Å–ø–µ—à–Ω–æ")
            
            # –¢–µ—Å—Ç–∏—Ä—É–µ–º ProductionConfig
            config = ProductionConfig('config/config.yaml')
            print("‚úÖ ProductionConfig —Ä–∞–±–æ—Ç–∞–µ—Ç")
            
            return True
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∏–º–ø–æ—Ä—Ç–∞: {e}")
            return False
    else:
        print("‚ùå main_production.py –Ω–µ –Ω–∞–π–¥–µ–Ω")
        return False


def main():
    """–ó–∞–ø—É—Å–∫ –≤—Å–µ—Ö —Ç–µ—Å—Ç–æ–≤"""
    print("="*80)
    print("üöÄ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ Production —É–ª—É—á—à–µ–Ω–∏–π")
    print("="*80)
    
    tests = [
        ("Weighted Loss", test_weighted_loss),
        ("Bias Initialization", test_bias_initialization),
        ("Config Updates", test_config_updates),
        ("Diversity Monitoring", test_diversity_monitoring),
        ("Production Ready Main", test_production_ready_main)
    ]
    
    passed = 0
    total = len(tests)
    
    for test_name, test_func in tests:
        try:
            if test_func():
                passed += 1
                print(f"‚úÖ {test_name} - PASSED\n")
            else:
                print(f"‚ùå {test_name} - FAILED\n")
        except Exception as e:
            print(f"‚ùå {test_name} - ERROR: {e}\n")
    
    print("="*80)
    print(f"üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã: {passed}/{total} —Ç–µ—Å—Ç–æ–≤ –ø—Ä–æ–π–¥–µ–Ω–æ")
    
    if passed == total:
        print("üéâ –í—Å–µ —Ç–µ—Å—Ç—ã –ø—Ä–æ–π–¥–µ–Ω—ã —É—Å–ø–µ—à–Ω–æ!")
        print("\nüöÄ –°–∏—Å—Ç–µ–º–∞ –≥–æ—Ç–æ–≤–∞ –∫ production!")
        print("\n–°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏:")
        print("1. –ó–∞–ø—É—Å—Ç–∏—Ç—å –æ–±—É—á–µ–Ω–∏–µ: python main_production.py --mode train")
        print("2. –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –º–æ–¥–µ–ª—å: python evaluate_model_production.py")
        print("3. –í–∞–ª–∏–¥–∞—Ü–∏—è: python main_production.py --mode validate --model-path models_saved/best_model.pth")
    else:
        print("‚ö†Ô∏è –ù–µ–∫–æ—Ç–æ—Ä—ã–µ —Ç–µ—Å—Ç—ã –Ω–µ –ø—Ä–æ–π–¥–µ–Ω—ã, –ø—Ä–æ–≤–µ—Ä—å—Ç–µ –ª–æ–≥–∏ –≤—ã—à–µ")


if __name__ == "__main__":
    main()