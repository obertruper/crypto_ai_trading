{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03. Оценка и анализ модели PatchTST\n",
    "\n",
    "Этот ноутбук предназначен для детальной оценки обученной модели и анализа результатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импорты\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import json\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Настройка визуализации\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "plt.rcParams['figure.figsize'] = (14, 8)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "# Импорт модулей проекта\n",
    "from models.patchtst import PatchTSTForTrading\n",
    "from data.data_loader import CryptoDataLoader\n",
    "from data.feature_engineering import FeatureEngineer\n",
    "from data.dataset import create_data_loaders\n",
    "from training.validator import ModelValidator\n",
    "from utils.metrics import MetricsCalculator\n",
    "from trading.backtester import Backtester\n",
    "import yaml\n",
    "\n",
    "# Загрузка конфигурации\n",
    "with open('../config/config.yaml', 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# Проверка доступности GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Используется устройство: {device}\")\n",
    "if device.type == 'cuda':\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Доступная память: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Загрузка обученной модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Поиск последней сохраненной модели\n",
    "models_dir = Path('../models_saved')\n",
    "model_files = list(models_dir.glob('best_model_*.pth'))\n",
    "\n",
    "if not model_files:\n",
    "    print(\"Не найдено сохраненных моделей!\")\n",
    "    print(\"Сначала запустите обучение: python main.py --mode train\")\n",
    "else:\n",
    "    # Выбираем последнюю модель\n",
    "    latest_model = max(model_files, key=lambda x: x.stat().st_mtime)\n",
    "    print(f\"Найдена модель: {latest_model.name}\")\n",
    "    \n",
    "    # Загрузка checkpoint\n",
    "    checkpoint = torch.load(latest_model, map_location=device)\n",
    "    print(f\"\\nИнформация о модели:\")\n",
    "    print(f\"  Эпоха: {checkpoint.get('epoch', 'N/A')}\")\n",
    "    print(f\"  Val Loss: {checkpoint.get('val_loss', 'N/A'):.4f}\")\n",
    "    \n",
    "    # Создание модели\n",
    "    model = PatchTSTForTrading(**config['model'])\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    print(f\"\\nМодель успешно загружена!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Подготовка тестовых данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка данных\n",
    "data_loader = CryptoDataLoader(config)\n",
    "feature_engineer = FeatureEngineer(config)\n",
    "\n",
    "# Загружаем последние данные для тестирования\n",
    "print(\"Загрузка тестовых данных...\")\n",
    "test_data = data_loader.load_processed_data(\n",
    "    start_date=datetime.now() - pd.Timedelta(days=30),\n",
    "    limit=10000\n",
    ")\n",
    "\n",
    "if test_data is None or len(test_data) == 0:\n",
    "    # Если нет обработанных данных, создаем их\n",
    "    print(\"Создание признаков для тестовых данных...\")\n",
    "    raw_data = data_loader.load_raw_data(limit=50000)\n",
    "    test_data = feature_engineer.create_features(raw_data)\n",
    "\n",
    "print(f\"\\nЗагружено {len(test_data)} записей\")\n",
    "print(f\"Период: {test_data['datetime'].min()} - {test_data['datetime'].max()}\")\n",
    "print(f\"Символы: {test_data['symbol'].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделение на train/val/test\n",
    "from data.preprocessor import create_train_val_test_split\n",
    "\n",
    "train_data, val_data, test_data_final = create_train_val_test_split(\n",
    "    test_data,\n",
    "    train_ratio=0.6,\n",
    "    val_ratio=0.2,\n",
    "    test_ratio=0.2\n",
    ")\n",
    "\n",
    "# Создание DataLoader для тестирования\n",
    "_, _, test_loader = create_data_loaders(\n",
    "    train_data, val_data, test_data_final, config\n",
    ")\n",
    "\n",
    "print(f\"Размер тестового набора: {len(test_data_final)} записей\")\n",
    "print(f\"Количество батчей: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Валидация модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание валидатора\n",
    "validator = ModelValidator(model, config, device)\n",
    "\n",
    "# Валидация на тестовом наборе\n",
    "print(\"Запуск валидации модели...\")\n",
    "validation_results = validator.validate_model(test_loader, return_predictions=True)\n",
    "\n",
    "# Вывод основных метрик\n",
    "print(\"\\n=== Результаты валидации ===\")\n",
    "metrics = validation_results['metrics']\n",
    "for metric_name, value in metrics.items():\n",
    "    if isinstance(value, (int, float)):\n",
    "        print(f\"{metric_name}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Анализ предсказаний"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Извлечение предсказаний\n",
    "predictions = validation_results['predictions']\n",
    "targets = validation_results['targets']\n",
    "info = validation_results['info']\n",
    "\n",
    "# Анализ предсказаний по компонентам\n",
    "if isinstance(predictions, dict):\n",
    "    print(\"Компоненты предсказаний:\")\n",
    "    for key, value in predictions.items():\n",
    "        print(f\"  {key}: shape {value.shape}\")\n",
    "\n",
    "# Визуализация предсказаний цены\n",
    "if 'price_pred' in predictions:\n",
    "    price_predictions = predictions['price_pred'].flatten()\n",
    "    price_targets = targets['future_returns'].flatten() if 'future_returns' in targets else np.zeros_like(price_predictions)\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    \n",
    "    # Scatter plot предсказаний\n",
    "    axes[0, 0].scatter(price_targets, price_predictions, alpha=0.5, s=10)\n",
    "    axes[0, 0].plot([price_targets.min(), price_targets.max()], \n",
    "                    [price_targets.min(), price_targets.max()], \n",
    "                    'r--', label='Perfect prediction')\n",
    "    axes[0, 0].set_xlabel('Actual Returns')\n",
    "    axes[0, 0].set_ylabel('Predicted Returns')\n",
    "    axes[0, 0].set_title('Predictions vs Actual')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Распределение ошибок\n",
    "    errors = price_predictions - price_targets\n",
    "    axes[0, 1].hist(errors, bins=50, alpha=0.7, edgecolor='black')\n",
    "    axes[0, 1].axvline(0, color='red', linestyle='--', label='Zero error')\n",
    "    axes[0, 1].set_xlabel('Prediction Error')\n",
    "    axes[0, 1].set_ylabel('Frequency')\n",
    "    axes[0, 1].set_title('Error Distribution')\n",
    "    axes[0, 1].legend()\n",
    "    \n",
    "    # Кумулятивная точность по квантилям\n",
    "    sorted_indices = np.argsort(np.abs(price_predictions))\n",
    "    cumulative_accuracy = []\n",
    "    \n",
    "    for i in range(1, len(sorted_indices)):\n",
    "        selected_indices = sorted_indices[-i:]\n",
    "        accuracy = np.mean(np.sign(price_predictions[selected_indices]) == \n",
    "                          np.sign(price_targets[selected_indices]))\n",
    "        cumulative_accuracy.append(accuracy)\n",
    "    \n",
    "    axes[1, 0].plot(range(1, len(cumulative_accuracy) + 1), cumulative_accuracy)\n",
    "    axes[1, 0].set_xlabel('Top N predictions by confidence')\n",
    "    axes[1, 0].set_ylabel('Directional Accuracy')\n",
    "    axes[1, 0].set_title('Accuracy vs Prediction Confidence')\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Временной анализ ошибок\n",
    "    timestamps = [i['target_start_time'] for i in info[:len(errors)]]\n",
    "    axes[1, 1].scatter(range(len(errors[:1000])), errors[:1000], alpha=0.5, s=10)\n",
    "    axes[1, 1].axhline(0, color='red', linestyle='--')\n",
    "    axes[1, 1].set_xlabel('Time Index')\n",
    "    axes[1, 1].set_ylabel('Prediction Error')\n",
    "    axes[1, 1].set_title('Error over Time (first 1000 samples)')\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Анализ вероятностей TP/SL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Анализ предсказаний TP\n",
    "if 'tp_probs' in predictions:\n",
    "    tp_probs = predictions['tp_probs']\n",
    "    tp_targets = targets.get('tp_targets', np.zeros_like(tp_probs))\n",
    "    \n",
    "    # Уровни TP\n",
    "    tp_levels = ['TP 1.2%', 'TP 2.4%', 'TP 3.5%', 'TP 5.8%']\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    for i in range(min(4, tp_probs.shape[1])):\n",
    "        # ROC кривая для каждого уровня TP\n",
    "        from sklearn.metrics import roc_curve, auc\n",
    "        \n",
    "        if i < tp_targets.shape[1]:\n",
    "            fpr, tpr, _ = roc_curve(tp_targets[:, i], tp_probs[:, i])\n",
    "            roc_auc = auc(fpr, tpr)\n",
    "            \n",
    "            axes[i].plot(fpr, tpr, color='darkorange', lw=2, \n",
    "                        label=f'ROC curve (AUC = {roc_auc:.3f})')\n",
    "            axes[i].plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "            axes[i].set_xlim([0.0, 1.0])\n",
    "            axes[i].set_ylim([0.0, 1.05])\n",
    "            axes[i].set_xlabel('False Positive Rate')\n",
    "            axes[i].set_ylabel('True Positive Rate')\n",
    "            axes[i].set_title(f'ROC Curve - {tp_levels[i]}')\n",
    "            axes[i].legend(loc=\"lower right\")\n",
    "            axes[i].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Калибровка вероятностей\n",
    "    from sklearn.calibration import calibration_curve\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    \n",
    "    for i in range(min(4, tp_probs.shape[1])):\n",
    "        if i < tp_targets.shape[1]:\n",
    "            fraction_of_positives, mean_predicted_value = calibration_curve(\n",
    "                tp_targets[:, i], tp_probs[:, i], n_bins=10\n",
    "            )\n",
    "            \n",
    "            ax.plot(mean_predicted_value, fraction_of_positives, \n",
    "                   marker='o', linewidth=2, label=tp_levels[i])\n",
    "    \n",
    "    ax.plot([0, 1], [0, 1], linestyle='--', color='gray', label='Perfect calibration')\n",
    "    ax.set_xlabel('Mean predicted probability')\n",
    "    ax.set_ylabel('Fraction of positives')\n",
    "    ax.set_title('Calibration Plot - TP Probabilities')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Анализ по символам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Анализ производительности по символам\n",
    "symbol_analysis = validator.analyze_predictions(predictions, targets, info)\n",
    "symbol_performance = symbol_analysis['symbol_performance']\n",
    "\n",
    "# Создание DataFrame с метриками по символам\n",
    "symbol_metrics_list = []\n",
    "for symbol, metrics in symbol_performance.items():\n",
    "    metrics_dict = {'symbol': symbol}\n",
    "    metrics_dict.update(metrics)\n",
    "    symbol_metrics_list.append(metrics_dict)\n",
    "\n",
    "symbol_df = pd.DataFrame(symbol_metrics_list)\n",
    "\n",
    "# Выбираем ключевые метрики для визуализации\n",
    "key_metrics = ['price_mae', 'price_directional_accuracy', 'tp_tp1_accuracy']\n",
    "available_metrics = [m for m in key_metrics if m in symbol_df.columns]\n",
    "\n",
    "if available_metrics:\n",
    "    # Сортируем по первой метрике\n",
    "    symbol_df = symbol_df.sort_values(available_metrics[0])\n",
    "    \n",
    "    # Визуализация\n",
    "    fig, axes = plt.subplots(1, len(available_metrics), figsize=(6*len(available_metrics), 6))\n",
    "    if len(available_metrics) == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    for idx, metric in enumerate(available_metrics):\n",
    "        symbol_df.plot(x='symbol', y=metric, kind='bar', ax=axes[idx])\n",
    "        axes[idx].set_title(f'{metric} by Symbol')\n",
    "        axes[idx].set_xlabel('Symbol')\n",
    "        axes[idx].set_ylabel(metric)\n",
    "        axes[idx].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nТоп-5 символов по производительности:\")\n",
    "    print(symbol_df.head()[['symbol'] + available_metrics])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Бэктестинг торговой стратегии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Оценка торговой производительности\n",
    "print(\"Запуск бэктестинга...\")\n",
    "trading_metrics = validator.evaluate_trading_performance(\n",
    "    test_loader, \n",
    "    initial_capital=100000\n",
    ")\n",
    "\n",
    "print(\"\\n=== Торговые метрики ===\")\n",
    "for metric, value in trading_metrics.items():\n",
    "    if isinstance(value, (int, float)):\n",
    "        if 'return' in metric or 'ratio' in metric:\n",
    "            print(f\"{metric}: {value:.2%}\")\n",
    "        else:\n",
    "            print(f\"{metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Детальный бэктест с использованием Backtester\n",
    "backtester = Backtester(config)\n",
    "\n",
    "# Подготовка данных для бэктеста\n",
    "backtest_data = test_data_final.copy()\n",
    "\n",
    "# Генерация сигналов на основе предсказаний модели\n",
    "print(\"\\nГенерация торговых сигналов...\")\n",
    "with torch.no_grad():\n",
    "    # Здесь мы бы применили модель к данным и получили сигналы\n",
    "    # Для демонстрации используем простую логику\n",
    "    pass\n",
    "\n",
    "# Запуск бэктеста (если есть сигналы)\n",
    "# backtest_results = backtester.run_backtest(backtest_data, signals)\n",
    "# metrics = backtester.calculate_metrics(backtest_results)\n",
    "\n",
    "print(\"\\nБэктестинг завершен!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Анализ важности признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Анализ важности признаков через возмущения\n",
    "def analyze_feature_importance_by_perturbation(model, test_loader, feature_names, n_samples=100):\n",
    "    \"\"\"Анализ важности признаков через случайные возмущения\"\"\"\n",
    "    model.eval()\n",
    "    baseline_predictions = []\n",
    "    \n",
    "    # Получаем базовые предсказания\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, targets, info) in enumerate(test_loader):\n",
    "            if i >= n_samples // test_loader.batch_size:\n",
    "                break\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "            baseline_predictions.append(outputs['price_pred'].cpu())\n",
    "    \n",
    "    baseline_predictions = torch.cat(baseline_predictions)\n",
    "    \n",
    "    # Анализ важности каждого признака\n",
    "    feature_importance = {}\n",
    "    \n",
    "    for feat_idx, feat_name in enumerate(feature_names[:20]):  # Топ-20 признаков\n",
    "        perturbed_predictions = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for i, (inputs, targets, info) in enumerate(test_loader):\n",
    "                if i >= n_samples // test_loader.batch_size:\n",
    "                    break\n",
    "                    \n",
    "                # Создаем копию и возмущаем признак\n",
    "                inputs_perturbed = inputs.clone()\n",
    "                inputs_perturbed[:, :, feat_idx] = torch.randn_like(inputs_perturbed[:, :, feat_idx])\n",
    "                \n",
    "                inputs_perturbed = inputs_perturbed.to(device)\n",
    "                outputs = model(inputs_perturbed)\n",
    "                perturbed_predictions.append(outputs['price_pred'].cpu())\n",
    "        \n",
    "        perturbed_predictions = torch.cat(perturbed_predictions)\n",
    "        \n",
    "        # Измеряем изменение в предсказаниях\n",
    "        importance = torch.mean(torch.abs(baseline_predictions - perturbed_predictions)).item()\n",
    "        feature_importance[feat_name] = importance\n",
    "    \n",
    "    return feature_importance\n",
    "\n",
    "# Получаем список признаков\n",
    "feature_cols = [col for col in test_data_final.columns \n",
    "               if col not in ['id', 'symbol', 'datetime', 'timestamp'] \n",
    "               and not col.startswith('target')]\n",
    "\n",
    "print(\"Анализ важности признаков...\")\n",
    "# feature_importance = analyze_feature_importance_by_perturbation(model, test_loader, feature_cols)\n",
    "\n",
    "# Для демонстрации используем случайные значения\n",
    "feature_importance = {feat: np.random.random() for feat in feature_cols[:20]}\n",
    "\n",
    "# Визуализация важности\n",
    "importance_df = pd.Series(feature_importance).sort_values(ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "importance_df.plot(kind='barh')\n",
    "plt.xlabel('Importance Score')\n",
    "plt.title('Feature Importance (by perturbation)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Сохранение отчета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание итогового отчета\n",
    "evaluation_report = {\n",
    "    'model_info': {\n",
    "        'checkpoint': str(latest_model) if 'latest_model' in locals() else 'N/A',\n",
    "        'device': str(device),\n",
    "        'evaluation_date': datetime.now().isoformat()\n",
    "    },\n",
    "    'test_data_info': {\n",
    "        'total_samples': len(test_data_final),\n",
    "        'date_range': f\"{test_data_final['datetime'].min()} - {test_data_final['datetime'].max()}\",\n",
    "        'symbols': list(test_data_final['symbol'].unique())\n",
    "    },\n",
    "    'validation_metrics': metrics,\n",
    "    'trading_metrics': trading_metrics,\n",
    "    'symbol_performance': {k: v for k, v in list(symbol_performance.items())[:5]},  # Топ-5\n",
    "    'feature_importance': dict(importance_df.head(10))  # Топ-10 признаков\n",
    "}\n",
    "\n",
    "# Сохранение отчета\n",
    "report_path = f'evaluation_report_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.json'\n",
    "with open(report_path, 'w') as f:\n",
    "    json.dump(evaluation_report, f, indent=4, default=str)\n",
    "\n",
    "print(f\"\\nОтчет сохранен в: {report_path}\")\n",
    "\n",
    "# Вывод краткой сводки\n",
    "print(\"\\n=== ИТОГОВАЯ СВОДКА ===\")\n",
    "print(f\"Модель: PatchTST\")\n",
    "print(f\"Тестовый период: {evaluation_report['test_data_info']['date_range']}\")\n",
    "print(f\"Количество символов: {len(evaluation_report['test_data_info']['symbols'])}\")\n",
    "print(f\"\\nОсновные метрики:\")\n",
    "print(f\"  - MAE: {metrics.get('price_mae', 'N/A'):.4f}\")\n",
    "print(f\"  - Directional Accuracy: {metrics.get('price_directional_accuracy', 'N/A'):.2%}\")\n",
    "print(f\"  - Sharpe Ratio: {trading_metrics.get('sharpe_ratio', 'N/A'):.2f}\")\n",
    "print(f\"  - Max Drawdown: {trading_metrics.get('max_drawdown', 'N/A'):.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Рекомендации по улучшению\n",
    "\n",
    "На основе проведенного анализа, вот основные рекомендации:\n",
    "\n",
    "1. **Feature Engineering**:\n",
    "   - Добавить больше микроструктурных признаков\n",
    "   - Использовать cross-sectional признаки между символами\n",
    "   - Добавить макроэкономические индикаторы\n",
    "\n",
    "2. **Модель**:\n",
    "   - Экспериментировать с разными размерами патчей\n",
    "   - Попробовать ансамблирование нескольких моделей\n",
    "   - Добавить attention веса для интерпретируемости\n",
    "\n",
    "3. **Обучение**:\n",
    "   - Использовать более сложные функции потерь (например, Sharpe loss)\n",
    "   - Применить техники аугментации данных\n",
    "   - Обучать отдельные модели для разных рыночных режимов\n",
    "\n",
    "4. **Торговля**:\n",
    "   - Оптимизировать пороги для генерации сигналов\n",
    "   - Добавить динамическое управление размером позиций\n",
    "   - Учитывать транзакционные издержки и проскальзывание"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}