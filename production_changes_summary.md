# üìã –ò—Ç–æ–≥–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–π –≤ production –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏

## ‚úÖ –í—Å–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è –≤–Ω–µ—Å–µ–Ω—ã —É—Å–ø–µ—à–Ω–æ!

### 1. **–£–ø—Ä–æ—â–µ–Ω–∞ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –º–æ–¥–µ–ª–∏**:
- `d_model`: 384 ‚Üí **256** (–º–µ–Ω—å—à–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤)
- `d_ff`: 768 ‚Üí **512** (–ø—Ä–æ—â–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞)
- `e_layers`: 2 ‚Üí **1** (–º–∏–Ω–∏–º—É–º —Å–ª–æ–µ–≤)
- `batch_size`: 1024 ‚Üí **256** (—Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å)

### 2. **–£—Å–∏–ª–µ–Ω–∞ —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è**:
- `dropout`: 0.3 ‚Üí **0.5** (–≤—ã—Å–æ–∫–∏–π dropout)
- `attention_dropout`: 0.1 ‚Üí **0.2** 
- `weight_decay`: 0.001 ‚Üí **0.1** (–≤ 100 —Ä–∞–∑ –±–æ–ª—å—à–µ!)
- `gradient_clip`: 0.3 ‚Üí **0.1** (–∞–≥—Ä–µ—Å—Å–∏–≤–Ω–µ–µ)

### 3. **–°–Ω–∏–∂–µ–Ω learning rate**:
- `learning_rate`: 0.0001 ‚Üí **0.00001** (–≤ 10 —Ä–∞–∑ –º–µ–Ω—å—à–µ)
- `warmup_steps`: 2000 ‚Üí **5000** (–¥–æ–ª—å—à–µ —Ä–∞–∑–æ–≥—Ä–µ–≤)
- `gradient_accumulation`: 8 ‚Üí **4** (—ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–π batch = 1024)

### 4. **–£—Å–∏–ª–µ–Ω–∞ –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö**:
- `mixup_alpha`: 0.2 ‚Üí **0.4** (–±–æ–ª—å—à–µ —Å–º–µ—à–∏–≤–∞–Ω–∏—è)
- `weight_noise`: 0.01 ‚Üí **0.02** (–±–æ–ª—å—à–µ —à—É–º–∞)
- `dropout_schedule`: false ‚Üí **true** (–∞–¥–∞–ø—Ç–∏–≤–Ω—ã–π dropout)

### 5. **–ò–∑–º–µ–Ω–µ–Ω—ã –≤–µ—Å–∞ loss —Ñ—É–Ω–∫—Ü–∏–∏**:
- `directions_weight`: 2.0 ‚Üí **1.0** (–±–µ–∑ –ø–µ—Ä–µ–∫–æ—Å–∞)
- `class_weights`: [1.5, 1.5, 0.5] ‚Üí **[1.0, 1.0, 3.0]** (—Ñ–æ–∫—É—Å –Ω–∞ FLAT)

### 6. **–ù–æ–≤—ã–π scheduler**:
- `CosineAnnealingWarmRestarts` ‚Üí **ReduceLROnPlateau**
- –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —Å–Ω–∏–∂–µ–Ω–∏–µ LR –ø—Ä–∏ –∑–∞—Å—Ç–æ–µ
- `factor`: 0.5 (—É–º–µ–Ω—å—à–µ–Ω–∏–µ –≤ 2 —Ä–∞–∑–∞)
- `patience`: 5 —ç–ø–æ—Ö

## üéØ –û–∂–∏–¥–∞–µ–º—ã–π —ç—Ñ—Ñ–µ–∫—Ç:
1. **–û—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è** - —É–ø—Ä–æ—â–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å + —Å–∏–ª—å–Ω–∞—è —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è
2. **–°—Ç–∞–±–∏–ª—å–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ** - –Ω–∏–∑–∫–∏–π LR + –º–∞–ª—ã–π batch size
3. **–õ—É—á—à–∞—è –≥–µ–Ω–µ—Ä–∞–ª–∏–∑–∞—Ü–∏—è** - –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏—è + dropout schedule
4. **–ü—Ä–∞–≤–∏–ª—å–Ω—ã–π –±–∞–ª–∞–Ω—Å –∫–ª–∞—Å—Å–æ–≤** - —Ñ–æ–∫—É—Å –Ω–∞ FLAT –∫–ª–∞—Å—Å
5. **–ê–¥–∞–ø—Ç–∏–≤–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ** - ReduceLROnPlateau –ø–æ–¥—Å—Ç—Ä–æ–∏—Ç—Å—è –ø–æ–¥ –¥–∞–Ω–Ω—ã–µ

## üöÄ –ö–æ–º–∞–Ω–¥–∞ –¥–ª—è –∑–∞–ø—É—Å–∫–∞:
```bash
# –ù–æ–≤–æ–µ –æ–±—É—á–µ–Ω–∏–µ —Å –∏–∑–º–µ–Ω–µ–Ω–Ω–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π
python main.py --mode production

# –ò–ª–∏ fine-tuning –æ—Ç –ø–æ—Å–ª–µ–¥–Ω–µ–π –º–æ–¥–µ–ª–∏
python main.py --mode production --checkpoint models_saved/best_model_20250711_153803.pth
```

## üìä –¶–µ–ª–µ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏:
- Direction Accuracy: **40-42%** (–±—ã–ª–æ 36.2%)
- Win Rate: **48-50%** (–±—ã–ª–æ 46.2%)
- Val Loss: **< 3.5** (–±—ã–ª–æ 5.3)
- FLAT predictions: **20-25%** (–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –±–∞–ª–∞–Ω—Å)