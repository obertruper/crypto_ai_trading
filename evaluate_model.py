#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–π –æ—Ü–µ–Ω–∫–∏ –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ PatchTST
"""

import torch
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
import json
from datetime import datetime
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix
import warnings
warnings.filterwarnings('ignore')

import sys
sys.path.append('/mnt/SSD/PYCHARMPRODJECT/LLM TRANSFORM/crypto_ai_trading')

from config.config_loader import ConfigLoader
from models.patchtst_unified import UnifiedPatchTST
from data.precomputed_dataset import create_precomputed_dataloaders
from utils.logger import Logger

def load_config(config_path):
    config_loader = ConfigLoader()
    return config_loader.load(config_path)

logger = Logger(level="INFO", name=__name__)

class ModelEvaluator:
    def __init__(self, config_path='config/config.yaml'):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –æ—Ü–µ–Ω—â–∏–∫–∞ –º–æ–¥–µ–ª–∏"""
        self.config = load_config(config_path)
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.results = {}
        
    def load_model(self, checkpoint_path='models_saved/best_model.pth'):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏"""
        logger.info(f"üì• –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –∏–∑ {checkpoint_path}")
        
        checkpoint = torch.load(checkpoint_path, map_location=self.device)
        
        # –°–æ–∑–¥–∞–µ–º –º–æ–¥–µ–ª—å
        self.model = UnifiedPatchTST(
            input_size=self.config['model']['input_size'],
            output_size=self.config['model']['output_size'],
            seq_len=self.config['model']['seq_len'],
            pred_len=self.config['model']['pred_len'],
            patch_len=self.config['model']['patch_len'],
            stride=self.config['model']['stride'],
            d_model=self.config['model']['d_model'],
            n_heads=self.config['model']['n_heads'],
            e_layers=self.config['model']['e_layers'],
            d_ff=self.config['model']['d_ff'],
            dropout=self.config['model']['dropout'],
            activation=self.config['model']['activation']
        )
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤–µ—Å–∞
        self.model.load_state_dict(checkpoint['model_state_dict'])
        self.model.to(self.device)
        self.model.eval()
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏—Å—Ç–æ—Ä–∏—é –æ–±—É—á–µ–Ω–∏—è
        self.training_history = checkpoint.get('history', {})
        
        logger.info(f"‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞. –≠–ø–æ—Ö–∞: {checkpoint.get('epoch', 'N/A')}")
        logger.info(f"üìä –õ—É—á—à–∏–π val_loss: {checkpoint.get('val_loss', 'N/A'):.6f}")
        
        return self.model
        
    def load_data(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
        logger.info("üìä –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö...")
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º PrecomputedDataLoaders –¥–ª—è –±—ã—Å—Ç—Ä–æ–π –∑–∞–≥—Ä—É–∑–∫–∏
        data_loaders = PrecomputedDataLoaders(self.config)
        _, _, self.test_loader = data_loaders.get_loaders()
        
        logger.info(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(self.test_loader.dataset)} —Ç–µ—Å—Ç–æ–≤—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤")
        
        return self.test_loader
        
    def evaluate_predictions(self):
        """–û—Ü–µ–Ω–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –º–æ–¥–µ–ª–∏"""
        logger.info("üîç –ù–∞—á–∞–ª–æ –æ—Ü–µ–Ω–∫–∏ –º–æ–¥–µ–ª–∏ –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö...")
        
        all_predictions = []
        all_targets = []
        all_features = []
        
        with torch.no_grad():
            for batch_idx, batch in enumerate(self.test_loader):
                features = batch['features'].to(self.device)
                targets = batch['targets'].to(self.device)
                
                # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
                outputs = self.model(features)
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
                all_predictions.append(outputs.cpu().numpy())
                all_targets.append(targets.cpu().numpy())
                all_features.append(features.cpu().numpy())
                
                if batch_idx % 10 == 0:
                    logger.info(f"   –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –±–∞—Ç—á–µ–π: {batch_idx + 1}/{len(self.test_loader)}")
        
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        self.predictions = np.vstack(all_predictions)
        self.targets = np.vstack(all_targets)
        self.features = np.vstack(all_features)
        
        logger.info(f"‚úÖ –û—Ü–µ–Ω–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞. –§–æ—Ä–º–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π: {self.predictions.shape}")
        
        return self.predictions, self.targets
        
    def calculate_metrics(self):
        """–†–∞—Å—á–µ—Ç –º–µ—Ç—Ä–∏–∫ –¥–ª—è –∫–∞–∂–¥–æ–π —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π"""
        logger.info("üìà –†–∞—Å—á–µ—Ç –º–µ—Ç—Ä–∏–∫ –ø–æ –∫–∞–∂–¥–æ–π —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π...")
        
        # –ù–∞–∑–≤–∞–Ω–∏—è —Ü–µ–ª–µ–≤—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö (20 —à—Ç—É–∫)
        target_names = [
            'future_return_15m', 'future_return_1h', 'future_return_4h', 'future_return_12h',
            'direction_15m', 'direction_1h', 'direction_4h', 'direction_12h',
            'volatility_15m', 'volatility_1h', 'volatility_4h', 'volatility_12h',
            'volume_change_15m', 'volume_change_1h', 'volume_change_4h', 'volume_change_12h',
            'price_range_15m', 'price_range_1h', 'price_range_4h', 'price_range_12h'
        ]
        
        metrics_results = {}
        
        for i, target_name in enumerate(target_names):
            pred = self.predictions[:, i]
            true = self.targets[:, i]
            
            if 'direction' in target_name:
                # –î–ª—è –±–∏–Ω–∞—Ä–Ω–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
                pred_binary = (pred > 0.5).astype(int)
                true_binary = (true > 0.5).astype(int)
                
                accuracy = accuracy_score(true_binary, pred_binary)
                precision, recall, f1, _ = precision_recall_fscore_support(
                    true_binary, pred_binary, average='binary'
                )
                
                metrics_results[target_name] = {
                    'accuracy': accuracy,
                    'precision': precision,
                    'recall': recall,
                    'f1_score': f1,
                    'type': 'classification'
                }
            else:
                # –î–ª—è —Ä–µ–≥—Ä–µ—Å—Å–∏–∏
                mse = mean_squared_error(true, pred)
                mae = mean_absolute_error(true, pred)
                r2 = r2_score(true, pred)
                
                metrics_results[target_name] = {
                    'mse': mse,
                    'mae': mae,
                    'rmse': np.sqrt(mse),
                    'r2': r2,
                    'type': 'regression'
                }
        
        self.metrics_results = metrics_results
        
        # –í—ã–≤–æ–¥–∏–º —Å–≤–æ–¥–∫—É
        logger.info("\nüìä –°–í–û–î–ö–ê –ú–ï–¢–†–ò–ö:")
        logger.info("=" * 70)
        
        # –†–µ–≥—Ä–µ—Å—Å–∏–æ–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
        logger.info("\nüéØ –†–µ–≥—Ä–µ—Å—Å–∏–æ–Ω–Ω—ã–µ —Ü–µ–ª–µ–≤—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ:")
        for name, metrics in metrics_results.items():
            if metrics['type'] == 'regression':
                logger.info(f"{name:20s} | MAE: {metrics['mae']:.4f} | RMSE: {metrics['rmse']:.4f} | R¬≤: {metrics['r2']:.4f}")
        
        # –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–æ–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
        logger.info("\nüéØ –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ü–µ–ª–µ–≤—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ:")
        for name, metrics in metrics_results.items():
            if metrics['type'] == 'classification':
                logger.info(f"{name:20s} | Acc: {metrics['accuracy']:.4f} | F1: {metrics['f1_score']:.4f}")
        
        return metrics_results
        
    def create_visualizations(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"""
        logger.info("üé® –°–æ–∑–¥–∞–Ω–∏–µ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–π...")
        
        output_dir = Path('experiments/evaluation_results')
        output_dir.mkdir(parents=True, exist_ok=True)
        
        # 1. –ì—Ä–∞—Ñ–∏–∫ –∏—Å—Ç–æ—Ä–∏–∏ –æ–±—É—á–µ–Ω–∏—è
        if self.training_history:
            plt.figure(figsize=(12, 5))
            
            plt.subplot(1, 2, 1)
            plt.plot(self.training_history.get('train_loss', []), label='Train Loss')
            plt.plot(self.training_history.get('val_loss', []), label='Val Loss')
            plt.xlabel('Epoch')
            plt.ylabel('Loss')
            plt.title('–ò—Å—Ç–æ—Ä–∏—è –æ–±—É—á–µ–Ω–∏—è')
            plt.legend()
            plt.grid(True)
            
            plt.subplot(1, 2, 2)
            if 'learning_rates' in self.training_history:
                plt.plot(self.training_history['learning_rates'])
                plt.xlabel('Epoch')
                plt.ylabel('Learning Rate')
                plt.title('–ò–∑–º–µ–Ω–µ–Ω–∏–µ Learning Rate')
                plt.grid(True)
            
            plt.tight_layout()
            plt.savefig(output_dir / 'training_history.png', dpi=300)
            plt.close()
        
        # 2. Scatter plots –¥–ª—è —Ä–µ–≥—Ä–µ—Å—Å–∏–æ–Ω–Ω—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö
        regression_vars = [name for name, m in self.metrics_results.items() if m['type'] == 'regression']
        
        n_cols = 4
        n_rows = (len(regression_vars) + n_cols - 1) // n_cols
        
        plt.figure(figsize=(16, 4 * n_rows))
        
        for idx, var_name in enumerate(regression_vars[:8]):  # –ü–µ—Ä–≤—ã–µ 8 –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö
            plt.subplot(n_rows, n_cols, idx + 1)
            
            var_idx = [i for i, name in enumerate(self.metrics_results.keys()) if name == var_name][0]
            
            # –°–ª—É—á–∞–π–Ω–∞—è –≤—ã–±–æ—Ä–∫–∞ –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
            sample_size = min(1000, len(self.predictions))
            sample_idx = np.random.choice(len(self.predictions), sample_size, replace=False)
            
            plt.scatter(self.targets[sample_idx, var_idx], 
                       self.predictions[sample_idx, var_idx], 
                       alpha=0.5, s=10)
            
            # –õ–∏–Ω–∏—è –∏–¥–µ–∞–ª—å–Ω–æ–≥–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
            min_val = min(self.targets[sample_idx, var_idx].min(), 
                         self.predictions[sample_idx, var_idx].min())
            max_val = max(self.targets[sample_idx, var_idx].max(), 
                         self.predictions[sample_idx, var_idx].max())
            plt.plot([min_val, max_val], [min_val, max_val], 'r--', lw=2)
            
            plt.xlabel('–†–µ–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è')
            plt.ylabel('–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è')
            plt.title(f'{var_name}\nR¬≤={self.metrics_results[var_name]["r2"]:.3f}')
            plt.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig(output_dir / 'predictions_vs_actual.png', dpi=300)
        plt.close()
        
        # 3. Confusion matrices –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–æ–Ω–Ω—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö
        classification_vars = [name for name, m in self.metrics_results.items() if m['type'] == 'classification']
        
        if classification_vars:
            n_vars = len(classification_vars)
            plt.figure(figsize=(5 * n_vars, 4))
            
            for idx, var_name in enumerate(classification_vars):
                plt.subplot(1, n_vars, idx + 1)
                
                var_idx = [i for i, name in enumerate(self.metrics_results.keys()) if name == var_name][0]
                
                pred_binary = (self.predictions[:, var_idx] > 0.5).astype(int)
                true_binary = (self.targets[:, var_idx] > 0.5).astype(int)
                
                cm = confusion_matrix(true_binary, pred_binary)
                
                sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
                plt.xlabel('–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–µ')
                plt.ylabel('–†–µ–∞–ª—å–Ω—ã–µ')
                plt.title(f'{var_name}\nAccuracy={self.metrics_results[var_name]["accuracy"]:.3f}')
            
            plt.tight_layout()
            plt.savefig(output_dir / 'confusion_matrices.png', dpi=300)
            plt.close()
        
        # 4. –°–≤–æ–¥–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ –º–µ—Ç—Ä–∏–∫
        plt.figure(figsize=(12, 8))
        
        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ç–∞–±–ª–∏—Ü—ã
        table_data = []
        for name, metrics in self.metrics_results.items():
            if metrics['type'] == 'regression':
                table_data.append([
                    name,
                    'Regression',
                    f"{metrics['mae']:.4f}",
                    f"{metrics['rmse']:.4f}",
                    f"{metrics['r2']:.4f}",
                    '-'
                ])
            else:
                table_data.append([
                    name,
                    'Classification',
                    '-',
                    '-',
                    '-',
                    f"{metrics['accuracy']:.4f}"
                ])
        
        df_metrics = pd.DataFrame(table_data, 
                                 columns=['Variable', 'Type', 'MAE', 'RMSE', 'R¬≤', 'Accuracy'])
        
        # –°–æ–∑–¥–∞–µ–º —Ç–∞–±–ª–∏—Ü—É
        ax = plt.subplot(111)
        ax.axis('tight')
        ax.axis('off')
        table = ax.table(cellText=df_metrics.values,
                        colLabels=df_metrics.columns,
                        cellLoc='center',
                        loc='center')
        table.auto_set_font_size(False)
        table.set_fontsize(10)
        table.scale(1.2, 1.5)
        
        plt.title('–°–≤–æ–¥–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ –º–µ—Ç—Ä–∏–∫ –º–æ–¥–µ–ª–∏', fontsize=14, pad=20)
        plt.savefig(output_dir / 'metrics_summary_table.png', dpi=300, bbox_inches='tight')
        plt.close()
        
        logger.info(f"‚úÖ –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {output_dir}")
        
    def save_results(self):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –æ—Ü–µ–Ω–∫–∏"""
        output_dir = Path('experiments/evaluation_results')
        output_dir.mkdir(parents=True, exist_ok=True)
        
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç—Ä–∏–∫–∏ –≤ JSON
        results = {
            'timestamp': timestamp,
            'model_path': 'models_saved/best_model.pth',
            'test_samples': len(self.predictions),
            'metrics': self.metrics_results,
            'summary': {
                'avg_mae_regression': np.mean([m['mae'] for m in self.metrics_results.values() if m['type'] == 'regression']),
                'avg_r2_regression': np.mean([m['r2'] for m in self.metrics_results.values() if m['type'] == 'regression']),
                'avg_accuracy_classification': np.mean([m['accuracy'] for m in self.metrics_results.values() if m['type'] == 'classification'])
            }
        }
        
        with open(output_dir / f'evaluation_results_{timestamp}.json', 'w') as f:
            json.dump(results, f, indent=4)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–µ—Ç–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç
        with open(output_dir / f'evaluation_report_{timestamp}.txt', 'w') as f:
            f.write("=" * 80 + "\n")
            f.write("–û–¢–ß–ï–¢ –ü–û –û–¶–ï–ù–ö–ï –ú–û–î–ï–õ–ò PatchTST\n")
            f.write("=" * 80 + "\n\n")
            
            f.write(f"–î–∞—Ç–∞ –æ—Ü–µ–Ω–∫–∏: {timestamp}\n")
            f.write(f"–ú–æ–¥–µ–ª—å: models_saved/best_model.pth\n")
            f.write(f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–µ—Å—Ç–æ–≤—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤: {len(self.predictions)}\n\n")
            
            f.write("–°–í–û–î–ù–´–ï –ú–ï–¢–†–ò–ö–ò:\n")
            f.write("-" * 40 + "\n")
            f.write(f"–°—Ä–µ–¥–Ω–∏–π MAE (—Ä–µ–≥—Ä–µ—Å—Å–∏—è): {results['summary']['avg_mae_regression']:.4f}\n")
            f.write(f"–°—Ä–µ–¥–Ω–∏–π R¬≤ (—Ä–µ–≥—Ä–µ—Å—Å–∏—è): {results['summary']['avg_r2_regression']:.4f}\n")
            f.write(f"–°—Ä–µ–¥–Ω—è—è —Ç–æ—á–Ω–æ—Å—Ç—å (–∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è): {results['summary']['avg_accuracy_classification']:.4f}\n\n")
            
            f.write("–î–ï–¢–ê–õ–¨–ù–´–ï –ú–ï–¢–†–ò–ö–ò –ü–û –ü–ï–†–ï–ú–ï–ù–ù–´–ú:\n")
            f.write("-" * 40 + "\n")
            
            for name, metrics in self.metrics_results.items():
                f.write(f"\n{name}:\n")
                for metric_name, value in metrics.items():
                    if metric_name != 'type':
                        f.write(f"  {metric_name}: {value:.4f}\n")
        
        logger.info(f"‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {output_dir}")
        
    def run_full_evaluation(self):
        """–ó–∞–ø—É—Å–∫ –ø–æ–ª–Ω–æ–π –æ—Ü–µ–Ω–∫–∏ –º–æ–¥–µ–ª–∏"""
        logger.info("üöÄ –ó–∞–ø—É—Å–∫ –ø–æ–ª–Ω–æ–π –æ—Ü–µ–Ω–∫–∏ –º–æ–¥–µ–ª–∏...")
        
        # 1. –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
        self.load_model()
        
        # 2. –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        self.load_data()
        
        # 3. –ü–æ–ª—É—á–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
        self.evaluate_predictions()
        
        # 4. –†–∞—Å—á–µ—Ç –º–µ—Ç—Ä–∏–∫
        self.calculate_metrics()
        
        # 5. –°–æ–∑–¥–∞–Ω–∏–µ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–π
        self.create_visualizations()
        
        # 6. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        self.save_results()
        
        logger.info("‚úÖ –û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ!")
        

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    evaluator = ModelEvaluator()
    evaluator.run_full_evaluation()


if __name__ == "__main__":
    main()