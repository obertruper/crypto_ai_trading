#!/usr/bin/env python3
"""
–ü—Ä–æ–≤–µ—Ä–∫–∞ —É–ª—É—á—à–µ–Ω–Ω—ã—Ö –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤ –ø–æ—Å–ª–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–π
"""

import pandas as pd
import numpy as np
from pathlib import Path
import yaml

def check_indicators():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç–∏ —É–ª—É—á—à–µ–Ω–Ω—ã—Ö –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤"""
    
    print("üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ —É–ª—É—á—à–µ–Ω–Ω—ã—Ö –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤ –ø–æ—Å–ª–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–π\n")
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –Ω–µ–±–æ–ª—å—à—É—é –≤—ã–±–æ—Ä–∫—É –¥–∞–Ω–Ω—ã—Ö
    cache_dir = Path("data/processed")
    train_file = cache_dir / "train_data.parquet"
    
    if not train_file.exists():
        print("‚ùå –§–∞–π–ª train_data.parquet –Ω–µ –Ω–∞–π–¥–µ–Ω")
        return
    
    # –ß–∏—Ç–∞–µ–º –ø–µ—Ä–≤—ã–µ 10000 –∑–∞–ø–∏—Å–µ–π –¥–ª—è –±—ã—Å—Ç—Ä–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏
    df = pd.read_parquet(train_file, engine='pyarrow').head(10000)
    print(f"üìä –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(df)} –∑–∞–ø–∏—Å–µ–π –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏\n")
    
    # –°–ø–∏—Å–æ–∫ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
    indicators_to_check = {
        'close_vwap_ratio': {
            'expected_range': (0.7, 1.3),
            'description': '–†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–µ –≥—Ä–∞–Ω–∏—Ü—ã –¥–ª—è –∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç (¬±30%)'
        },
        'vwap_extreme_deviation': {
            'expected_range': (0, 1),
            'description': '–ë–∏–Ω–∞—Ä–Ω—ã–π –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä —ç–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω—ã—Ö –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–π'
        },
        'bb_position': {
            'expected_range': (0, 1),
            'description': '–ü–æ–∑–∏—Ü–∏—è –≤ Bollinger Bands (—Å –∫–ª–∏–ø–ø–∏–Ω–≥–æ–º)'
        },
        'bb_breakout_upper': {
            'expected_range': (0, 1),
            'description': '–ü—Ä–æ–±–æ–π –≤–µ—Ä—Ö–Ω–µ–π –≥—Ä–∞–Ω–∏—Ü—ã BB'
        },
        'bb_breakout_lower': {
            'expected_range': (0, 1),
            'description': '–ü—Ä–æ–±–æ–π –Ω–∏–∂–Ω–µ–π –≥—Ä–∞–Ω–∏—Ü—ã BB'
        },
        'price_impact': {
            'expected_range': (0, 10),
            'description': 'Price impact —Å dollar volume'
        },
        'kyle_lambda': {
            'expected_range': (0, 10),
            'description': 'Kyle Lambda (–ø—Ä–∞–≤–∏–ª—å–Ω–∞—è —Ñ–æ—Ä–º—É–ª–∞)'
        },
        'realized_vol_daily': {
            'expected_range': (0, 5),
            'description': '–î–Ω–µ–≤–Ω–∞—è –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å'
        },
        'volume_zscore': {
            'expected_range': (-50, 50),
            'description': 'Z-score –æ–±—ä–µ–º–∞ (—Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –¥–∏–∞–ø–∞–∑–æ–Ω)'
        },
        'toxicity': {
            'expected_range': (0, 1),
            'description': 'Toxicity = 1/(1+price_impact)'
        }
    }
    
    print("üìà –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ò–ù–î–ò–ö–ê–¢–û–†–û–í:\n")
    
    for indicator, info in indicators_to_check.items():
        if indicator in df.columns:
            stats = df[indicator].describe()
            min_val, max_val = info['expected_range']
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–∏–∞–ø–∞–∑–æ–Ω–∞
            in_range = (stats['min'] >= min_val - 0.01) and (stats['max'] <= max_val + 0.01)
            status = "‚úÖ" if in_range else "‚ö†Ô∏è"
            
            print(f"{status} {indicator}:")
            print(f"   {info['description']}")
            print(f"   –î–∏–∞–ø–∞–∑–æ–Ω: [{stats['min']:.4f}, {stats['max']:.4f}]")
            print(f"   –°—Ä–µ–¥–Ω–µ–µ: {stats['mean']:.4f}, Std: {stats['std']:.4f}")
            print(f"   –û–∂–∏–¥–∞–µ—Ç—Å—è: {info['expected_range']}")
            
            # –°–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ –ø—Ä–æ–≤–µ—Ä–∫–∏
            if indicator == 'toxicity':
                mean_expected = stats['mean'] > 0.95
                print(f"   {'‚úÖ' if mean_expected else '‚ùå'} Mean > 0.95: {mean_expected}")
            
            if indicator == 'bb_breakout_upper':
                breakout_pct = stats['mean'] * 100
                print(f"   –ü—Ä–æ—Ü–µ–Ω—Ç –ø—Ä–æ–±–æ–µ–≤ –≤–≤–µ—Ä—Ö: {breakout_pct:.1f}%")
            
            if indicator == 'volume_zscore':
                extreme_count = ((df[indicator] > 10) | (df[indicator] < -10)).sum()
                extreme_pct = extreme_count / len(df) * 100
                print(f"   –≠–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è (|z| > 10): {extreme_pct:.2f}%")
            
            print()
        else:
            print(f"‚ùå {indicator}: –ù–ï –ù–ê–ô–î–ï–ù –í –î–ê–ù–ù–´–•\n")
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π
    print("üìä –ö–û–†–†–ï–õ–Ø–¶–ò–ò –ú–ï–ñ–î–£ –ò–ù–î–ò–ö–ê–¢–û–†–ê–ú–ò:\n")
    
    correlation_pairs = [
        ('price_impact', 'toxicity'),
        ('bb_position', 'bb_breakout_upper'),
        ('close_vwap_ratio', 'vwap_extreme_deviation'),
        ('volume_zscore', 'price_impact')
    ]
    
    for ind1, ind2 in correlation_pairs:
        if ind1 in df.columns and ind2 in df.columns:
            corr = df[ind1].corr(df[ind2])
            print(f"–ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è {ind1} <-> {ind2}: {corr:.3f}")
    
    print("\nüéØ –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:")
    print("1. –ï—Å–ª–∏ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç - –Ω—É–∂–Ω–æ –ø–µ—Ä–µ—Å–æ–∑–¥–∞—Ç—å –¥–∞—Ç–∞—Å–µ—Ç")
    print("2. –ï—Å–ª–∏ –¥–∏–∞–ø–∞–∑–æ–Ω—ã –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã - –ø—Ä–æ–≤–µ—Ä–∏—Ç—å —Ñ–æ—Ä–º—É–ª—ã –≤ feature_engineering.py")
    print("3. –î–ª—è –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è –∏–∑–º–µ–Ω–µ–Ω–∏–π –∑–∞–ø—É—Å—Ç–∏—Ç–µ: python prepare_trading_data.py --force-recreate")

if __name__ == "__main__":
    check_indicators()