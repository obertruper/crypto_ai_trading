#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∞–Ω–Ω—ã—Ö –ø–µ—Ä–µ–¥ –æ–±—É—á–µ–Ω–∏–µ–º
"""

import pandas as pd
import yaml
from pathlib import Path
from data.constants import (
    TRADING_TARGET_VARIABLES, ADDITIONAL_TARGET_VARIABLES,
    SERVICE_COLUMNS, validate_data_structure
)
from utils.logger import get_logger

def main():
    logger = get_logger("DataValidator")
    
    logger.info("="*80)
    logger.info("üîç –í–∞–ª–∏–¥–∞—Ü–∏—è —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∞–Ω–Ω—ã—Ö")
    logger.info("="*80)
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è —Ñ–∞–π–ª–æ–≤
    data_dir = Path("data/processed")
    files = {
        'train': data_dir / "train_data.parquet",
        'val': data_dir / "val_data.parquet", 
        'test': data_dir / "test_data.parquet"
    }
    
    missing_files = [name for name, path in files.items() if not path.exists()]
    if missing_files:
        logger.error(f"‚ùå –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç —Ñ–∞–π–ª—ã: {missing_files}")
        logger.error("–ó–∞–ø—É—Å—Ç–∏—Ç–µ: python prepare_trading_data.py")
        return False
    
    logger.info("‚úÖ –í—Å–µ —Ñ–∞–π–ª—ã –Ω–∞–π–¥–µ–Ω—ã")
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
    with open('config/config.yaml', 'r') as f:
        config = yaml.safe_load(f)
    
    config_targets = config['model']['target_variables']
    logger.info(f"\nüìã –¶–µ–ª–µ–≤—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –∏–∑ config.yaml: {len(config_targets)}")
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞–∂–¥–æ–≥–æ —Ñ–∞–π–ª–∞
    all_valid = True
    for name, path in files.items():
        logger.info(f"\n{'='*40}")
        logger.info(f"–ü—Ä–æ–≤–µ—Ä–∫–∞ {name}_data.parquet")
        logger.info(f"{'='*40}")
        
        df = pd.read_parquet(path)
        logger.info(f"–†–∞–∑–º–µ—Ä: {df.shape}")
        
        try:
            info = validate_data_structure(df)
            logger.info(f"‚úÖ –ü—Ä–∏–∑–Ω–∞–∫–æ–≤: {info['n_features']}")
            logger.info(f"‚úÖ –¶–µ–ª–µ–≤—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö: {info['n_targets']}")
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è —Å –∫–æ–Ω—Ñ–∏–≥–æ–º
            df_targets = set(info['target_cols'])
            config_targets_set = set(config_targets)
            
            if df_targets != config_targets_set:
                logger.warning("‚ö†Ô∏è –ù–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Ü–µ–ª–µ–≤—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö —Å –∫–æ–Ω—Ñ–∏–≥–æ–º!")
                only_in_df = df_targets - config_targets_set
                only_in_config = config_targets_set - df_targets
                
                if only_in_df:
                    logger.warning(f"   –¢–æ–ª—å–∫–æ –≤ –¥–∞–Ω–Ω—ã—Ö: {only_in_df}")
                if only_in_config:
                    logger.error(f"   ‚ùå –¢–æ–ª—å–∫–æ –≤ –∫–æ–Ω—Ñ–∏–≥–µ: {only_in_config}")
                    all_valid = False
                    
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö
            additional_found = [col for col in ADDITIONAL_TARGET_VARIABLES if col in df.columns]
            if additional_found:
                logger.info(f"‚ÑπÔ∏è –ù–∞–π–¥–µ–Ω–æ {len(additional_found)} –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö —Ü–µ–ª–µ–≤—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö")
                logger.info("   (–æ–Ω–∏ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –¥–ª—è –æ–±—É—á–µ–Ω–∏—è)")
                
        except ValueError as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏: {e}")
            all_valid = False
    
    # –ò—Ç–æ–≥–æ–≤—ã–π –≤–µ—Ä–¥–∏–∫—Ç
    logger.info("\n" + "="*80)
    if all_valid:
        logger.info("‚úÖ –í–ê–õ–ò–î–ê–¶–ò–Ø –ü–†–û–ô–î–ï–ù–ê –£–°–ü–ï–®–ù–û!")
        logger.info("\n–ú–æ–∂–Ω–æ –∑–∞–ø—É—Å–∫–∞—Ç—å –æ–±—É—á–µ–Ω–∏–µ:")
        logger.info("  python main.py --mode train")
    else:
        logger.error("‚ùå –í–ê–õ–ò–î–ê–¶–ò–Ø –ù–ï –ü–†–û–ô–î–ï–ù–ê!")
        logger.error("\n–ò—Å–ø—Ä–∞–≤—å—Ç–µ –æ—à–∏–±–∫–∏ –∏ –∑–∞–ø—É—Å—Ç–∏—Ç–µ –≤–∞–ª–∏–¥–∞—Ü–∏—é —Å–Ω–æ–≤–∞")
    logger.info("="*80)
    
    return all_valid

if __name__ == "__main__":
    main()