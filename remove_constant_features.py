#!/usr/bin/env python3
"""
–£–¥–∞–ª–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å –Ω—É–ª–µ–≤–æ–π –¥–∏—Å–ø–µ—Ä—Å–∏–µ–π –∏–∑ –¥–∞–Ω–Ω—ã—Ö
"""
import pandas as pd
import numpy as np
from pathlib import Path

print("üîß –£–¥–∞–ª–µ–Ω–∏–µ –∫–æ–Ω—Å—Ç–∞–Ω—Ç–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏–∑ –¥–∞–Ω–Ω—ã—Ö")
print("="*60)

# –ü—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è
features_to_remove = ['vwap_extreme_deviation']

datasets = {
    'train': 'data/processed/train_data.parquet',
    'val': 'data/processed/val_data.parquet',
    'test': 'data/processed/test_data.parquet'
}

for name, path in datasets.items():
    print(f"\nüìä –û–±—Ä–∞–±–æ—Ç–∫–∞ {name.upper()} –Ω–∞–±–æ—Ä–∞:")
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
    df = pd.read_parquet(path)
    original_shape = df.shape
    
    # –£–¥–∞–ª—è–µ–º –ø—Ä–æ–±–ª–µ–º–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
    removed = []
    for feature in features_to_remove:
        if feature in df.columns:
            df = df.drop(columns=[feature])
            removed.append(feature)
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
    df.to_parquet(path, index=False)
    
    print(f"   –ò—Å—Ö–æ–¥–Ω—ã–π —Ä–∞–∑–º–µ—Ä: {original_shape}")
    print(f"   –ù–æ–≤—ã–π —Ä–∞–∑–º–µ—Ä: {df.shape}")
    print(f"   –£–¥–∞–ª–µ–Ω–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {len(removed)}")
    if removed:
        print(f"   –£–¥–∞–ª–µ–Ω–Ω—ã–µ: {', '.join(removed)}")

print("\n‚úÖ –î–∞–Ω–Ω—ã–µ –æ–±–Ω–æ–≤–ª–µ–Ω—ã!")
print("\nüìù –¢–µ–ø–µ—Ä—å –∑–∞–ø—É—Å—Ç–∏—Ç–µ –ø—Ä–æ–≤–µ—Ä–∫—É:")
print("   python verify_data_correctness.py")