#!/usr/bin/env python3
"""
–¢–µ—Å—Ç–æ–≤—ã–π —Å–∫—Ä–∏–ø—Ç –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏ –ø—Ä–æ–±–ª–µ–º—ã —Å –æ–±—É—á–µ–Ω–∏–µ–º
"""
import torch
import yaml
import pandas as pd
import numpy as np
from pathlib import Path

# –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
with open('config/config.yaml', 'r') as f:
    config = yaml.safe_load(f)

print("="*80)
print("üîç –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê –ü–†–û–ë–õ–ï–ú–´ –° –û–ë–£–ß–ï–ù–ò–ï–ú")
print("="*80)

# 1. –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
print("\n1Ô∏è‚É£ –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö:")
data_dir = Path("data/processed")
train_file = data_dir / "train_data.parquet"

if train_file.exists():
    train_data = pd.read_parquet(train_file)
    print(f"‚úÖ Train data –∑–∞–≥—Ä—É–∂–µ–Ω–∞: {len(train_data):,} –∑–∞–ø–∏—Å–µ–π")
    
    # –ê–Ω–∞–ª–∏–∑ –∫–æ–ª–æ–Ω–æ–∫
    exclude_prefixes = ('target_', 'future_', 'long_tp', 'short_tp', 'long_sl', 'short_sl',
                       'long_optimal', 'short_optimal', 'long_expected', 'short_expected',
                       'best_direction', 'signal_strength', 'long_final', 'short_final')
    
    feature_cols = [col for col in train_data.columns 
                   if col not in ['id', 'symbol', 'datetime', 'timestamp', 'sector']
                   and not any(col.startswith(prefix) for prefix in exclude_prefixes)]
    
    target_cols = [col for col in train_data.columns 
                  if col.startswith(('target_', 'future_return_', 'long_tp', 'short_tp', 
                                   'long_sl', 'short_sl', 'long_optimal', 'short_optimal',
                                   'best_direction'))]
    
    print(f"\nüìä –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–∞–Ω–Ω—ã—Ö:")
    print(f"   - –í—Å–µ–≥–æ –∫–æ–ª–æ–Ω–æ–∫: {len(train_data.columns)}")
    print(f"   - –ü—Ä–∏–∑–Ω–∞–∫–æ–≤: {len(feature_cols)}")
    print(f"   - –¶–µ–ª–µ–≤—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö: {len(target_cols)}")
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ NaN
    nan_counts = train_data[feature_cols].isna().sum()
    if nan_counts.sum() > 0:
        print(f"\n‚ö†Ô∏è  –ù–∞–π–¥–µ–Ω—ã NaN –≤ –ø—Ä–∏–∑–Ω–∞–∫–∞—Ö:")
        for col, count in nan_counts[nan_counts > 0].head().items():
            print(f"   - {col}: {count} NaN")
    else:
        print(f"\n‚úÖ NaN –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –≤ –ø—Ä–∏–∑–Ω–∞–∫–∞—Ö")
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–∏–∞–ø–∞–∑–æ–Ω–æ–≤ –∑–Ω–∞—á–µ–Ω–∏–π
    print(f"\nüìà –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤:")
    numeric_features = train_data[feature_cols].select_dtypes(include=[np.number])
    print(f"   - Min –∑–Ω–∞—á–µ–Ω–∏—è: {numeric_features.min().min():.4f}")
    print(f"   - Max –∑–Ω–∞—á–µ–Ω–∏—è: {numeric_features.max().max():.4f}")
    print(f"   - Mean –∑–Ω–∞—á–µ–Ω–∏—è: {numeric_features.mean().mean():.4f}")
    print(f"   - Std –∑–Ω–∞—á–µ–Ω–∏—è: {numeric_features.std().mean():.4f}")
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ü–µ–ª–µ–≤—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö
    print(f"\nüéØ –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Ü–µ–ª–µ–≤—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö:")
    for col in target_cols[:5]:  # –ü–µ—Ä–≤—ã–µ 5 —Ü–µ–ª–µ–≤—ã—Ö
        if col in train_data.columns:
            unique_vals = train_data[col].unique()
            if len(unique_vals) < 10:
                print(f"   - {col}: —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è = {unique_vals}")
            else:
                print(f"   - {col}: min={train_data[col].min():.4f}, max={train_data[col].max():.4f}, mean={train_data[col].mean():.4f}")

# 2. –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –º–æ–¥–µ–ª–∏
print(f"\n2Ô∏è‚É£ –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –º–æ–¥–µ–ª–∏:")
print(f"   - Model name: {config['model']['name']}")
print(f"   - Task type: {config['model'].get('task_type', 'regression')}")
print(f"   - Learning rate: {config['model']['learning_rate']}")
print(f"   - Batch size: {config['model']['batch_size']}")
print(f"   - Loss function: {config['loss']['name']}")

# 3. –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–æ—Å—Ç–æ–≥–æ –±–∞—Ç—á–∞ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
print(f"\n3Ô∏è‚É£ –°–æ–∑–¥–∞–Ω–∏–µ —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –±–∞—Ç—á–∞:")
from data.dataset import TradingDataset

# –°–æ–∑–¥–∞–µ–º –º–∞–ª–µ–Ω—å–∫–∏–π dataset –¥–ª—è —Ç–µ—Å—Ç–∞
test_dataset = TradingDataset(
    data=train_data.head(1000),  # –ë–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ 1000 –∑–∞–ø–∏—Å–µ–π
    config=config,
    context_window=config['model']['context_window'],
    prediction_window=config['model']['pred_len'],
    feature_cols=feature_cols,
    target_cols=target_cols
)

print(f"‚úÖ Dataset —Å–æ–∑–¥–∞–Ω: {len(test_dataset)} –ø—Ä–∏–º–µ—Ä–æ–≤")

# –ü–æ–ª—É—á–∞–µ–º –æ–¥–∏–Ω –±–∞—Ç—á
X, y, info = test_dataset[0]
print(f"\nüìä –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ –±–∞—Ç—á–∞:")
print(f"   - X shape: {X.shape}")
print(f"   - y shape: {y.shape}")
print(f"   - X dtype: {X.dtype}")
print(f"   - y dtype: {y.dtype}")

# 4. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏
print(f"\n4Ô∏è‚É£ –¢–µ—Å—Ç –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –º–æ–¥–µ–ª–∏:")
try:
    # –û–±–Ω–æ–≤–ª—è–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
    config_copy = config.copy()
    config_copy['model']['input_features'] = len(feature_cols)
    config_copy['model']['n_features'] = len(feature_cols)
    config_copy['model']['target_variables'] = target_cols
    
    from models.patchtst import create_patchtst_model
    
    model = create_patchtst_model(config_copy)
    print(f"‚úÖ –ú–æ–¥–µ–ª—å —Å–æ–∑–¥–∞–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
    print(f"   - –ü–∞—Ä–∞–º–µ—Ç—Ä–æ–≤: {sum(p.numel() for p in model.parameters()):,}")
    
    # –¢–µ—Å—Ç forward pass
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model = model.to(device)
    X_batch = X.unsqueeze(0).to(device)  # –î–æ–±–∞–≤–ª—è–µ–º batch dimension
    
    with torch.no_grad():
        output = model(X_batch)
    
    print(f"\nüìä Output shape: {output.shape}")
    print(f"   - Output min: {output.min().item():.4f}")
    print(f"   - Output max: {output.max().item():.4f}")
    print(f"   - Output mean: {output.mean().item():.4f}")
    
    # –¢–µ—Å—Ç loss
    from models.trading_losses import TradingMultiTaskLoss
    criterion = TradingMultiTaskLoss(config_copy)
    
    y_batch = y.unsqueeze(0).to(device)
    loss = criterion(output, y_batch)
    
    print(f"\nüìä Loss value: {loss.item():.4f}")
    
except Exception as e:
    print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
    import traceback
    traceback.print_exc()

print("\n" + "="*80)
print("‚úÖ –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞")
print("="*80)