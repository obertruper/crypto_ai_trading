"""
–û—Ç–ª–∞–¥–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞ –¥–ª—è Direction –º–æ–¥–µ–ª–∏
"""

import pandas as pd
import torch
from torch.utils.data import DataLoader

# –ò–º–ø–æ—Ä—Ç—ã –∏–∑ –ø—Ä–æ–µ–∫—Ç–∞
from train_direction_model import DirectionDatasetAdapter
from utils.config import load_config

def debug_dataset():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∞–Ω–Ω—ã—Ö –≤ –¥–∞—Ç–∞—Å–µ—Ç–µ"""
    
    print("üîç –û—Ç–ª–∞–¥–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞...")
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
    train_data = pd.read_parquet("data/processed/train_data.parquet")
    
    print(f"\nüìä –ó–∞–≥—Ä—É–∂–µ–Ω–æ –¥–∞–Ω–Ω—ã—Ö: {len(train_data)} —Å—Ç—Ä–æ–∫")
    print(f"   –ö–æ–ª–æ–Ω–∫–∏: {train_data.shape[1]}")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º direction –∫–æ–ª–æ–Ω–∫–∏
    direction_cols = [col for col in train_data.columns if col.startswith('direction_')]
    print(f"\nüéØ Direction –∫–æ–ª–æ–Ω–∫–∏: {direction_cols}")
    
    if direction_cols:
        for col in direction_cols[:2]:  # –ü–µ—Ä–≤—ã–µ 2 –¥–ª—è –ø—Ä–∏–º–µ—Ä–∞
            print(f"\n   {col}:")
            print(f"   - –£–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è: {train_data[col].unique()}")
            print(f"   - –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ: {train_data[col].value_counts().to_dict()}")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º future_return –∫–æ–ª–æ–Ω–∫–∏
    return_cols = [col for col in train_data.columns if col.startswith('future_return_')]
    print(f"\nüí∞ Future return –∫–æ–ª–æ–Ω–∫–∏: {return_cols}")
    
    # –°–æ–∑–¥–∞–µ–º –¥–∞—Ç–∞—Å–µ—Ç
    config = load_config('configs/direction_only.yaml')
    
    feature_columns = [col for col in train_data.columns 
                      if col not in ['id', 'symbol', 'datetime', 'timestamp']
                      and not col.startswith(('target_', 'future_', 'direction_', 'optimal_'))]
    
    print(f"\n‚ú® –ü—Ä–∏–∑–Ω–∞–∫–æ–≤: {len(feature_columns)}")
    
    # –°–æ–∑–¥–∞–µ–º –Ω–µ–±–æ–ª—å—à–æ–π –¥–∞—Ç–∞—Å–µ—Ç –¥–ª—è —Ç–µ—Å—Ç–∞
    small_data = train_data.head(1000)
    
    dataset = DirectionDatasetAdapter(
        small_data,
        context_window=168,
        feature_cols=feature_columns,
        target_cols=direction_cols,
        stride=1,
        normalize=False
    )
    
    print(f"\nüì¶ –î–∞—Ç–∞—Å–µ—Ç —Å–æ–∑–¥–∞–Ω: {len(dataset)} –ø—Ä–∏–º–µ—Ä–æ–≤")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–µ—Ä–≤—ã–π –ø—Ä–∏–º–µ—Ä
    if len(dataset) > 0:
        features, targets, info = dataset[0]
        
        print(f"\nüîç –ü–µ—Ä–≤—ã–π –ø—Ä–∏–º–µ—Ä:")
        print(f"   Features shape: {features.shape}")
        print(f"   Targets: {targets}")
        print(f"   Price changes: {info.get('price_changes', {})}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º targets
        for key, value in targets.items():
            print(f"\n   {key}:")
            print(f"   - Shape: {value.shape}")
            print(f"   - Type: {value.dtype}")
            print(f"   - Value: {value.item() if value.numel() == 1 else value}")
    
    # –°–æ–∑–¥–∞–µ–º DataLoader
    loader = DataLoader(dataset, batch_size=4, shuffle=False)
    
    print("\nüöÄ –ü—Ä–æ–≤–µ—Ä–∫–∞ –±–∞—Ç—á–∞...")
    for i, (features, targets, info) in enumerate(loader):
        print(f"\n   –ë–∞—Ç—á {i}:")
        print(f"   Features shape: {features.shape}")
        
        for key, value in targets.items():
            print(f"   {key} shape: {value.shape}, dtype: {value.dtype}")
            
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º price_changes
        if 'price_changes' in info:
            for timeframe, changes in info['price_changes'].items():
                print(f"   price_changes[{timeframe}] shape: {changes.shape}")
        
        break  # –¢–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–π –±–∞—Ç—á
    
    print("\n‚úÖ –û—Ç–ª–∞–¥–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")


if __name__ == "__main__":
    debug_dataset()