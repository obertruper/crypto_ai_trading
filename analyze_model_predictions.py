#!/usr/bin/env python3
"""
–ê–Ω–∞–ª–∏–∑ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏
"""

import torch
import yaml
from pathlib import Path
import h5py
import numpy as np

from utils.logger import get_logger

def main():
    logger = get_logger("AnalyzeModel")
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º checkpoint
    checkpoint_path = Path("models_saved/best_model.pth")
    if not checkpoint_path.exists():
        logger.error(f"‚ùå Checkpoint –Ω–µ –Ω–∞–π–¥–µ–Ω: {checkpoint_path}")
        return
        
    logger.info(f"üì• –ó–∞–≥—Ä—É–∂–∞–µ–º checkpoint –∏–∑ {checkpoint_path}")
    checkpoint = torch.load(checkpoint_path, map_location='cuda')
    
    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ
    logger.info("\nüìä –°–æ–¥–µ—Ä–∂–∏–º–æ–µ checkpoint:")
    for key in checkpoint.keys():
        if key == 'model_state_dict':
            logger.info(f"   {key}: {len(checkpoint[key])} –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤")
            # –ò—â–µ–º direction_head bias
            for param_name, param in checkpoint[key].items():
                if 'direction_head' in param_name and 'bias' in param_name:
                    logger.info(f"\n   üìç {param_name}: shape={param.shape}")
                    if param.shape[0] == 12:
                        bias = param.view(4, 3)
                        for i in range(4):
                            logger.info(f"      TF{i}: LONG={bias[i,0]:.3f}, SHORT={bias[i,1]:.3f}, FLAT={bias[i,2]:.3f}")
        else:
            logger.info(f"   {key}: {checkpoint[key] if not isinstance(checkpoint[key], dict) else len(checkpoint[key])}")
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
    val_file = Path("cache/precomputed/val_w168_s4.h5")
    if val_file.exists():
        logger.info(f"\nüìä –ó–∞–≥—Ä—É–∂–∞–µ–º –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ {val_file}")
        
        with h5py.File(val_file, 'r') as f:
            X = f['X'][:100]  # –ü–µ—Ä–≤—ã–µ 100 –ø—Ä–∏–º–µ—Ä–æ–≤
            y = f['y'][:100]
            
            logger.info(f"   X shape: {X.shape}")
            logger.info(f"   y shape: {y.shape}")
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤ –≤ –¥–∞–Ω–Ω—ã—Ö
            if y.shape[2] >= 8:  # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –µ—Å—Ç—å direction –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ
                for i, tf in enumerate(['15m', '1h', '4h', '12h']):
                    direction_idx = 4 + i
                    if direction_idx < y.shape[2]:
                        directions = y[:, 0, direction_idx]
                        unique, counts = np.unique(directions, return_counts=True)
                        
                        logger.info(f"\n   üïê {tf} - —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤ –¥–∞–Ω–Ω—ã—Ö:")
                        for cls, cnt in zip(unique, counts):
                            logger.info(f"      –ö–ª–∞—Å—Å {int(cls)}: {cnt} ({cnt/len(directions)*100:.1f}%)")
    
    # –°–æ–∑–¥–∞–µ–º –º–æ–¥–µ–ª—å –∏ –∑–∞–≥—Ä—É–∂–∞–µ–º –≤–µ—Å–∞
    config_path = Path("config/config.yaml")
    with open(config_path, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    
    # –û–±–Ω–æ–≤–ª—è–µ–º input_size –∏–∑ checkpoint
    if 'config' in checkpoint:
        saved_config = checkpoint['config']
        if 'model' in saved_config and 'input_size' in saved_config['model']:
            config['model']['input_size'] = saved_config['model']['input_size']
            logger.info(f"\n‚úÖ –ò—Å–ø–æ–ª—å–∑—É–µ–º input_size –∏–∑ checkpoint: {config['model']['input_size']}")
    
    # –ü—Ä–æ–±—É–µ–º –∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å
    try:
        from models.patchtst_unified import UnifiedPatchTSTForTrading
        model = UnifiedPatchTSTForTrading(config['model']).cuda()
        model.load_state_dict(checkpoint['model_state_dict'], strict=False)
        model.eval()
        logger.info("‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
        
        # –¢–µ—Å—Ç–∏—Ä—É–µ–º –Ω–∞ —Å–ª—É—á–∞–π–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        batch_size = 32
        seq_len = 168
        n_features = config['model']['input_size']
        
        x = torch.randn(batch_size, seq_len, n_features).cuda()
        
        with torch.no_grad():
            outputs = model(x)
            
            if hasattr(outputs, '_direction_logits'):
                direction_logits = outputs._direction_logits
                
                logger.info("\nüìä –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –º–æ–¥–µ–ª–∏ –Ω–∞ —Å–ª—É—á–∞–π–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö:")
                for i, tf in enumerate(['15m', '1h', '4h', '12h']):
                    logits = direction_logits[:, i, :]
                    probs = torch.softmax(logits, dim=-1)
                    predictions = torch.argmax(probs, dim=-1)
                    
                    unique, counts = torch.unique(predictions, return_counts=True)
                    
                    logger.info(f"\n   üïê {tf}:")
                    class_dist = {0: 0, 1: 0, 2: 0}
                    for cls, cnt in zip(unique.cpu().numpy(), counts.cpu().numpy()):
                        class_dist[int(cls)] = cnt
                    
                    logger.info(f"      LONG:  {class_dist[0]} ({class_dist[0]/batch_size*100:.1f}%)")
                    logger.info(f"      SHORT: {class_dist[1]} ({class_dist[1]/batch_size*100:.1f}%)")
                    logger.info(f"      FLAT:  {class_dist[2]} ({class_dist[2]/batch_size*100:.1f}%)")
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ª–æ–≥–∏—Ç—ã
                    mean_logits = logits.mean(dim=0).cpu()
                    logger.info(f"      –°—Ä–µ–¥–Ω–∏–µ –ª–æ–≥–∏—Ç—ã: [{mean_logits[0]:.3f}, {mean_logits[1]:.3f}, {mean_logits[2]:.3f}]")
                    
                    if len(unique) == 1:
                        logger.warning(f"      ‚ö†Ô∏è –ú–æ–¥–µ–ª—å –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç –¢–û–õ–¨–ö–û –∫–ª–∞—Å—Å {unique[0].item()}!")
                        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e}")

if __name__ == "__main__":
    main()