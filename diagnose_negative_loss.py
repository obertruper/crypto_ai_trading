#!/usr/bin/env python3
"""
–î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –ø—Ä–æ–±–ª–µ–º—ã —Å –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–º loss
"""

import torch
import torch.nn.functional as F
import numpy as np

def test_confidence_loss():
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ confidence loss —Å —Ä–∞–∑–Ω—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏"""
    print("\n" + "="*80)
    print("üîç –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –ø—Ä–æ–±–ª–µ–º—ã —Å –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–º loss")
    print("="*80)
    
    # –¢–µ—Å—Ç–æ–≤—ã–µ —Å–ª—É—á–∞–∏
    batch_size = 4
    n_timeframes = 4
    
    # –°–ª—É—á–∞–π 1: –ù–æ—Ä–º–∞–ª—å–Ω—ã–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
    print("\n1. –ù–æ—Ä–º–∞–ª—å–Ω—ã–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è:")
    confidence_logits = torch.randn(batch_size, n_timeframes) * 2  # –õ–æ–≥–∏—Ç—ã –æ—Ç -2 –¥–æ 2
    correct_predictions = torch.randint(0, 2, (batch_size, n_timeframes)).float()
    
    loss1 = F.binary_cross_entropy_with_logits(confidence_logits, correct_predictions)
    print(f"   Confidence logits: {confidence_logits[0]}")
    print(f"   Correct predictions: {correct_predictions[0]}")
    print(f"   Loss: {loss1.item():.4f}")
    
    # –°–ª—É—á–∞–π 2: –û—á–µ–Ω—å —É–≤–µ—Ä–µ–Ω–Ω—ã–µ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
    print("\n2. –û—á–µ–Ω—å —É–≤–µ—Ä–µ–Ω–Ω—ã–µ –ü–†–ê–í–ò–õ–¨–ù–´–ï –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è:")
    confidence_logits = torch.ones(batch_size, n_timeframes) * 10  # –û—á–µ–Ω—å –≤—ã—Å–æ–∫–∏–µ –ª–æ–≥–∏—Ç—ã
    correct_predictions = torch.ones(batch_size, n_timeframes)  # –í—Å–µ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ
    
    loss2 = F.binary_cross_entropy_with_logits(confidence_logits, correct_predictions)
    print(f"   Confidence logits: {confidence_logits[0]}")
    print(f"   Correct predictions: {correct_predictions[0]}")
    print(f"   Loss: {loss2.item():.4f}")
    
    # –°–ª—É—á–∞–π 3: –û—á–µ–Ω—å —É–≤–µ—Ä–µ–Ω–Ω—ã–µ –ù–ï–ü–†–ê–í–ò–õ–¨–ù–´–ï –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
    print("\n3. –û—á–µ–Ω—å —É–≤–µ—Ä–µ–Ω–Ω—ã–µ –ù–ï–ü–†–ê–í–ò–õ–¨–ù–´–ï –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è:")
    confidence_logits = torch.ones(batch_size, n_timeframes) * 10  # –û—á–µ–Ω—å –≤—ã—Å–æ–∫–∏–µ –ª–æ–≥–∏—Ç—ã
    correct_predictions = torch.zeros(batch_size, n_timeframes)  # –í—Å–µ –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ
    
    loss3 = F.binary_cross_entropy_with_logits(confidence_logits, correct_predictions)
    print(f"   Confidence logits: {confidence_logits[0]}")
    print(f"   Correct predictions: {correct_predictions[0]}")
    print(f"   Loss: {loss3.item():.4f}")
    
    # –°–ª—É—á–∞–π 4: –ù–µ–≥–∞—Ç–∏–≤–Ω—ã–µ –ª–æ–≥–∏—Ç—ã —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è–º–∏
    print("\n4. –ù–µ–≥–∞—Ç–∏–≤–Ω—ã–µ –ª–æ–≥–∏—Ç—ã —Å –ü–†–ê–í–ò–õ–¨–ù–´–ú–ò –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è–º–∏:")
    confidence_logits = torch.ones(batch_size, n_timeframes) * -10  # –û—á–µ–Ω—å –Ω–∏–∑–∫–∏–µ –ª–æ–≥–∏—Ç—ã
    correct_predictions = torch.zeros(batch_size, n_timeframes)  # –ü—Ä–∞–≤–∏–ª—å–Ω–æ (low conf = wrong)
    
    loss4 = F.binary_cross_entropy_with_logits(confidence_logits, correct_predictions)
    print(f"   Confidence logits: {confidence_logits[0]}")
    print(f"   Correct predictions: {correct_predictions[0]}")
    print(f"   Loss: {loss4.item():.4f}")
    
    # –ü—Ä–æ–±–ª–µ–º–∞ —Å —Å—É–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ–º losses
    print("\n5. –ü—Ä–æ–±–ª–µ–º–∞ —Å—É–º–º–∏—Ä–æ–≤–∞–Ω–∏—è –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö loss –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤:")
    losses = []
    
    # –ù–æ—Ä–º–∞–ª—å–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã loss
    mse_loss = torch.tensor(0.5)
    ce_loss = torch.tensor(1.2)
    bce_loss = torch.tensor(0.8)
    
    losses.extend([mse_loss, ce_loss, bce_loss])
    
    # –ü—Ä–æ–±–ª–µ–º–Ω—ã–π confidence loss
    problematic_confidence_loss = torch.tensor(-100.0)  # –ï—Å–ª–∏ –º–æ–¥–µ–ª—å —Å–ª–∏—à–∫–æ–º —É–≤–µ—Ä–µ–Ω–∞
    losses.append(problematic_confidence_loss * 0.5)  # –î–∞–∂–µ —Å –≤–µ—Å–æ–º 0.5
    
    total_loss = sum(losses)
    print(f"   MSE loss: {mse_loss.item()}")
    print(f"   CE loss: {ce_loss.item()}")
    print(f"   BCE loss: {bce_loss.item()}")
    print(f"   Confidence loss (weighted): {(problematic_confidence_loss * 0.5).item()}")
    print(f"   Total loss: {total_loss.item()}")
    
    print("\nüî¥ –ü–†–û–ë–õ–ï–ú–ê –ù–ê–ô–î–ï–ù–ê:")
    print("   BCE loss –º–æ–∂–µ—Ç –¥–∞–≤–∞—Ç—å –æ—á–µ–Ω—å –±–æ–ª—å—à–∏–µ –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è")
    print("   –∫–æ–≥–¥–∞ –º–æ–¥–µ–ª—å —É–≤–µ—Ä–µ–Ω–∞ –≤ –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è—Ö!")
    
    print("\nüí° –†–ï–®–ï–ù–ò–ï:")
    print("   1. –û–≥—Ä–∞–Ω–∏—á–∏—Ç—å confidence logits —Å –ø–æ–º–æ—â—å—é tanh –∏–ª–∏ clamp")
    print("   2. –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å gradient clipping –¥–ª—è confidence loss")
    print("   3. –£–º–µ–Ω—å—à–∏—Ç—å –≤–µ—Å confidence loss")
    print("   4. –î–æ–±–∞–≤–∏—Ç—å —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—é –¥–ª—è confidence head")
    print("="*80)


if __name__ == "__main__":
    test_confidence_loss()