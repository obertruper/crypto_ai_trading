"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–π –æ—Ü–µ–Ω–∫–∏ –æ–±—É—á–µ–Ω–Ω–æ–π Direction –º–æ–¥–µ–ª–∏
–í–∫–ª—é—á–∞–µ—Ç confusion matrix, –º–µ—Ç—Ä–∏–∫–∏ –ø–æ –∫–ª–∞—Å—Å–∞–º –∏ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—é
"""

import torch
import torch.nn as nn
from torch.utils.data import DataLoader
import numpy as np
import pandas as pd
from pathlib import Path
import argparse
import json
from datetime import datetime
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix, classification_report, accuracy_score
from typing import Dict, List, Tuple, Optional
import warnings
warnings.filterwarnings('ignore')

from models.direction_predictor import DirectionPredictor
from train_direction_model import DirectionDatasetAdapter
from data.data_loader import CryptoDataLoader
from utils.logger import get_logger, setup_logging
from utils.config import load_config


class DirectionModelEvaluator:
    """–î–µ—Ç–∞–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ Direction –º–æ–¥–µ–ª–∏"""
    
    def __init__(self, model: nn.Module, config: Dict, device: torch.device = None):
        self.model = model
        self.config = config
        self.logger = get_logger("DirectionEvaluator")
        
        if device is None:
            self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        else:
            self.device = device
            
        self.model.to(self.device)
        self.model.eval()
        
        # –ú–∞–ø–ø–∏–Ω–≥ –∫–ª–∞—Å—Å–æ–≤
        self.class_names = ['UP', 'DOWN', 'FLAT']
        self.class_to_idx = {name: idx for idx, name in enumerate(self.class_names)}
        
    def evaluate(self, dataloader: DataLoader, 
                dataset_name: str = 'test') -> Dict:
        """–ü–æ–ª–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏ –Ω–∞ –¥–∞—Ç–∞—Å–µ—Ç–µ"""
        
        self.logger.info(f"\n{'='*60}")
        self.logger.info(f"–û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏ –Ω–∞ {dataset_name} –¥–∞—Ç–∞—Å–µ—Ç–µ")
        self.logger.info(f"{'='*60}")
        
        all_predictions = {
            '15m': {'pred': [], 'true': [], 'probs': []},
            '1h': {'pred': [], 'true': [], 'probs': []},
            '4h': {'pred': [], 'true': [], 'probs': []},
            '12h': {'pred': [], 'true': [], 'probs': []}
        }
        
        all_profits = []
        all_symbols = []
        
        with torch.no_grad():
            for batch_idx, (inputs, targets, info) in enumerate(dataloader):
                inputs = inputs.to(self.device)
                
                # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
                outputs = self.model(inputs)
                
                # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—ã–π —Ç–∞–π–º—Ñ—Ä–µ–π–º
                for timeframe in ['15m', '1h', '4h', '12h']:
                    key = f'direction_{timeframe}'
                    if key in outputs and key in targets:
                        logits = outputs[key]
                        true_labels = targets[key].to(self.device).squeeze()
                        
                        # Softmax –¥–ª—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π
                        probs = torch.softmax(logits, dim=-1)
                        predictions = logits.argmax(dim=-1)
                        
                        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
                        all_predictions[timeframe]['pred'].extend(predictions.cpu().numpy())
                        all_predictions[timeframe]['true'].extend(true_labels.cpu().numpy())
                        all_predictions[timeframe]['probs'].extend(probs.cpu().numpy())
                
                # –†–∞—Å—á–µ—Ç –ø—Ä–∏–±—ã–ª–∏ (–¥–ª—è –æ—Å–Ω–æ–≤–Ω–æ–≥–æ —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞ 4h)
                if 'price_changes' in info and '4h' in info['price_changes']:
                    price_changes = info['price_changes']['4h'].squeeze()
                    predictions_4h = outputs['direction_4h'].argmax(dim=-1)
                    
                    # –ü—Ä–æ—Å—Ç–æ–π —Ä–∞—Å—á–µ—Ç P&L
                    profits = self._calculate_profits(predictions_4h, price_changes)
                    all_profits.extend(profits.cpu().numpy())
                
                # –°–∏–º–≤–æ–ª—ã –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –ø–æ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞–º
                if 'symbol' in info:
                    all_symbols.extend(info['symbol'])
        
        # –ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        results = {}
        
        for timeframe in ['15m', '1h', '4h', '12h']:
            if len(all_predictions[timeframe]['pred']) > 0:
                results[timeframe] = self._analyze_predictions(
                    np.array(all_predictions[timeframe]['pred']),
                    np.array(all_predictions[timeframe]['true']),
                    np.array(all_predictions[timeframe]['probs']),
                    timeframe
                )
        
        # –¢–æ—Ä–≥–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑
        if all_profits:
            results['trading'] = self._analyze_trading_performance(
                np.array(all_profits),
                all_symbols
            )
        
        # –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        results['summary'] = self._create_summary(results)
        
        return results
    
    def _analyze_predictions(self, predictions: np.ndarray, 
                           true_labels: np.ndarray,
                           probabilities: np.ndarray,
                           timeframe: str) -> Dict:
        """–ê–Ω–∞–ª–∏–∑ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –¥–ª—è —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞"""
        
        self.logger.info(f"\nüìä –ê–Ω–∞–ª–∏–∑ –¥–ª—è {timeframe}:")
        
        # –ë–∞–∑–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏
        accuracy = accuracy_score(true_labels, predictions)
        
        # Confusion Matrix
        cm = confusion_matrix(true_labels, predictions)
        
        # –î–µ—Ç–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç –ø–æ –∫–ª–∞—Å—Å–∞–º
        report = classification_report(
            true_labels, predictions,
            target_names=self.class_names,
            output_dict=True
        )
        
        # Directional accuracy (–±–µ–∑ FLAT)
        non_flat_mask = true_labels != 2
        if non_flat_mask.sum() > 0:
            directional_accuracy = accuracy_score(
                true_labels[non_flat_mask],
                predictions[non_flat_mask]
            )
        else:
            directional_accuracy = 0.0
        
        # Confidence –∞–Ω–∞–ª–∏–∑
        confidence_stats = self._analyze_confidence(predictions, probabilities, true_labels)
        
        # –í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        self.logger.info(f"  Overall Accuracy: {accuracy:.2%}")
        self.logger.info(f"  Directional Accuracy (UP/DOWN): {directional_accuracy:.2%}")
        
        for class_name in self.class_names:
            if class_name in report:
                metrics = report[class_name]
                self.logger.info(f"  {class_name}: Precision={metrics['precision']:.2%}, "
                               f"Recall={metrics['recall']:.2%}, F1={metrics['f1-score']:.2%}")
        
        return {
            'accuracy': accuracy,
            'directional_accuracy': directional_accuracy,
            'confusion_matrix': cm,
            'classification_report': report,
            'confidence_stats': confidence_stats
        }
    
    def _analyze_confidence(self, predictions: np.ndarray,
                          probabilities: np.ndarray,
                          true_labels: np.ndarray) -> Dict:
        """–ê–Ω–∞–ª–∏–∑ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–∏ –≤ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è—Ö"""
        
        # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –∫–∞–∫ –º–µ—Ä–∞ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
        max_probs = probabilities.max(axis=1)
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
        confidence_stats = {
            'mean_confidence': max_probs.mean(),
            'std_confidence': max_probs.std(),
            'min_confidence': max_probs.min(),
            'max_confidence': max_probs.max()
        }
        
        # –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –¥–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö –∏ –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
        correct_mask = predictions == true_labels
        confidence_stats['correct_confidence'] = max_probs[correct_mask].mean() if correct_mask.sum() > 0 else 0
        confidence_stats['incorrect_confidence'] = max_probs[~correct_mask].mean() if (~correct_mask).sum() > 0 else 0
        
        # –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –ø–æ –∫–ª–∞—Å—Å–∞–º
        for i, class_name in enumerate(self.class_names):
            class_mask = predictions == i
            if class_mask.sum() > 0:
                confidence_stats[f'{class_name}_confidence'] = max_probs[class_mask].mean()
        
        return confidence_stats
    
    def _calculate_profits(self, predictions: torch.Tensor, 
                         price_changes: torch.Tensor) -> torch.Tensor:
        """–†–∞—Å—á–µ—Ç –ø—Ä–∏–±—ã–ª–∏ –æ—Ç —Ç–æ—Ä–≥–æ–≤—ã—Ö —Ä–µ—à–µ–Ω–∏–π"""
        
        commission = self.config['bybit']['fees']['taker']
        profits = torch.zeros_like(price_changes)
        
        # LONG –ø–æ–∑–∏—Ü–∏–∏
        long_mask = predictions == 0
        profits[long_mask] = price_changes[long_mask] - commission
        
        # SHORT –ø–æ–∑–∏—Ü–∏–∏
        short_mask = predictions == 1
        profits[short_mask] = -price_changes[short_mask] - commission
        
        # HOLD (–Ω–µ—Ç —Ç–æ—Ä–≥–æ–≤–ª–∏)
        # profits –æ—Å—Ç–∞—é—Ç—Å—è 0
        
        return profits
    
    def _analyze_trading_performance(self, profits: np.ndarray,
                                   symbols: List[str]) -> Dict:
        """–ê–Ω–∞–ª–∏–∑ —Ç–æ—Ä–≥–æ–≤–æ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
        
        self.logger.info("\nüí∞ –¢–æ—Ä–≥–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑:")
        
        # –û–±—â–∏–µ –º–µ—Ç—Ä–∏–∫–∏
        total_trades = (profits != 0).sum()
        winning_trades = (profits > 0).sum()
        losing_trades = (profits < 0).sum()
        
        if total_trades > 0:
            win_rate = winning_trades / total_trades
            avg_profit = profits[profits > 0].mean() if winning_trades > 0 else 0
            avg_loss = abs(profits[profits < 0].mean()) if losing_trades > 0 else 0
            profit_factor = (avg_profit * winning_trades) / (avg_loss * losing_trades) if losing_trades > 0 else float('inf')
            
            # Sharpe Ratio (—É–ø—Ä–æ—â–µ–Ω–Ω—ã–π)
            if profits.std() > 0:
                sharpe_ratio = (profits.mean() * 252) / (profits.std() * np.sqrt(252))
            else:
                sharpe_ratio = 0
            
            # Maximum Drawdown
            cumulative_returns = (1 + profits).cumprod()
            running_max = np.maximum.accumulate(cumulative_returns)
            drawdown = (cumulative_returns - running_max) / running_max
            max_drawdown = drawdown.min()
            
        else:
            win_rate = avg_profit = avg_loss = profit_factor = sharpe_ratio = max_drawdown = 0
        
        # –ê–Ω–∞–ª–∏–∑ –ø–æ —Å–∏–º–≤–æ–ª–∞–º
        symbol_performance = {}
        if symbols:
            df = pd.DataFrame({'symbol': symbols, 'profit': profits})
            symbol_stats = df.groupby('symbol')['profit'].agg(['mean', 'std', 'count'])
            
            for symbol in symbol_stats.index[:10]:  # –¢–æ–ø 10 —Å–∏–º–≤–æ–ª–æ–≤
                stats = symbol_stats.loc[symbol]
                symbol_performance[symbol] = {
                    'avg_profit': stats['mean'],
                    'std': stats['std'],
                    'trades': int(stats['count'])
                }
        
        # –í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        self.logger.info(f"  Total Trades: {total_trades}")
        self.logger.info(f"  Win Rate: {win_rate:.2%}")
        self.logger.info(f"  Average Win: {avg_profit:.4%}")
        self.logger.info(f"  Average Loss: {avg_loss:.4%}")
        self.logger.info(f"  Profit Factor: {profit_factor:.2f}")
        self.logger.info(f"  Sharpe Ratio: {sharpe_ratio:.2f}")
        self.logger.info(f"  Max Drawdown: {max_drawdown:.2%}")
        
        return {
            'total_trades': int(total_trades),
            'win_rate': win_rate,
            'avg_profit': avg_profit,
            'avg_loss': avg_loss,
            'profit_factor': profit_factor,
            'sharpe_ratio': sharpe_ratio,
            'max_drawdown': max_drawdown,
            'symbol_performance': symbol_performance
        }
    
    def _create_summary(self, results: Dict) -> Dict:
        """–°–æ–∑–¥–∞–Ω–∏–µ –æ–±—â–µ–≥–æ —Ä–µ–∑—é–º–µ"""
        
        # –û—Å–Ω–æ–≤–Ω–æ–π —Ç–∞–π–º—Ñ—Ä–µ–π–º –¥–ª—è –æ—Ü–µ–Ω–∫–∏
        main_tf = '4h'
        
        if main_tf in results:
            main_results = results[main_tf]
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç—å –∫ —Ç–æ—Ä–≥–æ–≤–ª–µ
            is_profitable = (
                main_results['directional_accuracy'] > 0.55 and
                results.get('trading', {}).get('win_rate', 0) > 0.50 and
                results.get('trading', {}).get('profit_factor', 0) > 1.2
            )
            
            summary = {
                'main_timeframe': main_tf,
                'directional_accuracy': main_results['directional_accuracy'],
                'overall_accuracy': main_results['accuracy'],
                'is_profitable': is_profitable,
                'recommendation': 'READY for trading' if is_profitable else 'NOT ready for trading'
            }
            
            # –î–æ–±–∞–≤–ª—è–µ–º —Ç–æ—Ä–≥–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –µ—Å–ª–∏ –µ—Å—Ç—å
            if 'trading' in results:
                summary.update({
                    'win_rate': results['trading']['win_rate'],
                    'profit_factor': results['trading']['profit_factor'],
                    'sharpe_ratio': results['trading']['sharpe_ratio']
                })
        else:
            summary = {
                'error': 'No results for main timeframe',
                'is_profitable': False,
                'recommendation': 'NOT ready for trading'
            }
        
        return summary
    
    def visualize_results(self, results: Dict, save_path: Path):
        """–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –æ—Ü–µ–Ω–∫–∏"""
        
        # –°–æ–∑–¥–∞–µ–º —Ñ–∏–≥—É—Ä—É —Å –ø–æ–¥–≥—Ä–∞—Ñ–∏–∫–∞–º–∏
        fig = plt.figure(figsize=(20, 15))
        
        # 1. Confusion Matrices –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–≤
        timeframes = ['15m', '1h', '4h', '12h']
        for i, tf in enumerate(timeframes):
            if tf in results:
                ax = plt.subplot(3, 4, i+1)
                cm = results[tf]['confusion_matrix']
                sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                           xticklabels=self.class_names,
                           yticklabels=self.class_names,
                           ax=ax)
                ax.set_title(f'Confusion Matrix - {tf}')
                ax.set_xlabel('Predicted')
                ax.set_ylabel('True')
        
        # 2. Accuracy —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ
        ax = plt.subplot(3, 4, 5)
        accuracies = {tf: results[tf]['accuracy'] for tf in timeframes if tf in results}
        dir_accuracies = {tf: results[tf]['directional_accuracy'] for tf in timeframes if tf in results}
        
        x = list(accuracies.keys())
        y1 = list(accuracies.values())
        y2 = list(dir_accuracies.values())
        
        x_pos = np.arange(len(x))
        width = 0.35
        
        ax.bar(x_pos - width/2, y1, width, label='Overall Accuracy', alpha=0.8)
        ax.bar(x_pos + width/2, y2, width, label='Directional Accuracy', alpha=0.8)
        ax.axhline(y=0.55, color='r', linestyle='--', label='Profitable Threshold')
        
        ax.set_xlabel('Timeframe')
        ax.set_ylabel('Accuracy')
        ax.set_title('Accuracy by Timeframe')
        ax.set_xticks(x_pos)
        ax.set_xticklabels(x)
        ax.legend()
        ax.grid(True, alpha=0.3)
        
        # 3. Class-wise Performance
        ax = plt.subplot(3, 4, 6)
        if '4h' in results:
            report = results['4h']['classification_report']
            
            classes = []
            precisions = []
            recalls = []
            f1_scores = []
            
            for class_name in self.class_names:
                if class_name in report:
                    classes.append(class_name)
                    precisions.append(report[class_name]['precision'])
                    recalls.append(report[class_name]['recall'])
                    f1_scores.append(report[class_name]['f1-score'])
            
            x = np.arange(len(classes))
            width = 0.25
            
            ax.bar(x - width, precisions, width, label='Precision', alpha=0.8)
            ax.bar(x, recalls, width, label='Recall', alpha=0.8)
            ax.bar(x + width, f1_scores, width, label='F1-Score', alpha=0.8)
            
            ax.set_xlabel('Class')
            ax.set_ylabel('Score')
            ax.set_title('Class-wise Performance (4h)')
            ax.set_xticks(x)
            ax.set_xticklabels(classes)
            ax.legend()
            ax.grid(True, alpha=0.3)
        
        # 4. Trading Performance
        if 'trading' in results:
            # Win Rate –∏ Profit Factor
            ax = plt.subplot(3, 4, 7)
            metrics = ['Win Rate', 'Profit Factor']
            values = [
                results['trading']['win_rate'],
                results['trading']['profit_factor'] / 3  # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
            ]
            thresholds = [0.5, 1.2 / 3]
            
            bars = ax.bar(metrics, values, alpha=0.8)
            
            # –ü–æ—Ä–æ–≥–æ–≤—ã–µ –ª–∏–Ω–∏–∏
            ax.axhline(y=thresholds[0], color='r', linestyle='--', alpha=0.5)
            
            # –¶–≤–µ—Ç –±–∞—Ä–æ–≤ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –ø–æ—Ä–æ–≥–∞
            for i, (bar, val, thresh) in enumerate(zip(bars, values, thresholds)):
                if val > thresh:
                    bar.set_color('green')
                else:
                    bar.set_color('red')
            
            ax.set_ylabel('Value')
            ax.set_title('Trading Metrics')
            ax.set_ylim(0, 1)
            
            # –ê–Ω–Ω–æ—Ç–∞—Ü–∏–∏ —Å —Ä–µ–∞–ª—å–Ω—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏
            ax.text(0, values[0] + 0.02, f'{results["trading"]["win_rate"]:.2%}', 
                   ha='center', va='bottom')
            ax.text(1, values[1] + 0.02, f'{results["trading"]["profit_factor"]:.2f}', 
                   ha='center', va='bottom')
        
        # 5. Confidence Distribution
        ax = plt.subplot(3, 4, 8)
        if '4h' in results and 'confidence_stats' in results['4h']:
            conf_stats = results['4h']['confidence_stats']
            
            labels = ['Correct\nPredictions', 'Incorrect\nPredictions']
            values = [
                conf_stats.get('correct_confidence', 0),
                conf_stats.get('incorrect_confidence', 0)
            ]
            
            bars = ax.bar(labels, values, alpha=0.8)
            bars[0].set_color('green')
            bars[1].set_color('red')
            
            ax.set_ylabel('Average Confidence')
            ax.set_title('Model Confidence Analysis')
            ax.set_ylim(0, 1)
            
            # –ê–Ω–Ω–æ—Ç–∞—Ü–∏–∏
            for i, (label, value) in enumerate(zip(labels, values)):
                ax.text(i, value + 0.02, f'{value:.2%}', ha='center', va='bottom')
        
        # 6. Summary Text
        ax = plt.subplot(3, 1, 3)
        ax.axis('off')
        
        if 'summary' in results:
            summary = results['summary']
            
            summary_text = f"""
EVALUATION SUMMARY
==================

Main Timeframe: {summary.get('main_timeframe', 'N/A')}
Directional Accuracy: {summary.get('directional_accuracy', 0):.2%}
Overall Accuracy: {summary.get('overall_accuracy', 0):.2%}

TRADING METRICS:
Win Rate: {summary.get('win_rate', 0):.2%}
Profit Factor: {summary.get('profit_factor', 0):.2f}
Sharpe Ratio: {summary.get('sharpe_ratio', 0):.2f}

STATUS: {summary.get('recommendation', 'Unknown')}

{'‚úÖ Model is PROFITABLE and ready for trading!' if summary.get('is_profitable', False) 
 else '‚ùå Model needs more training to be profitable'}
"""
            
            ax.text(0.5, 0.5, summary_text, transform=ax.transAxes,
                   fontsize=14, verticalalignment='center',
                   horizontalalignment='center',
                   bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5),
                   family='monospace')
        
        plt.tight_layout()
        plt.savefig(save_path / 'evaluation_results.png', dpi=300, bbox_inches='tight')
        plt.close()
        
        self.logger.info(f"üìä –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {save_path / 'evaluation_results.png'}")
    
    def save_results(self, results: Dict, save_path: Path):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ —Ñ–∞–π–ª"""
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º numpy arrays –≤ —Å–ø–∏—Å–∫–∏ –¥–ª—è JSON
        def convert_to_serializable(obj):
            if isinstance(obj, np.ndarray):
                return obj.tolist()
            elif isinstance(obj, np.integer):
                return int(obj)
            elif isinstance(obj, np.floating):
                return float(obj)
            elif isinstance(obj, dict):
                return {k: convert_to_serializable(v) for k, v in obj.items()}
            elif isinstance(obj, list):
                return [convert_to_serializable(item) for item in obj]
            else:
                return obj
        
        serializable_results = convert_to_serializable(results)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º JSON
        json_path = save_path / 'evaluation_results.json'
        with open(json_path, 'w') as f:
            json.dump(serializable_results, f, indent=2)
        
        self.logger.info(f"üìÑ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {json_path}")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç—á–µ—Ç
        report_path = save_path / 'evaluation_report.txt'
        with open(report_path, 'w') as f:
            f.write("DIRECTION MODEL EVALUATION REPORT\n")
            f.write("="*50 + "\n\n")
            
            # Summary
            if 'summary' in results:
                f.write("SUMMARY:\n")
                for key, value in results['summary'].items():
                    f.write(f"  {key}: {value}\n")
                f.write("\n")
            
            # Detailed results by timeframe
            for tf in ['15m', '1h', '4h', '12h']:
                if tf in results:
                    f.write(f"\n{tf} RESULTS:\n")
                    f.write("-"*30 + "\n")
                    f.write(f"  Accuracy: {results[tf]['accuracy']:.2%}\n")
                    f.write(f"  Directional Accuracy: {results[tf]['directional_accuracy']:.2%}\n")
                    
                    # Classification report
                    if 'classification_report' in results[tf]:
                        f.write("\n  Per-class metrics:\n")
                        for class_name in self.class_names:
                            if class_name in results[tf]['classification_report']:
                                metrics = results[tf]['classification_report'][class_name]
                                f.write(f"    {class_name}:\n")
                                f.write(f"      Precision: {metrics['precision']:.2%}\n")
                                f.write(f"      Recall: {metrics['recall']:.2%}\n")
                                f.write(f"      F1-Score: {metrics['f1-score']:.2%}\n")
            
            # Trading performance
            if 'trading' in results:
                f.write("\n\nTRADING PERFORMANCE:\n")
                f.write("-"*30 + "\n")
                trading = results['trading']
                f.write(f"  Total Trades: {trading['total_trades']}\n")
                f.write(f"  Win Rate: {trading['win_rate']:.2%}\n")
                f.write(f"  Average Win: {trading['avg_profit']:.4%}\n")
                f.write(f"  Average Loss: {trading['avg_loss']:.4%}\n")
                f.write(f"  Profit Factor: {trading['profit_factor']:.2f}\n")
                f.write(f"  Sharpe Ratio: {trading['sharpe_ratio']:.2f}\n")
                f.write(f"  Max Drawdown: {trading['max_drawdown']:.2%}\n")
        
        self.logger.info(f"üìÑ –û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {report_path}")


def main():
    parser = argparse.ArgumentParser(description='Evaluate Direction Model')
    parser.add_argument('--checkpoint', type=str, required=True,
                       help='Path to model checkpoint')
    parser.add_argument('--config', type=str, default='config/config.yaml',
                       help='Path to config file')
    parser.add_argument('--dataset', type=str, default='test',
                       choices=['train', 'val', 'test'],
                       help='Dataset to evaluate on')
    parser.add_argument('--batch-size', type=int, default=256,
                       help='Batch size for evaluation')
    parser.add_argument('--symbols', nargs='+', default=None,
                       help='Specific symbols to evaluate')
    
    args = parser.parse_args()
    
    # Setup
    config = load_config(args.config)
    
    # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    log_dir = Path(f"logs/evaluation_{timestamp}")
    log_dir.mkdir(parents=True, exist_ok=True)
    
    setup_logging(log_dir, "evaluation")
    logger = get_logger("EvaluateDirection")
    
    logger.info("üéØ –ù–∞—á–∏–Ω–∞–µ–º –æ—Ü–µ–Ω–∫—É Direction –º–æ–¥–µ–ª–∏")
    logger.info(f"Checkpoint: {args.checkpoint}")
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ checkpoint
    logger.info("üìÇ –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏...")
    checkpoint = torch.load(args.checkpoint, map_location='cpu')
    
    # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –º–æ–¥–µ–ª–∏
    if 'config' in checkpoint:
        model_config = checkpoint['config']['model']
    else:
        model_config = config['model']
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏
    model = DirectionPredictor(model_config)
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –≤–µ—Å–æ–≤
    if 'model_state_dict' in checkpoint:
        model.load_state_dict(checkpoint['model_state_dict'])
    else:
        model.load_state_dict(checkpoint)
    
    logger.info("‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
    
    # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ checkpoint
    if 'history' in checkpoint:
        history = checkpoint['history']
        logger.info(f"üìä –ò—Å—Ç–æ—Ä–∏—è –æ–±—É—á–µ–Ω–∏—è:")
        logger.info(f"  - –≠–ø–æ—Ö –æ–±—É—á–µ–Ω–æ: {len(history['train_loss'])}")
        logger.info(f"  - –õ—É—á—à–∏–π val_loss: {min(history['val_loss']):.4f}")
        if 'val_metrics' in history and history['val_metrics']:
            last_metrics = history['val_metrics'][-1]
            if 'directional_accuracy' in last_metrics:
                logger.info(f"  - –ü–æ—Å–ª–µ–¥–Ω—è—è directional accuracy: {last_metrics['directional_accuracy']:.2%}")
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    logger.info(f"üìä –ó–∞–≥—Ä—É–∑–∫–∞ {args.dataset} –¥–∞—Ç–∞—Å–µ—Ç–∞...")
    data_loader = CryptoDataLoader(config)
    
    if args.symbols:
        data = data_loader.load_data(symbols=args.symbols)
    else:
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–µ –∂–µ —Å–∏–º–≤–æ–ª—ã —á—Ç–æ –∏ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏
        data = data_loader.load_data()
    
    # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
    train_data, val_data, test_data = data_loader.split_data(data)
    
    # –í—ã–±–æ—Ä –Ω—É–∂–Ω–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞
    if args.dataset == 'train':
        eval_data = train_data
    elif args.dataset == 'val':
        eval_data = val_data
    else:
        eval_data = test_data
    
    logger.info(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(eval_data)} –∑–∞–ø–∏—Å–µ–π")
    
    # –°–æ–∑–¥–∞–Ω–∏–µ dataset –∏ dataloader
    dataset = DirectionDatasetAdapter(
        eval_data,
        context_window=model_config.get('context_window', 168),
        feature_cols=data_loader.feature_columns,
        target_cols=[col for col in data_loader.target_columns if col.startswith('direction_')],
        stride=1  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≤—Å–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ—Ü–µ–Ω–∫–∏
    )
    
    dataloader = DataLoader(
        dataset,
        batch_size=args.batch_size,
        shuffle=False,
        num_workers=4,
        pin_memory=True
    )
    
    # Evaluator
    evaluator = DirectionModelEvaluator(model, config)
    
    # –û—Ü–µ–Ω–∫–∞
    logger.info("üîç –ù–∞—á–∏–Ω–∞–µ–º –æ—Ü–µ–Ω–∫—É...")
    results = evaluator.evaluate(dataloader, args.dataset)
    
    # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
    logger.info("üìä –°–æ–∑–¥–∞–Ω–∏–µ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–π...")
    evaluator.visualize_results(results, log_dir)
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    evaluator.save_results(results, log_dir)
    
    # –§–∏–Ω–∞–ª—å–Ω—ã–π –≤—ã–≤–æ–¥
    logger.info("\n" + "="*60)
    logger.info("–§–ò–ù–ê–õ–¨–ù–´–ï –†–ï–ó–£–õ–¨–¢–ê–¢–´:")
    logger.info("="*60)
    
    if 'summary' in results:
        summary = results['summary']
        logger.info(f"Directional Accuracy (4h): {summary.get('directional_accuracy', 0):.2%}")
        logger.info(f"Win Rate: {summary.get('win_rate', 0):.2%}")
        logger.info(f"Profit Factor: {summary.get('profit_factor', 0):.2f}")
        logger.info(f"\nüéØ {summary.get('recommendation', 'Unknown status')}")
        
        if summary.get('is_profitable', False):
            logger.info("‚úÖ –ú–æ–¥–µ–ª—å –≥–æ—Ç–æ–≤–∞ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é!")
        else:
            logger.info("‚ùå –ú–æ–¥–µ–ª—å —Ç—Ä–µ–±—É–µ—Ç –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è")
    
    logger.info(f"\nüìÅ –í—Å–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {log_dir}")


if __name__ == "__main__":
    main()