"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è —É–ª—É—á—à–µ–Ω–∏–π –º–æ–¥–µ–ª–∏
"""

import torch
import numpy as np
import pandas as pd
from pathlib import Path
import yaml

# –ò–º–ø–æ—Ä—Ç—ã –∏–∑ –ø—Ä–æ–µ–∫—Ç–∞
from models.patchtst_improved import ImprovedPatchTST
from data.target_scaler import TargetScaler, scale_targets_in_dataset
from data.data_loader import CryptoDataLoader
from data.dataset import create_data_loaders
from utils.logger import get_logger


def test_improved_model():
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —É–ª—É—á—à–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏"""
    logger = get_logger("TestImproved")
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
    with open('config/config.yaml', 'r') as f:
        config = yaml.safe_load(f)
    
    logger.info("üöÄ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —É–ª—É—á—à–µ–Ω–∏–π –º–æ–¥–µ–ª–∏")
    
    # 1. –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    logger.info("üì• –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö...")
    data_loader = CryptoDataLoader(config)
    train_data, val_data, test_data, feature_cols = data_loader.get_train_val_test_data()
    
    logger.info(f"–†–∞–∑–º–µ—Ä—ã –¥–∞–Ω–Ω—ã—Ö: Train={len(train_data)}, Val={len(val_data)}, Test={len(test_data)}")
    
    # 2. –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π
    logger.info("üéØ –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π...")
    target_col = config['model']['target_variable']
    
    train_scaled, val_scaled, test_scaled, target_scaler = scale_targets_in_dataset(
        train_data, val_data, test_data, target_col,
        scaler_path='models_saved/target_scaler.pkl'
    )
    
    # –û–±–Ω–æ–≤–ª—è–µ–º –∫–æ–Ω—Ñ–∏–≥ –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–Ω–æ–π —Ü–µ–ª–µ–≤–æ–π
    config['model']['target_variable'] = f"{target_col}_scaled"
    
    # 3. –°–æ–∑–¥–∞–Ω–∏–µ DataLoaders
    logger.info("üèóÔ∏è –°–æ–∑–¥–∞–Ω–∏–µ DataLoaders...")
    train_loader, val_loader, test_loader = create_data_loaders(
        train_scaled, val_scaled, test_scaled, config, feature_cols
    )
    
    # 4. –°–æ–∑–¥–∞–Ω–∏–µ —É–ª—É—á—à–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏
    logger.info("ü§ñ –°–æ–∑–¥–∞–Ω–∏–µ —É–ª—É—á—à–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ PatchTST...")
    
    model_params = {
        'c_in': len(feature_cols),
        'c_out': config['model']['output_size'],
        'context_window': config['model']['context_window'],
        'target_window': config['model']['target_window'],
        'patch_len': config['model']['patch_len'],
        'stride': config['model']['stride'],
        'd_model': config['model']['d_model'],
        'n_heads': config['model']['n_heads'],
        'd_ff': config['model']['d_ff'],
        'n_layers': config['model']['e_layers'],
        'dropout': config['model']['dropout'],
        'activation': config['model']['activation']
    }
    
    model = ImprovedPatchTST(**model_params)
    logger.info(f"–ü–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –º–æ–¥–µ–ª–∏: {sum(p.numel() for p in model.parameters()):,}")
    
    # 5. –¢–µ—Å—Ç forward pass
    logger.info("üîç –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ forward pass...")
    
    # –ü–æ–ª—É—á–∞–µ–º –æ–¥–∏–Ω –±–∞—Ç—á
    for batch in train_loader:
        inputs, targets, info = batch
        break
    
    logger.info(f"Input shape: {inputs.shape}")
    logger.info(f"Target shape: {targets.shape}")
    
    # Forward pass
    model.eval()
    with torch.no_grad():
        outputs = model(inputs)
        
    logger.info(f"Output shape: {outputs.shape}")
    logger.info(f"Output statistics: mean={outputs.mean():.4f}, std={outputs.std():.4f}")
    
    # 6. –¢–µ—Å—Ç loss
    criterion = torch.nn.MSELoss()
    loss = criterion(outputs, targets)
    logger.info(f"Initial loss: {loss.item():.4f}")
    
    # 7. –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å baseline
    baseline_pred = torch.zeros_like(targets)  # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –Ω—É–ª–µ–π (—Å—Ä–µ–¥–Ω–µ–µ –ø–æ—Å–ª–µ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏)
    baseline_loss = criterion(baseline_pred, targets)
    logger.info(f"Baseline loss (–Ω—É–ª–∏): {baseline_loss.item():.4f}")
    
    # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Å—Ä–µ–¥–Ω–µ–≥–æ
    mean_pred = targets.mean() * torch.ones_like(targets)
    mean_loss = criterion(mean_pred, targets)
    logger.info(f"Baseline loss (—Å—Ä–µ–¥–Ω–µ–µ): {mean_loss.item():.4f}")
    
    logger.info("‚úÖ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ —É—Å–ø–µ—à–Ω–æ!")
    
    return model, train_loader, val_loader, target_scaler


if __name__ == "__main__":
    test_improved_model()